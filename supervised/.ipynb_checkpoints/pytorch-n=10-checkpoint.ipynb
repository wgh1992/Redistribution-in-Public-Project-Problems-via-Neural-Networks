{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T00:35:05.633036Z",
     "start_time": "2021-05-23T00:35:03.404034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pygame\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm \n",
    "import matplotlib.cm as cm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "print(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T00:35:05.649029Z",
     "start_time": "2021-05-23T00:35:05.635032Z"
    }
   },
   "outputs": [],
   "source": [
    "global target_order\n",
    "target_order = \"supervised\"\n",
    "global temp_list\n",
    "temp_list = []\n",
    "Agent_number_n=10;\n",
    "Alpha = 0.882;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T00:35:14.440171Z",
     "start_time": "2021-05-23T00:35:05.650989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.88426788 0.83035063 0.70554783 ... 0.46534338 0.35300706 0.31187924]\n",
      "  [0.89106093 0.83035063 0.70554783 ... 0.46534338 0.35300706 0.31187924]\n",
      "  [0.89106093 0.88426788 0.70554783 ... 0.46534338 0.35300706 0.31187924]\n",
      "  ...\n",
      "  [0.89106093 0.88426788 0.83035063 ... 0.59041286 0.35300706 0.31187924]\n",
      "  [0.89106093 0.88426788 0.83035063 ... 0.59041286 0.46534338 0.31187924]\n",
      "  [0.89106093 0.88426788 0.83035063 ... 0.59041286 0.46534338 0.35300706]]\n",
      "\n",
      " [[0.90382865 0.86726401 0.58476074 ... 0.33742962 0.30343362 0.03984533]\n",
      "  [0.94547237 0.86726401 0.58476074 ... 0.33742962 0.30343362 0.03984533]\n",
      "  [0.94547237 0.90382865 0.58476074 ... 0.33742962 0.30343362 0.03984533]\n",
      "  ...\n",
      "  [0.94547237 0.90382865 0.86726401 ... 0.37919818 0.30343362 0.03984533]\n",
      "  [0.94547237 0.90382865 0.86726401 ... 0.37919818 0.33742962 0.03984533]\n",
      "  [0.94547237 0.90382865 0.86726401 ... 0.37919818 0.33742962 0.30343362]]\n",
      "\n",
      " [[0.974071   0.7736022  0.70481365 ... 0.04244464 0.01432555 0.00167776]\n",
      "  [0.98355976 0.7736022  0.70481365 ... 0.04244464 0.01432555 0.00167776]\n",
      "  [0.98355976 0.974071   0.70481365 ... 0.04244464 0.01432555 0.00167776]\n",
      "  ...\n",
      "  [0.98355976 0.974071   0.7736022  ... 0.16829421 0.01432555 0.00167776]\n",
      "  [0.98355976 0.974071   0.7736022  ... 0.16829421 0.04244464 0.00167776]\n",
      "  [0.98355976 0.974071   0.7736022  ... 0.16829421 0.04244464 0.01432555]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.85773506 0.82072647 0.80698948 ... 0.18494193 0.17355652 0.01995795]\n",
      "  [0.9392176  0.82072647 0.80698948 ... 0.18494193 0.17355652 0.01995795]\n",
      "  [0.9392176  0.85773506 0.80698948 ... 0.18494193 0.17355652 0.01995795]\n",
      "  ...\n",
      "  [0.9392176  0.85773506 0.82072647 ... 0.3931253  0.17355652 0.01995795]\n",
      "  [0.9392176  0.85773506 0.82072647 ... 0.3931253  0.18494193 0.01995795]\n",
      "  [0.9392176  0.85773506 0.82072647 ... 0.3931253  0.18494193 0.17355652]]\n",
      "\n",
      " [[0.868356   0.83806435 0.68319415 ... 0.36189952 0.15474683 0.14664275]\n",
      "  [0.94568707 0.83806435 0.68319415 ... 0.36189952 0.15474683 0.14664275]\n",
      "  [0.94568707 0.868356   0.68319415 ... 0.36189952 0.15474683 0.14664275]\n",
      "  ...\n",
      "  [0.94568707 0.868356   0.83806435 ... 0.38587864 0.15474683 0.14664275]\n",
      "  [0.94568707 0.868356   0.83806435 ... 0.38587864 0.36189952 0.14664275]\n",
      "  [0.94568707 0.868356   0.83806435 ... 0.38587864 0.36189952 0.15474683]]\n",
      "\n",
      " [[0.66157948 0.61495714 0.57051095 ... 0.4418445  0.0600712  0.02538883]\n",
      "  [0.94376509 0.61495714 0.57051095 ... 0.4418445  0.0600712  0.02538883]\n",
      "  [0.94376509 0.66157948 0.57051095 ... 0.4418445  0.0600712  0.02538883]\n",
      "  ...\n",
      "  [0.94376509 0.66157948 0.61495714 ... 0.49591314 0.0600712  0.02538883]\n",
      "  [0.94376509 0.66157948 0.61495714 ... 0.49591314 0.4418445  0.02538883]\n",
      "  [0.94376509 0.66157948 0.61495714 ... 0.49591314 0.4418445  0.0600712 ]]]\n",
      "[[[0.75304212 0.67432225 0.65461449 ... 0.55243181 0.50364527 0.24675915]\n",
      "  [0.95682311 0.67432225 0.65461449 ... 0.55243181 0.50364527 0.24675915]\n",
      "  [0.95682311 0.75304212 0.65461449 ... 0.55243181 0.50364527 0.24675915]\n",
      "  ...\n",
      "  [0.95682311 0.75304212 0.67432225 ... 0.57648773 0.50364527 0.24675915]\n",
      "  [0.95682311 0.75304212 0.67432225 ... 0.57648773 0.55243181 0.24675915]\n",
      "  [0.95682311 0.75304212 0.67432225 ... 0.57648773 0.55243181 0.50364527]]\n",
      "\n",
      " [[0.75247593 0.57712899 0.55802631 ... 0.07044515 0.06565712 0.0287664 ]\n",
      "  [0.82782367 0.57712899 0.55802631 ... 0.07044515 0.06565712 0.0287664 ]\n",
      "  [0.82782367 0.75247593 0.55802631 ... 0.07044515 0.06565712 0.0287664 ]\n",
      "  ...\n",
      "  [0.82782367 0.75247593 0.57712899 ... 0.16482203 0.06565712 0.0287664 ]\n",
      "  [0.82782367 0.75247593 0.57712899 ... 0.16482203 0.07044515 0.0287664 ]\n",
      "  [0.82782367 0.75247593 0.57712899 ... 0.16482203 0.07044515 0.06565712]]\n",
      "\n",
      " [[0.84452707 0.79808221 0.6991967  ... 0.09927458 0.01871954 0.01666208]\n",
      "  [0.91925933 0.79808221 0.6991967  ... 0.09927458 0.01871954 0.01666208]\n",
      "  [0.91925933 0.84452707 0.6991967  ... 0.09927458 0.01871954 0.01666208]\n",
      "  ...\n",
      "  [0.91925933 0.84452707 0.79808221 ... 0.12449605 0.01871954 0.01666208]\n",
      "  [0.91925933 0.84452707 0.79808221 ... 0.12449605 0.09927458 0.01666208]\n",
      "  [0.91925933 0.84452707 0.79808221 ... 0.12449605 0.09927458 0.01871954]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.91942647 0.85239434 0.82236869 ... 0.61126642 0.58603762 0.17626278]\n",
      "  [0.98570734 0.85239434 0.82236869 ... 0.61126642 0.58603762 0.17626278]\n",
      "  [0.98570734 0.91942647 0.82236869 ... 0.61126642 0.58603762 0.17626278]\n",
      "  ...\n",
      "  [0.98570734 0.91942647 0.85239434 ... 0.64717338 0.58603762 0.17626278]\n",
      "  [0.98570734 0.91942647 0.85239434 ... 0.64717338 0.61126642 0.17626278]\n",
      "  [0.98570734 0.91942647 0.85239434 ... 0.64717338 0.61126642 0.58603762]]\n",
      "\n",
      " [[0.89632027 0.76503725 0.69126662 ... 0.28508211 0.17188141 0.08695369]\n",
      "  [0.90494236 0.76503725 0.69126662 ... 0.28508211 0.17188141 0.08695369]\n",
      "  [0.90494236 0.89632027 0.69126662 ... 0.28508211 0.17188141 0.08695369]\n",
      "  ...\n",
      "  [0.90494236 0.89632027 0.76503725 ... 0.46111923 0.17188141 0.08695369]\n",
      "  [0.90494236 0.89632027 0.76503725 ... 0.46111923 0.28508211 0.08695369]\n",
      "  [0.90494236 0.89632027 0.76503725 ... 0.46111923 0.28508211 0.17188141]]\n",
      "\n",
      " [[0.81603361 0.81041772 0.79341242 ... 0.35660819 0.32113784 0.22186454]\n",
      "  [0.93063697 0.81041772 0.79341242 ... 0.35660819 0.32113784 0.22186454]\n",
      "  [0.93063697 0.81603361 0.79341242 ... 0.35660819 0.32113784 0.22186454]\n",
      "  ...\n",
      "  [0.93063697 0.81603361 0.81041772 ... 0.44151317 0.32113784 0.22186454]\n",
      "  [0.93063697 0.81603361 0.81041772 ... 0.44151317 0.35660819 0.22186454]\n",
      "  [0.93063697 0.81603361 0.81041772 ... 0.44151317 0.35660819 0.32113784]]]\n",
      "[6.38355986 5.30392286 4.30461151 ... 5.50381544 5.47261734 4.84703351]\n",
      "[6.16210229 3.70063405 4.54893918 ... 7.15643005 5.33720701 5.96216053]\n"
     ]
    }
   ],
   "source": [
    "global temp_list\n",
    "temp_list = []\n",
    "def appen(_x_list,y):\n",
    "    global temp_list\n",
    "    temp_list.append(_x_list)\n",
    "    \n",
    "def appen_train(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    \n",
    "    training_data.append(temp_list)\n",
    "    training_label.append(S)\n",
    "    \n",
    "\n",
    "def read_training_data():\n",
    "    for i in range(100000):\n",
    "        appen_train(sorted(np.random.rand(Agent_number_n), reverse=True));\n",
    "\n",
    "training_data=[]\n",
    "training_label=[]\n",
    "S=1.0\n",
    "read_training_data();\n",
    "\n",
    "def appen_test(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data.append(temp_list)\n",
    "    testing_label.append(S)\n",
    "    \n",
    "\n",
    "def read_testing_data():\n",
    "#     devided=20\n",
    "#     for i1 in range(devided+1):\n",
    "#         for i2 in range(i1+1):\n",
    "#             for i3 in range(i2+1):\n",
    "#                 appen_test(i1/devided,i2/devided,i3/devided);\n",
    "    for i in range(100000):\n",
    "        appen_test(sorted(np.random.rand(Agent_number_n), reverse=True));\n",
    "                            \n",
    "\n",
    "testing_data=[]\n",
    "testing_label=[]\n",
    "S=1.0\n",
    "read_testing_data();\n",
    "\n",
    "training_data=np.array(training_data)\n",
    "training_label=np.array(training_label)\n",
    "testing_data=np.array(testing_data)\n",
    "testing_label=np.array(testing_label)\n",
    "print(training_data)\n",
    "print(testing_data)\n",
    "print(training_label)\n",
    "print(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.363Z"
    }
   },
   "outputs": [],
   "source": [
    "def h_3_star(a, b, t):\n",
    "    return a - min(a, t) + b - min(b, t) + max(min(a, t)+min(b, t), 2*t/3) + 1/2 * max(min(a, t)+min(b, t), t) - 1/2 * max(max(min(a, t), min(b, t)), 2*t/3) - t/6\n",
    "\n",
    "\n",
    "def f_function(a, b, z):\n",
    "    if(z >= 1):\n",
    "        return (a+b)/2 + z/3\n",
    "    else:\n",
    "        return z/3 + h_3_star(a, b, 1-z)/2\n",
    "\n",
    "def h_function(input_list):\n",
    "    #input_list = sorted(input_list)\n",
    "    g_list = []\n",
    "    for j1 in range(len(input_list) ):\n",
    "        for j2 in range(len(input_list)):\n",
    "            if(j1 != j2):\n",
    "                a = input_list[j1]\n",
    "                b = input_list[j2]\n",
    "                z = sum(input_list)- a-b\n",
    "\n",
    "                g_list.append( f_function(a, b, z) * (Agent_number_n-1))\n",
    "    h = sum(g_list) * 3 /  (Agent_number_n) /  (Agent_number_n-1) /  (Agent_number_n - 2)\n",
    "    return h\n",
    "                \n",
    "                \n",
    "x_list = []\n",
    "y_list = []\n",
    "z_list = []\n",
    "result_list = []\n",
    "training_supervised_label=[]\n",
    "for index in range(len(training_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        x_list.append(training_data[index][i][0])\n",
    "        y_list.append(training_data[index][i][1])\n",
    "        h = h_function(training_data[index][i])\n",
    "        z_list.append(float(h))\n",
    "        h_list.append(float(h))\n",
    "    training_supervised_label.append(h_list)\n",
    "    result_list.append(sum(h_list)/training_label[index]) \n",
    "    \n",
    "    \n",
    "print(max(result_list), min(result_list), max(result_list)-min(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.365Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.368Z"
    }
   },
   "outputs": [],
   "source": [
    "training_supervised_label=np.array(training_supervised_label)\n",
    "print(training_supervised_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.370Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "print(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.373Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "        \n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.input_dim = Agent_number_n-1\n",
    "        self.hidden_dim = 100\n",
    "        self.output_dim = 1\n",
    "        self.hidden_layer_count = 6 \n",
    "        \n",
    "        current_dim = self.input_dim\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(self.hidden_layer_count):\n",
    "            self.layers.append(torch.nn.Linear(current_dim, self.hidden_dim))\n",
    "            current_dim = self.hidden_dim\n",
    "        self.layers.append(torch.nn.Linear(current_dim, self.output_dim))\n",
    "\n",
    "    def calculate(self, value_list):\n",
    "        h = value_list\n",
    "        for layer in self.layers:\n",
    "            h = torch.relu(layer(h))\n",
    "        return h\n",
    "\n",
    "    def forward(self, input_list,input_label,label):\n",
    "        global iteration,echo,target_order\n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).cuda().type(torch.float32)\n",
    "        h_list = []\n",
    "\n",
    "        if (target_order == \"supervised\"):\n",
    "            loss = 0 \n",
    "            for i in range(Agent_number_n):\n",
    "                h = self.calculate(input_list[i])\n",
    "                loss += torch.square(h - label[i])\n",
    "                h_list.append(h)\n",
    "            return loss\n",
    "        else:\n",
    "            for i in range(Agent_number_n):\n",
    "                h = self.calculate(input_list[i])\n",
    "                h_list.append(h)\n",
    "            input_label = torch.from_numpy(\n",
    "                np.array(input_label)).cuda().type(torch.float32)\n",
    "            sum_h = torch.sum(torch.cat(h_list)).cuda()\n",
    "\n",
    "\n",
    "            loss1 = torch.where((Agent_number_n-1)*input_label>sum_h,\n",
    "                            torch.square(((Agent_number_n-1)*input_label-sum_h)),\n",
    "                            torch.zeros(1).cuda()\n",
    "                          )\n",
    "\n",
    "            loss2 = torch.where((Agent_number_n-Alpha)*input_label<sum_h,\n",
    "                            torch.square((sum_h-(Agent_number_n-Alpha)*input_label)),\n",
    "                            torch.zeros(1).cuda()\n",
    "                          )\n",
    "\n",
    "            return loss1,loss2,h_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.375Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "net  = Net()\n",
    "net.apply(weight_init)\n",
    "\n",
    "net = torch.load(\"save/Deep_learning_10\")\n",
    "net.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.377Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#optimizer = opt.RMSprop(net.parameters(), lr=0.00001)\n",
    "#optimizer = opt.SGD(net.parameters(), lr=0.00001)\n",
    "optimizer = opt.Adam(net.parameters(), lr=0.000005)\n",
    "\n",
    "batch_size = 64\n",
    "echo = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.379Z"
    }
   },
   "outputs": [],
   "source": [
    "target_order = \"supervised\"\n",
    "for iteration in range(int(echo)):\n",
    "    # offender_types = []\n",
    "    # defender_types = []\n",
    "    \n",
    "    \n",
    "    X_train_list = []\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "    while(temp_number<len(training_data)-1):\n",
    "        loss_sum = 0\n",
    "        denominator = 0\n",
    "        for index in range(temp_number, min(batch_size+temp_number,len(training_data))):\n",
    "            h_loss = net(training_data[index],training_label[index],training_supervised_label[index])\n",
    "            denominator += 1\n",
    "            loss_sum += h_loss\n",
    "            \n",
    "        loss = (loss_sum) / denominator \n",
    "        total_batch_loss +=float(loss_sum)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        temp_number = index\n",
    "        \n",
    "        if(random.random()<=0.01):\n",
    "            print(temp_number,loss,float(loss_sum))\n",
    "\n",
    "\n",
    "    print(\"batch iteration\", iteration)\n",
    "    print(\"batch_loss: %.2f \" % (total_batch_loss/len(training_data)))\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.380Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = net.calculate(torch.tensor(testing_data[index][i]).cuda().type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list.append(sum(h_list)/testing_label[index])\n",
    "    \n",
    "\n",
    "print(max(result_list),min(result_list),max(result_list)-min(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.382Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.384Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net, \"save/Deep_learning_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.386Z"
    }
   },
   "outputs": [],
   "source": [
    "#optimizer = opt.RMSprop(net.parameters(), lr=0.00001)\n",
    "#optimizer = opt.SGD(net.parameters(), lr=0.00005)\n",
    "optimizer = opt.Adam(net.parameters(), lr=0.000005)\n",
    "\n",
    "batch_size = 64\n",
    "echo = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.389Z"
    }
   },
   "outputs": [],
   "source": [
    "target_order = \"unsupervised\"\n",
    "for iteration in range(int(echo)):\n",
    "    # offender_types = []\n",
    "    # defender_types = []\n",
    "    \n",
    "    \n",
    "    X_train_list = []\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "    while(temp_number<len(training_data)-1):\n",
    "        \n",
    "        loss2_list = []\n",
    "        loss1_sum = 0\n",
    "        loss2_sum = 0\n",
    "        denominator = 0\n",
    "        for index in range(temp_number, min(batch_size+temp_number,len(training_data))):\n",
    "            h_loss1,h_loss2,h_list = net(training_data[index],training_label[index],0)\n",
    "            denominator += 1\n",
    "            loss1_sum += h_loss1\n",
    "            loss2_sum += h_loss2\n",
    "            \n",
    "        loss_sum = loss1_sum + loss2_sum\n",
    "        loss = (loss_sum) / denominator \n",
    "        total_batch_loss +=float(loss_sum)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        temp_number = index\n",
    "        \n",
    "        if(random.random()<=0.01):\n",
    "            print(temp_number,loss,float(loss1_sum),float(loss2_sum))\n",
    "\n",
    "\n",
    "    print(\"batch iteration\", iteration)\n",
    "    print(\"batch_loss: %.2f \" % (total_batch_loss/len(training_data)))\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.394Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net, \"save/Deep_learning_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.396Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = net.calculate(torch.tensor(testing_data[index][i]).cuda().type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list.append(sum(h_list)/testing_label[index])\n",
    "    \n",
    "\n",
    "print(max(result_list),min(result_list),max(result_list)-min(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-23T00:35:03.398Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
