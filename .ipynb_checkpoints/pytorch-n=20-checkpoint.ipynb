{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T02:40:02.605412Z",
     "start_time": "2021-05-12T02:40:01.123165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The classic game of flappy bird. Make with python\n",
    "and pygame. Features pixel perfect collision using masks :o\n",
    "Date Modified:  Jul 30, 2019\n",
    "Author: Tech With Tim\n",
    "Estimated Work Time: 5 hours (1 just for that damn collision)\n",
    "\"\"\"\n",
    "import pygame\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm \n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T02:40:04.179252Z",
     "start_time": "2021-05-12T02:40:02.607408Z"
    }
   },
   "outputs": [],
   "source": [
    "Agent_number_n=10;\n",
    "Alpha = 0.7;\n",
    "\n",
    "global temp_list\n",
    "temp_list = []\n",
    "def appen(_x_list,y):\n",
    "    global temp_list\n",
    "    temp_list.append(_x_list)\n",
    "    \n",
    "def appen_train(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    \n",
    "    training_data.append(temp_list)\n",
    "    training_label.append(S)\n",
    "    \n",
    "\n",
    "def read_training_data():\n",
    "    for i in range(30000):\n",
    "        appen_train(np.random.rand(Agent_number_n));\n",
    "\n",
    "training_data=[]\n",
    "training_label=[]\n",
    "S=1.0\n",
    "read_training_data();\n",
    "\n",
    "def appen_test(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data.append(temp_list)\n",
    "    testing_label.append(S)\n",
    "    \n",
    "\n",
    "def read_testing_data():\n",
    "#     devided=20\n",
    "#     for i1 in range(devided+1):\n",
    "#         for i2 in range(i1+1):\n",
    "#             for i3 in range(i2+1):\n",
    "#                 appen_test(i1/devided,i2/devided,i3/devided);\n",
    "    for i in range(10000):\n",
    "        appen_test(np.random.rand(Agent_number_n));\n",
    "                            \n",
    "\n",
    "testing_data=[]\n",
    "testing_label=[]\n",
    "S=1.0\n",
    "read_testing_data();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T02:40:04.982579Z",
     "start_time": "2021-05-12T02:40:04.180289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.84207384 0.63903022 0.43489612 ... 0.21462329 0.41127828 0.79954471]\n",
      "  [0.8599114  0.63903022 0.43489612 ... 0.21462329 0.41127828 0.79954471]\n",
      "  [0.8599114  0.84207384 0.43489612 ... 0.21462329 0.41127828 0.79954471]\n",
      "  ...\n",
      "  [0.8599114  0.84207384 0.63903022 ... 0.68978765 0.41127828 0.79954471]\n",
      "  [0.8599114  0.84207384 0.63903022 ... 0.68978765 0.21462329 0.79954471]\n",
      "  [0.8599114  0.84207384 0.63903022 ... 0.68978765 0.21462329 0.41127828]]\n",
      "\n",
      " [[0.0258958  0.91814882 0.61535919 ... 0.88144498 0.96126898 0.25694311]\n",
      "  [0.99232061 0.91814882 0.61535919 ... 0.88144498 0.96126898 0.25694311]\n",
      "  [0.99232061 0.0258958  0.61535919 ... 0.88144498 0.96126898 0.25694311]\n",
      "  ...\n",
      "  [0.99232061 0.0258958  0.91814882 ... 0.70787987 0.96126898 0.25694311]\n",
      "  [0.99232061 0.0258958  0.91814882 ... 0.70787987 0.88144498 0.25694311]\n",
      "  [0.99232061 0.0258958  0.91814882 ... 0.70787987 0.88144498 0.96126898]]\n",
      "\n",
      " [[0.38179702 0.92000176 0.18412802 ... 0.21319695 0.81941268 0.27574287]\n",
      "  [0.11283565 0.92000176 0.18412802 ... 0.21319695 0.81941268 0.27574287]\n",
      "  [0.11283565 0.38179702 0.18412802 ... 0.21319695 0.81941268 0.27574287]\n",
      "  ...\n",
      "  [0.11283565 0.38179702 0.92000176 ... 0.47772794 0.81941268 0.27574287]\n",
      "  [0.11283565 0.38179702 0.92000176 ... 0.47772794 0.21319695 0.27574287]\n",
      "  [0.11283565 0.38179702 0.92000176 ... 0.47772794 0.21319695 0.81941268]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.5217736  0.53992231 0.86241289 ... 0.04074857 0.76151066 0.8468996 ]\n",
      "  [0.96561654 0.53992231 0.86241289 ... 0.04074857 0.76151066 0.8468996 ]\n",
      "  [0.96561654 0.5217736  0.86241289 ... 0.04074857 0.76151066 0.8468996 ]\n",
      "  ...\n",
      "  [0.96561654 0.5217736  0.53992231 ... 0.36215114 0.76151066 0.8468996 ]\n",
      "  [0.96561654 0.5217736  0.53992231 ... 0.36215114 0.04074857 0.8468996 ]\n",
      "  [0.96561654 0.5217736  0.53992231 ... 0.36215114 0.04074857 0.76151066]]\n",
      "\n",
      " [[0.6753418  0.52835543 0.3169578  ... 0.55164151 0.09903493 0.3630398 ]\n",
      "  [0.36878846 0.52835543 0.3169578  ... 0.55164151 0.09903493 0.3630398 ]\n",
      "  [0.36878846 0.6753418  0.3169578  ... 0.55164151 0.09903493 0.3630398 ]\n",
      "  ...\n",
      "  [0.36878846 0.6753418  0.52835543 ... 0.19090898 0.09903493 0.3630398 ]\n",
      "  [0.36878846 0.6753418  0.52835543 ... 0.19090898 0.55164151 0.3630398 ]\n",
      "  [0.36878846 0.6753418  0.52835543 ... 0.19090898 0.55164151 0.09903493]]\n",
      "\n",
      " [[0.31328956 0.51895231 0.85822054 ... 0.69385948 0.92950404 0.64161882]\n",
      "  [0.65799303 0.51895231 0.85822054 ... 0.69385948 0.92950404 0.64161882]\n",
      "  [0.65799303 0.31328956 0.85822054 ... 0.69385948 0.92950404 0.64161882]\n",
      "  ...\n",
      "  [0.65799303 0.31328956 0.51895231 ... 0.19835074 0.92950404 0.64161882]\n",
      "  [0.65799303 0.31328956 0.51895231 ... 0.19835074 0.69385948 0.64161882]\n",
      "  [0.65799303 0.31328956 0.51895231 ... 0.19835074 0.69385948 0.92950404]]]\n",
      "[[[0.0388056  0.43842917 0.74640105 ... 0.73368043 0.57698995 0.43548542]\n",
      "  [0.65790618 0.43842917 0.74640105 ... 0.73368043 0.57698995 0.43548542]\n",
      "  [0.65790618 0.0388056  0.74640105 ... 0.73368043 0.57698995 0.43548542]\n",
      "  ...\n",
      "  [0.65790618 0.0388056  0.43842917 ... 0.49608634 0.57698995 0.43548542]\n",
      "  [0.65790618 0.0388056  0.43842917 ... 0.49608634 0.73368043 0.43548542]\n",
      "  [0.65790618 0.0388056  0.43842917 ... 0.49608634 0.73368043 0.57698995]]\n",
      "\n",
      " [[0.70869349 0.96790392 0.5442238  ... 0.07380614 0.21623457 0.99491941]\n",
      "  [0.68202442 0.96790392 0.5442238  ... 0.07380614 0.21623457 0.99491941]\n",
      "  [0.68202442 0.70869349 0.5442238  ... 0.07380614 0.21623457 0.99491941]\n",
      "  ...\n",
      "  [0.68202442 0.70869349 0.96790392 ... 0.01398707 0.21623457 0.99491941]\n",
      "  [0.68202442 0.70869349 0.96790392 ... 0.01398707 0.07380614 0.99491941]\n",
      "  [0.68202442 0.70869349 0.96790392 ... 0.01398707 0.07380614 0.21623457]]\n",
      "\n",
      " [[0.67343872 0.52810595 0.00171354 ... 0.63588431 0.34625634 0.58444993]\n",
      "  [0.35344236 0.52810595 0.00171354 ... 0.63588431 0.34625634 0.58444993]\n",
      "  [0.35344236 0.67343872 0.00171354 ... 0.63588431 0.34625634 0.58444993]\n",
      "  ...\n",
      "  [0.35344236 0.67343872 0.52810595 ... 0.39377502 0.34625634 0.58444993]\n",
      "  [0.35344236 0.67343872 0.52810595 ... 0.39377502 0.63588431 0.58444993]\n",
      "  [0.35344236 0.67343872 0.52810595 ... 0.39377502 0.63588431 0.34625634]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.6760309  0.88868307 0.11136729 ... 0.2398167  0.53335604 0.72205955]\n",
      "  [0.81381035 0.88868307 0.11136729 ... 0.2398167  0.53335604 0.72205955]\n",
      "  [0.81381035 0.6760309  0.11136729 ... 0.2398167  0.53335604 0.72205955]\n",
      "  ...\n",
      "  [0.81381035 0.6760309  0.88868307 ... 0.62969335 0.53335604 0.72205955]\n",
      "  [0.81381035 0.6760309  0.88868307 ... 0.62969335 0.2398167  0.72205955]\n",
      "  [0.81381035 0.6760309  0.88868307 ... 0.62969335 0.2398167  0.53335604]]\n",
      "\n",
      " [[0.39596373 0.59461531 0.49012812 ... 0.27612329 0.79647141 0.49161625]\n",
      "  [0.78842369 0.59461531 0.49012812 ... 0.27612329 0.79647141 0.49161625]\n",
      "  [0.78842369 0.39596373 0.49012812 ... 0.27612329 0.79647141 0.49161625]\n",
      "  ...\n",
      "  [0.78842369 0.39596373 0.59461531 ... 0.45756321 0.79647141 0.49161625]\n",
      "  [0.78842369 0.39596373 0.59461531 ... 0.45756321 0.27612329 0.49161625]\n",
      "  [0.78842369 0.39596373 0.59461531 ... 0.45756321 0.27612329 0.79647141]]\n",
      "\n",
      " [[0.33824214 0.7634176  0.70120907 ... 0.63067538 0.62943002 0.78164922]\n",
      "  [0.7881686  0.7634176  0.70120907 ... 0.63067538 0.62943002 0.78164922]\n",
      "  [0.7881686  0.33824214 0.70120907 ... 0.63067538 0.62943002 0.78164922]\n",
      "  ...\n",
      "  [0.7881686  0.33824214 0.7634176  ... 0.76681492 0.62943002 0.78164922]\n",
      "  [0.7881686  0.33824214 0.7634176  ... 0.76681492 0.63067538 0.78164922]\n",
      "  [0.7881686  0.33824214 0.7634176  ... 0.76681492 0.63067538 0.62943002]]]\n",
      "[5.08502809 5.7932911  4.98969873 ... 5.32432129 4.46437622 6.10090814]\n",
      "[4.99232676 5.46659898 4.82758223 ... 4.82625357 5.51358254 6.74685738]\n"
     ]
    }
   ],
   "source": [
    "training_data=np.array(training_data)\n",
    "training_label=np.array(training_label)\n",
    "testing_data=np.array(testing_data)\n",
    "testing_label=np.array(testing_label)\n",
    "print(training_data)\n",
    "print(testing_data)\n",
    "print(training_label)\n",
    "print(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T02:40:05.049499Z",
     "start_time": "2021-05-12T02:40:04.982579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "print(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T02:40:05.065080Z",
     "start_time": "2021-05-12T02:40:05.049499Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "        \n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        num_input = Agent_number_n-1\n",
    "        num_hidden = 100\n",
    "        num_output = 1\n",
    "\n",
    "        self.hidden_0 = torch.nn.Linear(num_input, num_hidden)\n",
    "        self.hidden_1 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_2 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_3 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.output_allocation = torch.nn.Linear(num_hidden, num_output)\n",
    "\n",
    "    def calculate(self, value_list):\n",
    "        h1 = torch.relu_(self.hidden_0(value_list))\n",
    "        h2 = torch.relu_(self.hidden_1(h1))\n",
    "        h3 = torch.relu_(self.hidden_2(h2))\n",
    "        h4 = torch.relu_(self.hidden_3(h3))\n",
    "        h = torch.relu(self.output_allocation(h4))\n",
    "\n",
    "        return h\n",
    "\n",
    "    def forward(self, input_list,input_label):\n",
    "        global iteration,echo\n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).cuda().type(torch.float32)\n",
    "        h_list = []\n",
    "        for i in range(Agent_number_n):\n",
    "            h = self.calculate(input_list[i])\n",
    "            h_list.append(h)\n",
    "        \n",
    "        input_label = torch.from_numpy(\n",
    "            np.array(input_label)).cuda().type(torch.float32)\n",
    "        sum_h = torch.sum(torch.cat(h_list)).cuda()\n",
    "        \n",
    "        \n",
    "        loss1 = torch.where((Agent_number_n-1)*input_label>sum_h,\n",
    "                        torch.square((Agent_number_n-1)*input_label-sum_h),\n",
    "                        torch.zeros(1).cuda()\n",
    "                      )\n",
    "\n",
    "        loss2 = torch.where((Agent_number_n-Alpha)*input_label<sum_h,\n",
    "                        torch.square(sum_h-(Agent_number_n-Alpha)*input_label),\n",
    "                        torch.zeros(1).cuda()\n",
    "                      )\n",
    "                      \n",
    "\n",
    "        return loss1,loss2,h_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T02:40:06.271035Z",
     "start_time": "2021-05-12T02:40:05.065080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (hidden_0): Linear(in_features=9, out_features=100, bias=True)\n",
       "  (hidden_1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (hidden_2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (hidden_3): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (output_allocation): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "net  = Net()\n",
    "net.apply(weight_init)\n",
    "\n",
    "net = torch.load(\"save/Deep_learning_10\")\n",
    "net.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T02:40:06.276644Z",
     "start_time": "2021-05-12T02:40:06.271035Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#optimizer = opt.RMSprop(net.parameters(), lr=0.00001)\n",
    "#optimizer = opt.SGD(net.parameters(), lr=0.00001)\n",
    "optimizer = opt.Adam(net.parameters(), lr=0.00005)\n",
    "\n",
    "batch_size = 128\n",
    "echo = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T03:19:50.119603Z",
     "start_time": "2021-05-12T02:40:06.276644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6096 tensor([1777.7168], device='cuda:0', grad_fn=<DivBackward0>) 227547.75 0.0\n",
      "6858 tensor([1858.2067], device='cuda:0', grad_fn=<DivBackward0>) 237850.453125 0.0\n",
      "8763 tensor([1761.1691], device='cuda:0', grad_fn=<DivBackward0>) 225429.640625 0.0\n",
      "10414 tensor([1544.5771], device='cuda:0', grad_fn=<DivBackward0>) 197705.875 0.0\n",
      "11811 tensor([1490.6838], device='cuda:0', grad_fn=<DivBackward0>) 190807.53125 0.0\n",
      "17907 tensor([997.8778], device='cuda:0', grad_fn=<DivBackward0>) 127728.359375 0.0\n",
      "23114 tensor([445.6253], device='cuda:0', grad_fn=<DivBackward0>) 57040.03515625 0.0\n",
      "26416 tensor([211.5510], device='cuda:0', grad_fn=<DivBackward0>) 27078.5234375 0.0\n",
      "29337 tensor([60.0245], device='cuda:0', grad_fn=<DivBackward0>) 7682.90869140625 0.22330477833747864\n",
      "batch iteration 0\n",
      "batch_loss: 1140.04 \n",
      "\n",
      "2413 tensor([8.5556], device='cuda:0', grad_fn=<DivBackward0>) 1041.9896240234375 53.120887756347656\n",
      "3302 tensor([6.8046], device='cuda:0', grad_fn=<DivBackward0>) 821.4419555664062 49.543128967285156\n",
      "19050 tensor([3.0374], device='cuda:0', grad_fn=<DivBackward0>) 139.7335205078125 249.05014038085938\n",
      "20320 tensor([3.1549], device='cuda:0', grad_fn=<DivBackward0>) 162.7161865234375 241.1123504638672\n",
      "23241 tensor([3.0542], device='cuda:0', grad_fn=<DivBackward0>) 181.6903839111328 209.24888610839844\n",
      "batch iteration 1\n",
      "batch_loss: 4.70 \n",
      "\n",
      "8509 tensor([2.3861], device='cuda:0', grad_fn=<DivBackward0>) 99.86132049560547 205.55545043945312\n",
      "10541 tensor([2.5077], device='cuda:0', grad_fn=<DivBackward0>) 138.2119140625 182.77078247070312\n",
      "11684 tensor([1.8748], device='cuda:0', grad_fn=<DivBackward0>) 72.3040542602539 167.67042541503906\n",
      "13081 tensor([2.5191], device='cuda:0', grad_fn=<DivBackward0>) 154.1078338623047 168.34263610839844\n",
      "13716 tensor([1.7617], device='cuda:0', grad_fn=<DivBackward0>) 112.19902038574219 113.29273986816406\n",
      "15494 tensor([2.7899], device='cuda:0', grad_fn=<DivBackward0>) 164.97158813476562 192.13671875\n",
      "batch iteration 2\n",
      "batch_loss: 2.40 \n",
      "\n",
      "9017 tensor([1.8797], device='cuda:0', grad_fn=<DivBackward0>) 141.81932067871094 98.7876968383789\n",
      "18923 tensor([1.5257], device='cuda:0', grad_fn=<DivBackward0>) 94.55296325683594 100.73955535888672\n",
      "22606 tensor([1.6649], device='cuda:0', grad_fn=<DivBackward0>) 96.60076904296875 116.50304412841797\n",
      "27432 tensor([1.0866], device='cuda:0', grad_fn=<DivBackward0>) 45.85877990722656 93.22261810302734\n",
      "batch iteration 3\n",
      "batch_loss: 1.69 \n",
      "\n",
      "16891 tensor([0.5538], device='cuda:0', grad_fn=<DivBackward0>) 28.508710861206055 42.379493713378906\n",
      "17018 tensor([0.7027], device='cuda:0', grad_fn=<DivBackward0>) 40.18474197387695 49.76540756225586\n",
      "19304 tensor([0.4634], device='cuda:0', grad_fn=<DivBackward0>) 31.5196590423584 27.796789169311523\n",
      "27559 tensor([0.3438], device='cuda:0', grad_fn=<DivBackward0>) 15.839994430541992 28.17230987548828\n",
      "batch iteration 4\n",
      "batch_loss: 0.71 \n",
      "\n",
      "5080 tensor([0.3251], device='cuda:0', grad_fn=<DivBackward0>) 9.817215919494629 31.792434692382812\n",
      "6858 tensor([0.1739], device='cuda:0', grad_fn=<DivBackward0>) 14.854844093322754 7.408673286437988\n",
      "9906 tensor([0.1856], device='cuda:0', grad_fn=<DivBackward0>) 9.90469741821289 13.853025436401367\n",
      "10795 tensor([0.2042], device='cuda:0', grad_fn=<DivBackward0>) 6.676487922668457 19.457548141479492\n",
      "14859 tensor([0.1338], device='cuda:0', grad_fn=<DivBackward0>) 6.242018222808838 10.881775856018066\n",
      "21971 tensor([0.0691], device='cuda:0', grad_fn=<DivBackward0>) 2.7589902877807617 6.081936359405518\n",
      "22225 tensor([0.0864], device='cuda:0', grad_fn=<DivBackward0>) 2.3770313262939453 8.684020042419434\n",
      "22606 tensor([0.0958], device='cuda:0', grad_fn=<DivBackward0>) 6.727756023406982 5.539794445037842\n",
      "batch iteration 5\n",
      "batch_loss: 0.16 \n",
      "\n",
      "1397 tensor([0.1061], device='cuda:0', grad_fn=<DivBackward0>) 4.72808837890625 8.856132507324219\n",
      "5207 tensor([0.0486], device='cuda:0', grad_fn=<DivBackward0>) 1.5460864305496216 4.675889492034912\n",
      "10668 tensor([0.0341], device='cuda:0', grad_fn=<DivBackward0>) 1.0361565351486206 3.326591730117798\n",
      "16510 tensor([0.0200], device='cuda:0', grad_fn=<DivBackward0>) 0.8659021854400635 1.6960480213165283\n",
      "26543 tensor([0.0205], device='cuda:0', grad_fn=<DivBackward0>) 0.7416600584983826 1.883257269859314\n",
      "29210 tensor([0.0229], device='cuda:0', grad_fn=<DivBackward0>) 2.0118508338928223 0.9251382350921631\n",
      "batch iteration 6\n",
      "batch_loss: 0.04 \n",
      "\n",
      "5842 tensor([0.0174], device='cuda:0', grad_fn=<DivBackward0>) 0.4121665358543396 1.8213262557983398\n",
      "10033 tensor([0.0137], device='cuda:0', grad_fn=<DivBackward0>) 1.2668687105178833 0.4931127429008484\n",
      "22606 tensor([0.0112], device='cuda:0', grad_fn=<DivBackward0>) 0.8030133247375488 0.6259201765060425\n",
      "23876 tensor([0.0089], device='cuda:0', grad_fn=<DivBackward0>) 1.1077808141708374 0.028362881392240524\n",
      "26162 tensor([0.0102], device='cuda:0', grad_fn=<DivBackward0>) 0.09950768947601318 1.202232837677002\n",
      "29845 tensor([0.0059], device='cuda:0', grad_fn=<DivBackward0>) 0.13426071405410767 0.6216627955436707\n",
      "batch iteration 7\n",
      "batch_loss: 0.02 \n",
      "\n",
      "7747 tensor([0.0053], device='cuda:0', grad_fn=<DivBackward0>) 0.49915811419487 0.18046219646930695\n",
      "17272 tensor([0.0057], device='cuda:0', grad_fn=<DivBackward0>) 0.3688572347164154 0.36388421058654785\n",
      "17907 tensor([0.0074], device='cuda:0', grad_fn=<DivBackward0>) 0.4981938898563385 0.44631683826446533\n",
      "19177 tensor([0.0146], device='cuda:0', grad_fn=<DivBackward0>) 0.548826277256012 1.3255784511566162\n",
      "batch iteration 8\n",
      "batch_loss: 0.01 \n",
      "\n",
      "1143 tensor([0.0103], device='cuda:0', grad_fn=<DivBackward0>) 0.6243305802345276 0.6882478594779968\n",
      "5334 tensor([0.0061], device='cuda:0', grad_fn=<DivBackward0>) 0.09589863568544388 0.6872945427894592\n",
      "7239 tensor([0.0100], device='cuda:0', grad_fn=<DivBackward0>) 0.029739487916231155 1.2551628351211548\n",
      "21590 tensor([0.0052], device='cuda:0', grad_fn=<DivBackward0>) 0.0038748420774936676 0.660333514213562\n",
      "batch iteration 9\n",
      "batch_loss: 0.01 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(int(echo)):\n",
    "    # offender_types = []\n",
    "    # defender_types = []\n",
    "    \n",
    "    \n",
    "    X_train_list = []\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "    while(temp_number<len(training_data)-1):\n",
    "        loss2_list = []\n",
    "        loss1_sum = 0\n",
    "        loss2_sum = 0\n",
    "        denominator = 0\n",
    "        for index in range(temp_number, min(batch_size+temp_number,len(training_data))):\n",
    "            h_loss1,h_loss2,h_list = net(training_data[index],training_label[index])\n",
    "            denominator += 1\n",
    "            loss1_sum += h_loss1\n",
    "            loss2_sum += h_loss2\n",
    "            \n",
    "        loss_sum = loss1_sum + loss2_sum\n",
    "        loss = (loss_sum) / denominator \n",
    "        total_batch_loss +=float(loss_sum)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        temp_number = index\n",
    "        \n",
    "        if(random.random()<=0.02):\n",
    "            print(temp_number,loss,float(loss1_sum),float(loss2_sum))\n",
    "\n",
    "\n",
    "    print(\"batch iteration\", iteration)\n",
    "    print(\"batch_loss: %.2f \" % (total_batch_loss/len(training_data)))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T03:19:50.135651Z",
     "start_time": "2021-05-12T03:19:50.119603Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net, \"save/Deep_learning_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T03:20:41.990128Z",
     "start_time": "2021-05-12T03:19:50.137611Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = net.calculate(torch.tensor(testing_data[index][i]).cuda().type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list.append(sum(h_list)/testing_label[index])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T03:20:42.005290Z",
     "start_time": "2021-05-12T03:20:41.990128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.637315588864972 8.781236751794845 0.8560788370701271\n"
     ]
    }
   ],
   "source": [
    "print(max(result_list),min(result_list),max(result_list)-min(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T12:53:16.172008Z",
     "start_time": "2021-05-11T12:53:16.161037Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
