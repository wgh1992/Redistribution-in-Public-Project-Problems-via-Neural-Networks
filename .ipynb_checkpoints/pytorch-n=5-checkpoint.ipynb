{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T07:02:34.243972Z",
     "start_time": "2021-05-20T07:02:32.985933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The classic game of flappy bird. Make with python\n",
    "and pygame. Features pixel perfect collision using masks :o\n",
    "Date Modified:  Jul 30, 2019\n",
    "Author: Tech With Tim\n",
    "Estimated Work Time: 5 hours (1 just for that damn collision)\n",
    "\"\"\"\n",
    "import pygame\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm \n",
    "import matplotlib.cm as cm\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "print(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T07:02:34.259957Z",
     "start_time": "2021-05-20T07:02:34.245007Z"
    }
   },
   "outputs": [],
   "source": [
    "global target_order\n",
    "target_order = \"supervised\"\n",
    "global temp_list\n",
    "temp_list = []\n",
    "Agent_number_n=4;\n",
    "Alpha = (1-0.600);\n",
    "\n",
    "# torch.manual_seed(1)    # reproducible\n",
    "# np.random.seed(1)\n",
    "\n",
    "# Hyper Parameters\n",
    "BATCH_SIZE = 64\n",
    "LR_G = 0.00001           # learning rate for generator\n",
    "N_IDEAS = Agent_number_n             # think of this as number of ideas for generating an art work (Generator)\n",
    "ART_COMPONENTS = Agent_number_n     # it could be total point G can draw in the canvas\n",
    "PAINT_POINTS = np.vstack([np.linspace(-1, 1, ART_COMPONENTS) for _ in range(BATCH_SIZE)])\n",
    "\n",
    "\n",
    "GeneratorNet = nn.Sequential(                      # Generator\n",
    "    # random ideas (could from normal distribution)\n",
    "    nn.Linear(N_IDEAS, 128),\n",
    "    nn.ReLU(),\n",
    "    # making a painting from these random ideas\n",
    "    nn.Linear(128, ART_COMPONENTS),\n",
    ")\n",
    "#GeneratorNet = torch.load(\"save/GeneratorNet_4_1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.946Z"
    }
   },
   "outputs": [],
   "source": [
    "def appen(_x_list,y):\n",
    "    global temp_list\n",
    "    temp_list.append(_x_list)\n",
    "    \n",
    "def appen_train(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    \n",
    "    training_data.append(temp_list)\n",
    "    training_label.append(S)\n",
    "    \n",
    "\n",
    "def read_training_data():\n",
    "    for i in range(100000):\n",
    "        appen_train(np.random.rand(Agent_number_n));\n",
    "\n",
    "training_data=[]\n",
    "training_label=[]\n",
    "S=1.0\n",
    "read_training_data();\n",
    "\n",
    "def appen_test(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data.append(temp_list)\n",
    "    testing_label.append(S)\n",
    "    \n",
    "\n",
    "def read_testing_data():\n",
    "#     devided=20\n",
    "#     for i1 in range(devided+1):\n",
    "#         for i2 in range(i1+1):\n",
    "#             for i3 in range(i2+1):\n",
    "#                 appen_test(i1/devided,i2/devided,i3/devided);\n",
    "    for i in range(100000):\n",
    "        appen_test(np.random.rand(Agent_number_n));\n",
    "                            \n",
    "\n",
    "testing_data=[]\n",
    "testing_label=[]\n",
    "S=1.0\n",
    "read_testing_data();\n",
    "\n",
    "training_data=np.array(training_data)\n",
    "training_label=np.array(training_label)\n",
    "testing_data=np.array(testing_data)\n",
    "testing_label=np.array(testing_label)\n",
    "print(training_data)\n",
    "print(testing_data)\n",
    "print(training_label)\n",
    "print(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.947Z"
    }
   },
   "outputs": [],
   "source": [
    "def h_3_star(a, b, t):\n",
    "    return a - min(a, t) + b - min(b, t) + max(min(a, t)+min(b, t), 2*t/3) + 1/2 * max(min(a, t)+min(b, t), t) - 1/2 * max(max(min(a, t), min(b, t)), 2*t/3) - t/6\n",
    "\n",
    "\n",
    "def f_function(a, b, z):\n",
    "    if(z >= 1):\n",
    "        return (a+b)/2 + z/3\n",
    "    else:\n",
    "        return z/3 + h_3_star(a, b, 1-z)/2\n",
    "\n",
    "def h_function(input_list):\n",
    "    #input_list = sorted(input_list)\n",
    "    g_list = []\n",
    "    for j1 in range(len(input_list) ):\n",
    "        for j2 in range(len(input_list)):\n",
    "            if(j1 != j2):\n",
    "                a = input_list[j1]\n",
    "                b = input_list[j2]\n",
    "                z = sum(input_list)- a-b\n",
    "\n",
    "                g_list.append( f_function(a, b, z) * (Agent_number_n-1))\n",
    "    h = sum(g_list) * 3 /  (Agent_number_n) /  (Agent_number_n-1) /  (Agent_number_n - 2)\n",
    "    return h\n",
    "                \n",
    "                \n",
    "x_list = []\n",
    "y_list = []\n",
    "z_list = []\n",
    "result_list = []\n",
    "training_supervised_label=[]\n",
    "for index in range(len(training_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        x_list.append(training_data[index][i][0])\n",
    "        y_list.append(training_data[index][i][1])\n",
    "        h = h_function(training_data[index][i])\n",
    "        z_list.append(float(h))\n",
    "        h_list.append(float(h))\n",
    "    training_supervised_label.append(h_list)\n",
    "    result_list.append(sum(h_list)/training_label[index]) \n",
    "    \n",
    "    \n",
    "print(max(result_list), min(result_list), max(result_list)-min(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.948Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.949Z"
    }
   },
   "outputs": [],
   "source": [
    "training_supervised_label=np.array(training_supervised_label)\n",
    "print(training_supervised_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.951Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight, gain=1.0)\n",
    "        torch.nn.init.uniform_(m.bias, a=-1.0, b=1.0)\n",
    "        \n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        num_input = Agent_number_n-1\n",
    "        num_hidden = 100\n",
    "        num_output = 1\n",
    "\n",
    "        self.hidden_0 = torch.nn.Linear(num_input, num_hidden)\n",
    "        self.hidden_1 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_2 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_3 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_4 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_5 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_6 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_7 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_8 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.output_allocation = torch.nn.Linear(num_hidden, num_output)\n",
    "\n",
    "    def calculate(self, value_list):\n",
    "        h1 = torch.relu(self.hidden_0(value_list))\n",
    "        h2 = torch.relu(self.hidden_1(h1))\n",
    "        h3 = torch.relu(self.hidden_2(h2))\n",
    "        h4 = torch.relu(self.hidden_3(h3))\n",
    "        h5 = torch.relu(self.hidden_4(h4))\n",
    "        h6 = torch.relu(self.hidden_5(h5))\n",
    "        h7 = torch.relu(self.hidden_6(h6))\n",
    "        h8 = torch.relu(self.hidden_7(h7))\n",
    "        h9 = torch.relu(self.hidden_8(h8))\n",
    "        h = torch.relu(self.output_allocation(h9))\n",
    "\n",
    "        return h\n",
    "\n",
    "    def forward(self, input_list,input_label,label):\n",
    "        global iteration,echo,target_order\n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        h_list = []\n",
    "\n",
    "        if (target_order == \"supervised\"):\n",
    "            loss = 0 \n",
    "            for i in range(Agent_number_n):\n",
    "                h = self.calculate(input_list[i])\n",
    "                loss += torch.square(h - label[i])\n",
    "                h_list.append(h)\n",
    "            return loss\n",
    "        else:\n",
    "            for i in range(Agent_number_n):\n",
    "                h = self.calculate(input_list[i])\n",
    "                h_list.append(h)\n",
    "                \n",
    "            sum_h = torch.sum(torch.cat(h_list)).cuda()\n",
    "\n",
    "\n",
    "            loss1 = torch.where((Agent_number_n-1)*input_label>sum_h,\n",
    "                            torch.square((Agent_number_n-1)*input_label-sum_h)*1000,\n",
    "                            torch.zeros(1).cuda()\n",
    "                          )\n",
    "\n",
    "            loss2 = torch.where((Agent_number_n-Alpha)*input_label<sum_h,\n",
    "                            torch.square(sum_h-(Agent_number_n-Alpha)*input_label)*1000,\n",
    "                            torch.zeros(1).cuda()\n",
    "                          )\n",
    "\n",
    "            return loss1,loss2,h_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.952Z"
    }
   },
   "outputs": [],
   "source": [
    "def redistribution_value_function(input_tensor):\n",
    "    S = torch.max(torch.sum(input_tensor), torch.ones(1))\n",
    "    temp_list = []\n",
    "\n",
    "\n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        \n",
    "        for j in range(Agent_number_n):\n",
    "            if(i != j):\n",
    "                temp .append(input_tensor[j])\n",
    "                \n",
    "        temp = torch.stack(temp)\n",
    "        temp_list.append(temp)\n",
    "    return torch.stack(temp_list), S\n",
    "\n",
    "def Generator(GeneratorNet,DiscriminatorNet):\n",
    "\n",
    "    opt_G = torch.optim.Adam(GeneratorNet.parameters(), lr=LR_G)\n",
    "\n",
    "\n",
    "    DiscriminatorNet.requires_grad = False\n",
    "\n",
    "    show_list = []\n",
    "    for step in range(51):\n",
    "        # real painting from artist\n",
    "        G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                              requires_grad=True)  # random ideas\\n\n",
    "        # fake painting from G (random ideas)\n",
    "        G_values = GeneratorNet(G_ideas)\n",
    "    #     print(artist_paintings)\n",
    "    #     print(G_paintings)\n",
    "\n",
    "        result_list = []\n",
    "        for index in range(BATCH_SIZE):\n",
    "            h_list = []\n",
    "            value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                G_values[index])\n",
    "            for i in range(Agent_number_n):\n",
    "                h = DiscriminatorNet.calculate(\n",
    "                    value_list_tensor[i].cuda().type(torch.float32))\n",
    "                h_list.append(h)\n",
    "            h_list = torch.stack(h_list)\n",
    "            result_list.append(torch.sum(h_list)/S_tensor.cuda())\n",
    "            show_list.append(float(torch.sum(h_list)/S_tensor.cuda()))\n",
    "        result_list = torch.stack(result_list)\n",
    "\n",
    "        diff_loss = torch.max(result_list)-torch.min(result_list)\n",
    "        G_loss = torch.max(- diff_loss)\n",
    "\n",
    "        opt_G.zero_grad()\n",
    "        G_loss.backward()\n",
    "        opt_G.step()\n",
    "\n",
    "        if step % 50 == 0 and step != 0:  # plotting\n",
    "\n",
    "\n",
    "            print(max(show_list), min(show_list),\n",
    "                  max(show_list)-min(show_list))\n",
    "\n",
    "            plt.hist(show_list, bins=500)\n",
    "\n",
    "            plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "            plt.axvline(x=sum(show_list)/len(show_list), linestyle='--',\n",
    "                        linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "            plt.xlabel(\"samples\", labelpad=14)\n",
    "            plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "            plt.legend()\n",
    "\n",
    "            show_list.sort()\n",
    "            show_list = []\n",
    "            plt.show()\n",
    "    torch.save(GeneratorNet , \"save/GeneratorNet_4\") \n",
    "    \n",
    "    DiscriminatorNet.requires_grad = True\n",
    "    return GeneratorNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.953Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "net  = Net()\n",
    "net.apply(weight_init)\n",
    "\n",
    "net = torch.load(\"save/Deep_learning_4\")\n",
    "net.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.954Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#optimizer = opt.RMSprop(net.parameters(), lr=0.00001)\n",
    "#optimizer = opt.SGD(net.parameters(), lr=0.00001)\n",
    "optimizer = opt.Adam(net.parameters(), lr=0.00005)\n",
    "\n",
    "batch_size = 64\n",
    "echo = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.956Z"
    }
   },
   "outputs": [],
   "source": [
    "target_order = \"supervised\"\n",
    "for iteration in range(int(echo)):\n",
    "    # offender_types = []\n",
    "    # defender_types = []\n",
    "    \n",
    "    \n",
    "    X_train_list = []\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "    while(temp_number<len(training_data)-1):\n",
    "        loss_sum = 0\n",
    "        denominator = 0\n",
    "        for index in range(temp_number, min(batch_size+temp_number,len(training_data))):\n",
    "            h_loss = net(torch.from_numpy(\n",
    "            np.array(training_data[index])).cuda().type(torch.float32),training_label[index],training_supervised_label[index])\n",
    "            denominator += 1\n",
    "            loss_sum += h_loss\n",
    "            \n",
    "        loss = (loss_sum) / denominator \n",
    "        total_batch_loss +=float(loss_sum)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        temp_number = index\n",
    "        \n",
    "        if(random.random()<=0.01):\n",
    "            print(temp_number,loss,float(loss_sum))\n",
    "\n",
    "\n",
    "    print(\"batch iteration\", iteration)\n",
    "    print(\"batch_loss: %.2f \" % (total_batch_loss/len(training_data)))\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.957Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = net.calculate(torch.tensor(testing_data[index][i]).cuda().type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list.append(sum(h_list)/testing_label[index])\n",
    "    \n",
    "\n",
    "print(max(result_list),min(result_list),max(result_list)-min(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.959Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.001)], linestyle='--', linewidth=0.5, label=\"0.1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.999)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.960Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net, \"save/Deep_learning_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.961Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#optimizer = opt.RMSprop(net.parameters(), lr=0.00001)\n",
    "#optimizer = opt.SGD(net.parameters(), lr=0.00005)\n",
    "optimizer = opt.Adam(net.parameters(), lr=0.000001)\n",
    "\n",
    "batch_size = 64\n",
    "echo = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.962Z"
    }
   },
   "outputs": [],
   "source": [
    "target_order = \"unsupervised\"\n",
    "for iteration in range(int(echo)):\n",
    "    # offender_types = []\n",
    "    # defender_types = []\n",
    "\n",
    "    GeneratorNet = Generator(GeneratorNet, net)\n",
    "\n",
    "    X_train_list = []\n",
    "    total_batch_loss = 0\n",
    "    for i in range(101):\n",
    "\n",
    "        G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                              requires_grad=True)\n",
    "        G_values = GeneratorNet(G_ideas)\n",
    "\n",
    "        loss1_sum = 0\n",
    "        loss2_sum = 0\n",
    "\n",
    "        for index in range(BATCH_SIZE):\n",
    "            h_list = []\n",
    "            value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                G_values[index])\n",
    "\n",
    "            h_loss1, h_loss2, h_list = net(\n",
    "                value_list_tensor.cuda().type(torch.float32), S_tensor.cuda(), 0)\n",
    "            loss1_sum += h_loss1\n",
    "            loss2_sum += h_loss2\n",
    "\n",
    "        loss_sum = loss1_sum + loss2_sum\n",
    "        loss = (loss_sum) / BATCH_SIZE\n",
    "        total_batch_loss += float(loss_sum)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if(random.random() <= 0.01):\n",
    "            print(i, loss, float(loss1_sum), float(loss2_sum))\n",
    "\n",
    "    print(iteration, \"batch iteration\", iteration)\n",
    "    print(\"batch_loss: %.2f \" % (total_batch_loss/len(training_data)))\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "for iteration in range(int(echo)):\n",
    "    # offender_types = []\n",
    "    # defender_types = []\n",
    "\n",
    "    X_train_list = []\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0\n",
    "    while(temp_number < len(training_data)-1):\n",
    "\n",
    "        loss2_list = []\n",
    "        loss1_sum = 0\n",
    "        loss2_sum = 0\n",
    "        denominator = 0\n",
    "        for index in range(temp_number, min(batch_size+temp_number, len(training_data))):\n",
    "            h_loss1, h_loss2, h_list = net(\n",
    "                torch.from_numpy(\n",
    "                    np.array(\n",
    "                        training_data[index])).cuda().type(torch.float32), training_label[index], 0)\n",
    "            denominator += 1\n",
    "            loss1_sum += h_loss1\n",
    "            loss2_sum += h_loss2\n",
    "\n",
    "        loss_sum = loss1_sum + loss2_sum\n",
    "        loss = (loss_sum) / denominator\n",
    "        total_batch_loss += float(loss_sum)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        temp_number = index\n",
    "\n",
    "        if(random.random() <= 0.01):\n",
    "            print(temp_number, loss, float(loss1_sum), float(loss2_sum))\n",
    "\n",
    "    print(\"batch iteration\", iteration)\n",
    "    print(\"batch_loss: %.2f \" % (total_batch_loss/len(training_data)))\n",
    "\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.963Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net, \"save/Deep_learning_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.964Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = net.calculate(torch.tensor(testing_data[index][i]).cuda().type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list.append(sum(h_list)/testing_label[index])\n",
    "    \n",
    "\n",
    "print(max(result_list),min(result_list),max(result_list)-min(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-20T07:02:32.965Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.001)], linestyle='--', linewidth=0.5, label=\"0.1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.999)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
