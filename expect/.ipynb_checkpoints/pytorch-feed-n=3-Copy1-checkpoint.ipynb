{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:03:48.821043Z",
     "start_time": "2021-06-06T04:03:47.016126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pygame\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm \n",
    "import matplotlib.cm as cm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy.interpolate import griddata\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "print(dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:03:48.836977Z",
     "start_time": "2021-06-06T04:03:48.823010Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "global temp_list\n",
    "temp_list = []\n",
    "Agent_number_n=3;\n",
    "Alpha = 1.0;\n",
    "\n",
    "echo = 5\n",
    "BATCH_SIZE = 16\n",
    "LR = 0.001           # learning rate for generator\n",
    "Prior_Distribution = \"uniform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:03:48.868915Z",
     "start_time": "2021-06-06T04:03:48.838967Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "uniformlow = 0\n",
    "uniformhigh = 1.0\n",
    "\n",
    "normalloc = 0.2\n",
    "normalscale = 0.1\n",
    "\n",
    "doublePeakHighMean = 0.9\n",
    "doublePeakLowMean = 0.1\n",
    "doublePeakStd = 0.04\n",
    "\n",
    "beta_a = 0.3\n",
    "beta_b = 0.2\n",
    "\n",
    "d_1 = D.uniform.Uniform(uniformlow, uniformhigh)\n",
    "distributionRatio_1 = d_1.cdf(1) - d_1.cdf(0)\n",
    "distributionBase_1 = d_1.cdf(0)\n",
    "\n",
    "d_2 = D.normal.Normal(normalloc, normalscale)\n",
    "distributionRatio_2 = d_2.cdf(1) - d_2.cdf(0)\n",
    "distributionBase_2 = d_2.cdf(0)\n",
    "\n",
    "d_3 = D.normal.Normal(doublePeakLowMean, doublePeakStd)\n",
    "d_4 = D.normal.Normal(doublePeakHighMean, doublePeakStd)\n",
    "distributionRatio_3 = (d_3.cdf(1) + d_4.cdf(1) - d_3.cdf(0) - d_4.cdf(0)) / 2\n",
    "distributionBase_3 = d_3.cdf(0) + d_4.cdf(0)\n",
    "\n",
    "# d_5 = D.beta.Beta(beta_a,beta_b)\n",
    "\n",
    "# d10 = D.beta.Beta(0.5,0.5)\n",
    "\n",
    "\n",
    "def cdf(x, y, i=None):\n",
    "    if (y == \"uniform\"):\n",
    "        return (d_1.cdf(x) - distributionBase_1) / distributionRatio_1\n",
    "    elif (y == \"normal\"):\n",
    "        return (d_2.cdf(x) - distributionBase_2) / distributionRatio_2\n",
    "    elif (y == \"twopeak\"):\n",
    "        return (d_3.cdf(x) + d_4.cdf(x) -\n",
    "                distributionBase_3) / 2 / distributionRatio_3\n",
    "\n",
    "\n",
    "def pdf(x, y, i=None):\n",
    "    x= x.cpu()\n",
    "    if (y == \"uniform\"):\n",
    "        return torch.pow(torch.tensor(10), d_1.log_prob(x)).to(dev)\n",
    "    elif (y == \"normal\"):\n",
    "        return torch.pow(torch.tensor(10), d_2.log_prob(x)).to(dev)\n",
    "    elif (y == \"twopeak\"):\n",
    "        return (torch.pow(torch.tensor(10), d_3.log_prob(x)) +\n",
    "                torch.pow(torch.tensor(10), d_4.log_prob(x))).to(dev) / 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:03:50.078225Z",
     "start_time": "2021-06-06T04:03:48.869885Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10, device='cuda:0')\n",
      "tensor([1.], device='cuda:0')\n",
      "tensor([24.1906], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor(10).to(dev))\n",
    "print(pdf(torch.ones(1)*0.2,\"uniform\"))\n",
    "print(pdf(torch.ones(1)*0.2,\"normal\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:03:51.024693Z",
     "start_time": "2021-06-06T04:03:50.080220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.44344255 0.17784889]\n",
      "  [0.86300363 0.17784889]\n",
      "  [0.86300363 0.44344255]]\n",
      "\n",
      " [[0.11702261 0.08401195]\n",
      "  [0.52158693 0.08401195]\n",
      "  [0.52158693 0.11702261]]\n",
      "\n",
      " [[0.29610475 0.22531622]\n",
      "  [0.40483584 0.22531622]\n",
      "  [0.40483584 0.29610475]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.4929824  0.12847013]\n",
      "  [0.91063239 0.12847013]\n",
      "  [0.91063239 0.4929824 ]]\n",
      "\n",
      " [[0.37334859 0.20785783]\n",
      "  [0.9944724  0.20785783]\n",
      "  [0.9944724  0.37334859]]\n",
      "\n",
      " [[0.48467894 0.33498441]\n",
      "  [0.95015279 0.33498441]\n",
      "  [0.95015279 0.48467894]]]\n",
      "[[0.86300363 0.44344255 0.17784889]\n",
      " [0.52158693 0.11702261 0.08401195]\n",
      " [0.40483584 0.29610475 0.22531622]\n",
      " ...\n",
      " [0.91063239 0.4929824  0.12847013]\n",
      " [0.9944724  0.37334859 0.20785783]\n",
      " [0.95015279 0.48467894 0.33498441]]\n",
      "[[[0.1969534  0.08746709]\n",
      "  [0.7800463  0.08746709]\n",
      "  [0.7800463  0.1969534 ]]\n",
      "\n",
      " [[0.90325906 0.78600775]\n",
      "  [0.92024649 0.78600775]\n",
      "  [0.92024649 0.90325906]]\n",
      "\n",
      " [[0.75640293 0.61761381]\n",
      "  [0.8692856  0.61761381]\n",
      "  [0.8692856  0.75640293]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.94331615 0.35086223]\n",
      "  [0.98716843 0.35086223]\n",
      "  [0.98716843 0.94331615]]\n",
      "\n",
      " [[0.3656785  0.3568736 ]\n",
      "  [0.6985472  0.3568736 ]\n",
      "  [0.6985472  0.3656785 ]]\n",
      "\n",
      " [[0.69100089 0.64935343]\n",
      "  [0.92245571 0.64935343]\n",
      "  [0.92245571 0.69100089]]]\n",
      "[1.48429508 1.         1.         ... 1.53208492 1.57567882 1.76981613]\n",
      "[1.06446679 2.6095133  2.24330234 ... 2.28134681 1.42109931 2.26281003]\n"
     ]
    }
   ],
   "source": [
    "def appen(_x_list,y):\n",
    "    global temp_list\n",
    "    temp_list.append(_x_list)\n",
    "    \n",
    "def appen_train(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    \n",
    "    training_data.append(temp_list)\n",
    "    training_data_all.append(x_list)\n",
    "    training_label.append(S)\n",
    "    \n",
    "\n",
    "def read_training_data():\n",
    "    for i in range(50000):\n",
    "        appen_train(sorted(np.random.rand(Agent_number_n), reverse=True));\n",
    "\n",
    "training_data=[]\n",
    "training_data_all=[]\n",
    "training_label=[]\n",
    "S=1.0\n",
    "read_training_data();\n",
    "\n",
    "def appen_test(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data.append(temp_list)\n",
    "    testing_label.append(S)\n",
    "    \n",
    "\n",
    "def read_testing_data():\n",
    "    for i in range(10000):\n",
    "        appen_test(sorted(np.random.rand(Agent_number_n), reverse=True));\n",
    "                            \n",
    "\n",
    "testing_data=[]\n",
    "testing_label=[]\n",
    "S=1.0\n",
    "read_testing_data();\n",
    "\n",
    "training_data=np.array(training_data)\n",
    "training_data_all=np.array(training_data_all)\n",
    "training_label=np.array(training_label)\n",
    "testing_data=np.array(testing_data)\n",
    "testing_label=np.array(testing_label)\n",
    "print(training_data)\n",
    "print(training_data_all)\n",
    "print(testing_data)\n",
    "print(training_label)\n",
    "print(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:03:54.939820Z",
     "start_time": "2021-06-06T04:03:51.026687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.333295388697357 2.0 0.3332953886973571 2.1017551098958442\n"
     ]
    }
   ],
   "source": [
    "def h_3_star(a, b, t):\n",
    "    return a - min(a, t) + b - min(b, t) + max(min(a, t)+min(b, t), 2*t/3) + 1/2 * max(min(a, t)+min(b, t), t) - 1/2 * max(max(min(a, t), min(b, t)), 2*t/3) - t/6\n",
    "\n",
    "\n",
    "def f_function(a, b, z):\n",
    "    if(z >= 1):\n",
    "        return (a+b)/2 + z/3\n",
    "    else:\n",
    "        return z/3 + h_3_star(a, b, 1-z)/2\n",
    "\n",
    "def h_function(input_list):\n",
    "    #input_list = sorted(input_list)\n",
    "    g_list = []\n",
    "    for j1 in range(len(input_list) ):\n",
    "        for j2 in range(len(input_list)):\n",
    "            if(j1 != j2):\n",
    "                a = input_list[j1]\n",
    "                b = input_list[j2]\n",
    "                z = sum(input_list)- a-b\n",
    "\n",
    "                g_list.append( f_function(a, b, z) * (Agent_number_n-1))\n",
    "    h = sum(g_list) * 3 /  (Agent_number_n) /  (Agent_number_n-1) /  (Agent_number_n - 2)\n",
    "    return h\n",
    "                \n",
    "                \n",
    "x_list = []\n",
    "y_list = []\n",
    "z_list = []\n",
    "result_list = []\n",
    "training_supervised_label=[]\n",
    "for index in range(len(training_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        x_list.append(training_data[index][i][0])\n",
    "        y_list.append(training_data[index][i][1])\n",
    "        h = h_function(training_data[index][i])\n",
    "        z_list.append(float(h))\n",
    "        h_list.append(float(h))\n",
    "    training_supervised_label.append(h_list)\n",
    "    result_list.append(sum(h_list)/training_label[index]) \n",
    "    \n",
    "    \n",
    "print(max(result_list), min(result_list), max(result_list)-min(result_list),sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:03:56.062683Z",
     "start_time": "2021-06-06T04:03:54.943810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:03:56.140600Z",
     "start_time": "2021-06-06T04:03:56.065649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.66666667 0.9631103  1.36150079]\n",
      " [0.66666667 0.66666667 0.66666667]\n",
      " [0.66666667 0.66666667 0.70094059]\n",
      " ...\n",
      " [0.66666667 0.93667091 1.48343933]\n",
      " [0.66666667 1.13959247 1.38782862]\n",
      " [0.81966335 1.28596273 1.51050453]]\n",
      "tensor([0.3176], device='cuda:0', grad_fn=<SortBackward>)\n"
     ]
    }
   ],
   "source": [
    "training_supervised_label=np.array(training_supervised_label)\n",
    "print(training_supervised_label)\n",
    "devided_number = 1\n",
    "tensor_sample_list,indices = torch.sort(torch.rand(devided_number,requires_grad=True).to(dev))  # random ideas\\n\n",
    "print(tensor_sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:03:56.156556Z",
     "start_time": "2021-06-06T04:03:56.142593Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3176], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([0.8775], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(cdf(tensor_sample_list,Prior_Distribution))\n",
    "print(cdf(tensor_sample_list,\"normal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:03:56.188470Z",
     "start_time": "2021-06-06T04:03:56.158551Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.normal_(m.bias, mean=0.0, std=0.01)\n",
    "\n",
    "\n",
    "\n",
    "def redistribution_value_function(input_tensor):\n",
    "    S = torch.max(torch.sum(input_tensor), torch.ones(1).to(dev))\n",
    "    temp_list = []\n",
    "\n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i != j):\n",
    "                temp .append(input_tensor[j])\n",
    "\n",
    "        temp = torch.stack(temp)\n",
    "        temp_list.append(temp)\n",
    "    return torch.stack(temp_list), S\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.input_dim = (Agent_number_n-1)\n",
    "        self.hidden_dim = 100\n",
    "        self.output_dim = 1\n",
    "        self.hidden_layer_count = 6\n",
    "\n",
    "        current_dim = self.input_dim\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(self.hidden_layer_count):\n",
    "            self.layers.append(torch.nn.Linear(current_dim, self.hidden_dim))\n",
    "            current_dim = self.hidden_dim\n",
    "        self.layers.append(torch.nn.Linear(current_dim, self.output_dim))\n",
    "\n",
    "    def calculate(self, value_list):\n",
    "        h = value_list\n",
    "        for layer in self.layers:\n",
    "            h = torch.relu(layer(h))\n",
    "        return h\n",
    "\n",
    "    def forward(self, input_list, input_label, input_data):\n",
    "        global iteration, echo, target_order\n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).to(dev).type(torch.float32)\n",
    "        h_list = []\n",
    "\n",
    "        input_data = torch.from_numpy(\n",
    "            np.array(input_data)).to(dev).type(torch.float32)\n",
    "\n",
    "        random_index = random.randint(0, Agent_number_n-1)\n",
    "#         tensor_sample_list,indices = torch.sort(torch.rand(devided_number,requires_grad=True).to(dev))\n",
    "#         tensor_sample_list.to(dev) \n",
    "        tensor_sample_list = torch.rand(devided_number,requires_grad=True).to(dev)\n",
    "        temp_result_list = []\n",
    "        for enumerate_x in range(devided_number):\n",
    "            h_list = []\n",
    "            input_data_temp = input_data.detach().clone()\n",
    "\n",
    "            input_data_temp[random_index] = tensor_sample_list[enumerate_x]\n",
    "\n",
    "            value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                input_data_temp)\n",
    "\n",
    "            for i in range(Agent_number_n):\n",
    "                h = net.calculate(\n",
    "                    value_list_tensor[i].to(dev).type(torch.float32))\n",
    "                h_list.append(h)\n",
    "            h_list = torch.stack(h_list)\n",
    "            S_tensor = S_tensor.to(dev)\n",
    "            sum_h = torch.sum(h_list)\n",
    "\n",
    "            temp_loss1 = torch.where((Agent_number_n-1)*S_tensor > sum_h,\n",
    "                     torch.square(((Agent_number_n-1)*S_tensor-sum_h)),\n",
    "                     torch.zeros(1).to(dev)\n",
    "                  )\n",
    "            \n",
    "            temp_loss2 = torch.where((Agent_number_n-Alpha)*S_tensor<sum_h,\n",
    "                        torch.square((sum_h-(Agent_number_n-Alpha)*S_tensor))/10000,\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "\n",
    "            loss1 += temp_loss1 * pdf(tensor_sample_list[enumerate_x], Prior_Distribution)\n",
    "            loss2 += temp_loss2 * pdf(tensor_sample_list[enumerate_x], Prior_Distribution)\n",
    "                \n",
    "        return loss1, loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:03:56.204428Z",
     "start_time": "2021-06-06T04:03:56.190466Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "net  = Net()\n",
    "net.apply(weight_init)\n",
    "\n",
    "#net = torch.load(\"save/Deep_learning_F_3\")\n",
    "net.to(dev)\n",
    "\n",
    "#optimizer = opt.RMSprop(net.parameters(), lr=0.00001)\n",
    "#optimizer = opt.SGD(net.parameters(), lr=0.00005)\n",
    "optimizer = opt.Adam(net.parameters(), lr=LR)\n",
    "#optimizer = opt.Adadelta(net.parameters(), lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:10:16.739694Z",
     "start_time": "2021-06-06T04:03:56.207419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510 tensor(9.3587, device='cuda:0', grad_fn=<DivBackward0>) 149.73997497558594 0.0\n",
      "720 tensor(13.3204, device='cuda:0', grad_fn=<DivBackward0>) 213.12696838378906 0.0\n",
      "750 tensor(9.3252, device='cuda:0', grad_fn=<DivBackward0>) 149.2025604248047 0.0\n",
      "5325 tensor(11.4661, device='cuda:0', grad_fn=<DivBackward0>) 183.4579620361328 0.0\n",
      "5640 tensor(7.5635, device='cuda:0', grad_fn=<DivBackward0>) 121.01600646972656 0.0\n",
      "7380 tensor(8.9068, device='cuda:0', grad_fn=<DivBackward0>) 142.50836181640625 0.0\n",
      "8070 tensor(11.6386, device='cuda:0', grad_fn=<DivBackward0>) 186.21766662597656 0.0\n",
      "8340 tensor(10.2648, device='cuda:0', grad_fn=<DivBackward0>) 164.23756408691406 0.0\n",
      "9540 tensor(9.0757, device='cuda:0', grad_fn=<DivBackward0>) 145.210693359375 0.0\n",
      "10845 tensor(10.0673, device='cuda:0', grad_fn=<DivBackward0>) 161.07672119140625 0.0\n",
      "13230 tensor(8.6497, device='cuda:0', grad_fn=<DivBackward0>) 138.39556884765625 0.0\n",
      "17460 tensor(13.0720, device='cuda:0', grad_fn=<DivBackward0>) 209.15199279785156 0.0\n",
      "18750 tensor(10.0300, device='cuda:0', grad_fn=<DivBackward0>) 160.47946166992188 0.0\n",
      "19965 tensor(12.8803, device='cuda:0', grad_fn=<DivBackward0>) 206.0843505859375 0.0\n",
      "20625 tensor(11.8489, device='cuda:0', grad_fn=<DivBackward0>) 189.58251953125 0.0\n",
      "20700 tensor(8.1442, device='cuda:0', grad_fn=<DivBackward0>) 130.30703735351562 0.0\n",
      "22260 tensor(10.4326, device='cuda:0', grad_fn=<DivBackward0>) 166.92172241210938 0.0\n",
      "23700 tensor(8.2764, device='cuda:0', grad_fn=<DivBackward0>) 132.42311096191406 0.0\n",
      "25020 tensor(11.9540, device='cuda:0', grad_fn=<DivBackward0>) 191.26475524902344 0.0\n",
      "27945 tensor(10.7179, device='cuda:0', grad_fn=<DivBackward0>) 171.48670959472656 0.0\n",
      "31140 tensor(14.0296, device='cuda:0', grad_fn=<DivBackward0>) 224.4740753173828 0.0\n",
      "32445 tensor(9.8122, device='cuda:0', grad_fn=<DivBackward0>) 156.9944610595703 0.0\n",
      "32490 tensor(8.1680, device='cuda:0', grad_fn=<DivBackward0>) 130.68780517578125 0.0\n",
      "32985 tensor(10.6054, device='cuda:0', grad_fn=<DivBackward0>) 169.6863250732422 0.0\n",
      "34560 tensor(10.9819, device='cuda:0', grad_fn=<DivBackward0>) 175.710205078125 0.0\n",
      "35115 tensor(9.4608, device='cuda:0', grad_fn=<DivBackward0>) 151.3724365234375 0.0\n",
      "36150 tensor(10.5263, device='cuda:0', grad_fn=<DivBackward0>) 168.4209442138672 0.0\n",
      "36375 tensor(10.0909, device='cuda:0', grad_fn=<DivBackward0>) 161.45428466796875 0.0\n",
      "37065 tensor(12.9058, device='cuda:0', grad_fn=<DivBackward0>) 206.4926300048828 0.0\n",
      "37170 tensor(11.6581, device='cuda:0', grad_fn=<DivBackward0>) 186.5290985107422 0.0\n",
      "38880 tensor(8.6870, device='cuda:0', grad_fn=<DivBackward0>) 138.99266052246094 0.0\n",
      "42090 tensor(10.1567, device='cuda:0', grad_fn=<DivBackward0>) 162.5067596435547 0.0\n",
      "44295 tensor(10.6928, device='cuda:0', grad_fn=<DivBackward0>) 171.08477783203125 0.0\n",
      "45180 tensor(9.8008, device='cuda:0', grad_fn=<DivBackward0>) 156.8126220703125 0.0\n",
      "45645 tensor(11.2764, device='cuda:0', grad_fn=<DivBackward0>) 180.42251586914062 0.0\n",
      "47595 tensor(11.1848, device='cuda:0', grad_fn=<DivBackward0>) 178.9574432373047 0.0\n",
      "47730 tensor(11.3037, device='cuda:0', grad_fn=<DivBackward0>) 180.8593292236328 0.0\n",
      "48675 tensor(10.5989, device='cuda:0', grad_fn=<DivBackward0>) 169.58311462402344 0.0\n",
      "49215 tensor(10.9971, device='cuda:0', grad_fn=<DivBackward0>) 175.95388793945312 0.0\n",
      "batch iteration 0\n",
      "batch_loss: 10.94 \n",
      "\n",
      "\n",
      "1605 tensor(9.4843, device='cuda:0', grad_fn=<DivBackward0>) 151.7490692138672 0.0\n",
      "2820 tensor(12.2002, device='cuda:0', grad_fn=<DivBackward0>) 195.20387268066406 0.0\n",
      "4260 tensor(8.9459, device='cuda:0', grad_fn=<DivBackward0>) 143.13519287109375 0.0\n",
      "5010 tensor(10.3424, device='cuda:0', grad_fn=<DivBackward0>) 165.4780731201172 0.0\n",
      "7605 tensor(11.4176, device='cuda:0', grad_fn=<DivBackward0>) 182.68125915527344 0.0\n",
      "7920 tensor(10.1452, device='cuda:0', grad_fn=<DivBackward0>) 162.3226776123047 0.0\n",
      "8895 tensor(9.8570, device='cuda:0', grad_fn=<DivBackward0>) 157.71185302734375 0.0\n",
      "9975 tensor(10.3398, device='cuda:0', grad_fn=<DivBackward0>) 165.43692016601562 0.0\n",
      "12360 tensor(13.1275, device='cuda:0', grad_fn=<DivBackward0>) 210.04054260253906 0.0\n",
      "14640 tensor(9.5896, device='cuda:0', grad_fn=<DivBackward0>) 153.43280029296875 0.0\n",
      "17025 tensor(10.2137, device='cuda:0', grad_fn=<DivBackward0>) 163.41973876953125 0.0\n",
      "20295 tensor(10.8388, device='cuda:0', grad_fn=<DivBackward0>) 173.42112731933594 0.0\n",
      "23415 tensor(10.3834, device='cuda:0', grad_fn=<DivBackward0>) 166.13406372070312 0.0\n",
      "23595 tensor(9.7425, device='cuda:0', grad_fn=<DivBackward0>) 155.8803253173828 0.0\n",
      "23700 tensor(11.2542, device='cuda:0', grad_fn=<DivBackward0>) 180.06787109375 0.0\n",
      "23805 tensor(9.9987, device='cuda:0', grad_fn=<DivBackward0>) 159.97970581054688 0.0\n",
      "25515 tensor(11.4374, device='cuda:0', grad_fn=<DivBackward0>) 182.9990234375 0.0\n",
      "27060 tensor(10.9948, device='cuda:0', grad_fn=<DivBackward0>) 175.91693115234375 0.0\n",
      "27885 tensor(7.1807, device='cuda:0', grad_fn=<DivBackward0>) 114.89148712158203 0.0\n",
      "28530 tensor(8.4275, device='cuda:0', grad_fn=<DivBackward0>) 134.8401641845703 0.0\n",
      "31560 tensor(9.8138, device='cuda:0', grad_fn=<DivBackward0>) 157.02114868164062 0.0\n",
      "31800 tensor(10.8562, device='cuda:0', grad_fn=<DivBackward0>) 173.69981384277344 0.0\n",
      "34020 tensor(11.5798, device='cuda:0', grad_fn=<DivBackward0>) 185.27684020996094 0.0\n",
      "34155 tensor(8.7755, device='cuda:0', grad_fn=<DivBackward0>) 140.4084014892578 0.0\n",
      "34920 tensor(10.9537, device='cuda:0', grad_fn=<DivBackward0>) 175.25865173339844 0.0\n",
      "37305 tensor(10.1091, device='cuda:0', grad_fn=<DivBackward0>) 161.74594116210938 0.0\n",
      "39060 tensor(8.8391, device='cuda:0', grad_fn=<DivBackward0>) 141.4263153076172 0.0\n",
      "40065 tensor(10.5132, device='cuda:0', grad_fn=<DivBackward0>) 168.21173095703125 0.0\n",
      "40185 tensor(10.7715, device='cuda:0', grad_fn=<DivBackward0>) 172.3440399169922 0.0\n",
      "40410 tensor(10.1861, device='cuda:0', grad_fn=<DivBackward0>) 162.9775848388672 0.0\n",
      "41100 tensor(9.1786, device='cuda:0', grad_fn=<DivBackward0>) 146.8577880859375 0.0\n",
      "41220 tensor(11.0796, device='cuda:0', grad_fn=<DivBackward0>) 177.2739715576172 0.0\n",
      "42435 tensor(12.8220, device='cuda:0', grad_fn=<DivBackward0>) 205.15257263183594 0.0\n",
      "44340 tensor(14.4568, device='cuda:0', grad_fn=<DivBackward0>) 231.30838012695312 0.0\n",
      "46380 tensor(11.0146, device='cuda:0', grad_fn=<DivBackward0>) 176.23435974121094 0.0\n",
      "47535 tensor(9.6704, device='cuda:0', grad_fn=<DivBackward0>) 154.7267303466797 0.0\n",
      "47970 tensor(9.9563, device='cuda:0', grad_fn=<DivBackward0>) 159.30154418945312 0.0\n",
      "48495 tensor(8.9017, device='cuda:0', grad_fn=<DivBackward0>) 142.42674255371094 0.0\n",
      "49140 tensor(9.7051, device='cuda:0', grad_fn=<DivBackward0>) 155.28216552734375 0.0\n",
      "batch iteration 1\n",
      "batch_loss: 10.95 \n",
      "\n",
      "\n",
      "1710 tensor(9.3909, device='cuda:0', grad_fn=<DivBackward0>) 150.25509643554688 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2fab5699bad1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mloss_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtemp_number\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mh_loss1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_loss2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_data_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mdenominator\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mloss1_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mh_loss1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-a91353103435>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_list, input_label, input_data)\u001b[0m\n\u001b[0;32m     82\u001b[0m             temp_loss1 = torch.where((Agent_number_n-1)*S_tensor > sum_h,\n\u001b[0;32m     83\u001b[0m                      \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAgent_number_n\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mS_tensor\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msum_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                      \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m                   )\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(int(echo)):\n",
    "    # offender_types = []\n",
    "    # defender_types = []\n",
    "    \n",
    "    \n",
    "    X_train_list = []\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "    while(temp_number<len(training_data)-1):\n",
    "        \n",
    "        loss2_list = []\n",
    "        loss1_sum = 0\n",
    "        loss2_sum = 0\n",
    "        denominator = 0\n",
    "        loss_sum = []\n",
    "        for index in range(temp_number, min(BATCH_SIZE+temp_number,len(training_data))):\n",
    "            h_loss1,h_loss2 = net(training_data[index],training_label[index],training_data_all[index])\n",
    "            denominator += 1\n",
    "            loss1_sum += h_loss1\n",
    "            loss2_sum += h_loss2\n",
    "            loss_sum.append(h_loss1+h_loss2)\n",
    "            \n",
    "        loss = (torch.sum(torch.tensor(loss_sum,requires_grad=True).to(dev))) / denominator \n",
    "        total_batch_loss += float(torch.sum(torch.tensor(loss_sum,requires_grad=True).to(dev)))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        temp_number = index\n",
    "        \n",
    "        if(random.random()<=0.01):\n",
    "            print(temp_number,loss,float(loss1_sum),float(loss2_sum))\n",
    "\n",
    "\n",
    "    print(\"batch iteration\", iteration)\n",
    "    print(\"batch_loss: %.2f \" % (total_batch_loss/len(training_data)))\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:10:16.750808Z",
     "start_time": "2021-06-06T04:03:46.984Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net, \"save/Deep_learning_F_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:10:16.751806Z",
     "start_time": "2021-06-06T04:03:46.985Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = net.calculate(torch.tensor(testing_data[index][i]).cuda().type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list.append(sum(h_list)/testing_label[index])\n",
    "    \n",
    "\n",
    "print(max(result_list),min(result_list),max(result_list)-min(result_list),sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:10:16.752803Z",
     "start_time": "2021-06-06T04:03:46.987Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:10:16.753800Z",
     "start_time": "2021-06-06T04:03:46.991Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create the figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# Generate the values\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "z_vals = []\n",
    "x_ = np.linspace(0.0,1.0,101)\n",
    "y_ = np.linspace(0.0,1.0,101)\n",
    "\n",
    "result_list = []\n",
    "for i in range(len(x_)):\n",
    "    for j in range(0,i):\n",
    "        h = net.calculate(torch.tensor([x_[i],y_[j]]).cuda().type(torch.float32))\n",
    "        x_vals.append(x_[i])\n",
    "        y_vals.append(y_[j])\n",
    "        z_vals.append(float(h))\n",
    "\n",
    "\n",
    "# Plot the values\n",
    "ax.scatter(x_vals, y_vals, z_vals, c = 'b', marker='o')\n",
    "\n",
    "\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Z-axis')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:10:16.754798Z",
     "start_time": "2021-06-06T04:03:46.993Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(z=z_vals, x=x_vals, y=y_vals)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:10:16.755796Z",
     "start_time": "2021-06-06T04:03:46.995Z"
    }
   },
   "outputs": [],
   "source": [
    "# def h_function(input_list):\n",
    "\n",
    "#     h = max(sum(input_list),2/3) + 1/2 * max(sum(input_list),1) - 1/2 * max(input_list[0],2/3) - 1/6\n",
    "#     return h\n",
    "\n",
    "def h_function(input_list):\n",
    "    if(sum(input_list)>=2/3):\n",
    "        h = sum(input_list)\n",
    "    else:\n",
    "        h = 2/3\n",
    "    return h   \n",
    "                \n",
    "x_list2 = []\n",
    "y_list2 = []\n",
    "z_list2 = []\n",
    "result_list = []\n",
    "for index in range(len(training_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        x_list2.append(training_data[index][i][0])\n",
    "        y_list2.append(training_data[index][i][1])\n",
    "        h = h_function(training_data[index][i])\n",
    "        z_list2.append(float(h))\n",
    "        h_list.append(float(h))\n",
    "    result_list.append(sum(h_list)/training_label[index]) \n",
    "    \n",
    "    \n",
    "print(max(result_list), min(result_list), max(result_list)-min(result_list),sum(result_list)/len(result_list))\n",
    "fig = px.scatter_3d(z=z_list2[:10000], x=x_list2[:10000], y=y_list2[:10000])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:10:16.757790Z",
     "start_time": "2021-06-06T04:03:46.996Z"
    }
   },
   "outputs": [],
   "source": [
    "# def h_function(input_list):\n",
    "\n",
    "#     h = max(sum(input_list),2/3) + 1/2 * max(sum(input_list),1) - 1/2 * max(input_list[0],2/3) - 1/6\n",
    "#     return h\n",
    "\n",
    "def h_function(input_list):\n",
    "    if(sum(input_list)>=2/3):\n",
    "        h = sum(input_list)\n",
    "    else:\n",
    "        h = 2/3-sum(input_list)*1/16+1/24\n",
    "    return h   \n",
    "                \n",
    "x_list2 = []\n",
    "y_list2 = []\n",
    "z_list2 = []\n",
    "result_list = []\n",
    "for index in range(len(training_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        x_list2.append(training_data[index][i][0])\n",
    "        y_list2.append(training_data[index][i][1])\n",
    "        h = h_function(training_data[index][i])\n",
    "        z_list2.append(float(h))\n",
    "        h_list.append(float(h))\n",
    "    result_list.append(sum(h_list)/training_label[index]) \n",
    "    \n",
    "    \n",
    "print(max(result_list), min(result_list), max(result_list)-min(result_list),sum(result_list)/len(result_list))\n",
    "fig = px.scatter_3d(z=z_list2[:10000], x=x_list2[:10000], y=y_list2[:10000])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:10:16.758787Z",
     "start_time": "2021-06-06T04:03:46.998Z"
    }
   },
   "outputs": [],
   "source": [
    "# def h_function(input_list):\n",
    "\n",
    "#     h = max(sum(input_list),2/3) + 1/2 * max(sum(input_list),1) - 1/2 * max(input_list[0],2/3) - 1/6\n",
    "#     return h\n",
    "\n",
    "def h_function(input_list):\n",
    "\n",
    "    h = max(sum(input_list),2/3) + 1/2 * max(sum(input_list),1) - 1/2 * max(input_list[0],2/3) - 1/6\n",
    "    return h   \n",
    "                \n",
    "x_list1 = []\n",
    "y_list1 = []\n",
    "z_list1 = []\n",
    "result_list = []\n",
    "for index in range(len(training_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        x_list1.append(training_data[index][i][0])\n",
    "        y_list1.append(training_data[index][i][1])\n",
    "        h = h_function(training_data[index][i])\n",
    "        z_list1.append(float(h))\n",
    "        h_list.append(float(h))\n",
    "    result_list.append(sum(h_list)/training_label[index]) \n",
    "    \n",
    "    \n",
    "print(max(result_list), min(result_list), max(result_list)-min(result_list),sum(result_list)/len(result_list))\n",
    "fig = px.scatter_3d(z=z_list1[:10000], x=x_list1[:10000], y=y_list1[:10000])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:10:16.759784Z",
     "start_time": "2021-06-06T04:03:47.000Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(z=z_list[:10000], x=x_list[:10000], y=y_list[:10000])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:10:16.760782Z",
     "start_time": "2021-06-06T04:03:47.001Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# Generate the values\n",
    "\n",
    "# Plot the values\n",
    "ax.scatter(x_list, y_list, z_list, c = 'b', marker='o')\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Z-axis')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T04:10:16.761779Z",
     "start_time": "2021-06-06T04:03:47.002Z"
    }
   },
   "outputs": [],
   "source": [
    "o_frame = np.linspace(0.0,1.0,101)\n",
    "    \n",
    "#o* = argmax_o { (2 * theta_O - 400)(o-o*o/2) + (2 * theta_D - 15)(1-o)  }\n",
    "\n",
    "grid_x, grid_y = np.mgrid[0:1:400j, 0:1:400j]\n",
    "\n",
    "points =np.reshape([x_vals,y_vals],(2,-1))\n",
    "\n",
    "points = np.transpose(points)\n",
    "\n",
    "grid_z2 = griddata(points, z_vals, (grid_x, grid_y), method='nearest')\n",
    "\n",
    "\n",
    "im =plt.imshow(grid_z2.T, extent=(0,1,0,1) , aspect='auto',interpolation='bilinear')\n",
    "plt.colorbar(im)\n",
    "plt.title('high')\n",
    "plt.xlabel(r\"Defender type $\\dot{\\Theta}$d\")\n",
    "plt.ylabel(r\"offender type $\\dot{\\Theta}$o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
