{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T12:19:59.364665Z",
     "start_time": "2021-06-15T12:19:57.160532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pygame\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm \n",
    "import matplotlib.cm as cm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy.interpolate import griddata\n",
    "# import LossAccPlotter\n",
    "# from laplotter import LossAccPlotter\n",
    "# from check_laplotter import show_chart, add_noise\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "print(dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T12:19:59.380516Z",
     "start_time": "2021-06-15T12:19:59.367044Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "global temp_list\n",
    "temp_list = []\n",
    "Agent_number_n=10;\n",
    "Alpha = 1.0;\n",
    "\n",
    "echo = 2001\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001           # learning rate for generator\n",
    "\n",
    "def Generate_distribution(Agent_number_n):\n",
    "    return sorted(np.random.rand(Agent_number_n), reverse=True)\n",
    "    #return sorted(np.random.normal(normalloc,normalscale,Agent_number_n), reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T12:20:00.192269Z",
     "start_time": "2021-06-15T12:19:59.381514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.67987278 0.61741057 0.56634018 ... 0.13076853 0.11515332 0.08740509]\n",
      "  [0.79405758 0.61741057 0.56634018 ... 0.13076853 0.11515332 0.08740509]\n",
      "  [0.79405758 0.67987278 0.56634018 ... 0.13076853 0.11515332 0.08740509]\n",
      "  ...\n",
      "  [0.79405758 0.67987278 0.61741057 ... 0.15756761 0.11515332 0.08740509]\n",
      "  [0.79405758 0.67987278 0.61741057 ... 0.15756761 0.13076853 0.08740509]\n",
      "  [0.79405758 0.67987278 0.61741057 ... 0.15756761 0.13076853 0.11515332]]\n",
      "\n",
      " [[0.80654522 0.77521929 0.74211622 ... 0.28773117 0.19760062 0.0339361 ]\n",
      "  [0.89561724 0.77521929 0.74211622 ... 0.28773117 0.19760062 0.0339361 ]\n",
      "  [0.89561724 0.80654522 0.74211622 ... 0.28773117 0.19760062 0.0339361 ]\n",
      "  ...\n",
      "  [0.89561724 0.80654522 0.77521929 ... 0.4021653  0.19760062 0.0339361 ]\n",
      "  [0.89561724 0.80654522 0.77521929 ... 0.4021653  0.28773117 0.0339361 ]\n",
      "  [0.89561724 0.80654522 0.77521929 ... 0.4021653  0.28773117 0.19760062]]\n",
      "\n",
      " [[0.8013517  0.64506366 0.6240863  ... 0.51125838 0.42428276 0.20803049]\n",
      "  [0.97419806 0.64506366 0.6240863  ... 0.51125838 0.42428276 0.20803049]\n",
      "  [0.97419806 0.8013517  0.6240863  ... 0.51125838 0.42428276 0.20803049]\n",
      "  ...\n",
      "  [0.97419806 0.8013517  0.64506366 ... 0.55034962 0.42428276 0.20803049]\n",
      "  [0.97419806 0.8013517  0.64506366 ... 0.55034962 0.51125838 0.20803049]\n",
      "  [0.97419806 0.8013517  0.64506366 ... 0.55034962 0.51125838 0.42428276]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.91641288 0.79310236 0.57625834 ... 0.31960281 0.14518927 0.09449305]\n",
      "  [0.97386227 0.79310236 0.57625834 ... 0.31960281 0.14518927 0.09449305]\n",
      "  [0.97386227 0.91641288 0.57625834 ... 0.31960281 0.14518927 0.09449305]\n",
      "  ...\n",
      "  [0.97386227 0.91641288 0.79310236 ... 0.34600575 0.14518927 0.09449305]\n",
      "  [0.97386227 0.91641288 0.79310236 ... 0.34600575 0.31960281 0.09449305]\n",
      "  [0.97386227 0.91641288 0.79310236 ... 0.34600575 0.31960281 0.14518927]]\n",
      "\n",
      " [[0.9712864  0.81168157 0.80356716 ... 0.14601542 0.08276064 0.05707697]\n",
      "  [0.97523792 0.81168157 0.80356716 ... 0.14601542 0.08276064 0.05707697]\n",
      "  [0.97523792 0.9712864  0.80356716 ... 0.14601542 0.08276064 0.05707697]\n",
      "  ...\n",
      "  [0.97523792 0.9712864  0.81168157 ... 0.37201171 0.08276064 0.05707697]\n",
      "  [0.97523792 0.9712864  0.81168157 ... 0.37201171 0.14601542 0.05707697]\n",
      "  [0.97523792 0.9712864  0.81168157 ... 0.37201171 0.14601542 0.08276064]]\n",
      "\n",
      " [[0.71322585 0.69569434 0.58085783 ... 0.4283738  0.18286161 0.09564639]\n",
      "  [0.98613336 0.69569434 0.58085783 ... 0.4283738  0.18286161 0.09564639]\n",
      "  [0.98613336 0.71322585 0.58085783 ... 0.4283738  0.18286161 0.09564639]\n",
      "  ...\n",
      "  [0.98613336 0.71322585 0.69569434 ... 0.43062329 0.18286161 0.09564639]\n",
      "  [0.98613336 0.71322585 0.69569434 ... 0.43062329 0.4283738  0.09564639]\n",
      "  [0.98613336 0.71322585 0.69569434 ... 0.43062329 0.4283738  0.18286161]]]\n",
      "[3.64197398 5.31228335 5.92792569 ... 5.1832362  5.30423896 5.03990532]\n"
     ]
    }
   ],
   "source": [
    "def h_3_star(a, b, t):\n",
    "    return a - min(a, t) + b - min(b, t) + max(min(a, t)+min(b, t), 2*t/3) + 1/2 * max(min(a, t)+min(b, t), t) - 1/2 * max(max(min(a, t), min(b, t)), 2*t/3) - t/6\n",
    "\n",
    "\n",
    "def f_function(a, b, z):\n",
    "    if(z >= 1):\n",
    "        return (a+b)/2 + z/3\n",
    "    else:\n",
    "        return z/3 + h_3_star(a, b, 1-z)/2\n",
    "\n",
    "def h_function_label(input_list):\n",
    "    #input_list = sorted(input_list)\n",
    "    g_list = []\n",
    "    for j1 in range(len(input_list) ):\n",
    "        for j2 in range(len(input_list)):\n",
    "            if(j1 != j2):\n",
    "                a = input_list[j1]\n",
    "                b = input_list[j2]\n",
    "                z = sum(input_list)- a-b\n",
    "\n",
    "                g_list.append( f_function(a, b, z) * (Agent_number_n-1))\n",
    "    h = sum(g_list) * 3 /  (Agent_number_n) /  (Agent_number_n-1) /  (Agent_number_n - 2)\n",
    "    return h\n",
    "\n",
    "def appen(_x_list,y):\n",
    "    global temp_list\n",
    "    temp_list.append(_x_list)\n",
    "    \n",
    "def appen_train(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "        \n",
    "        h = h_function_label(temp)\n",
    "        h_list.append(float(h))\n",
    "    temp_list = np.array(temp_list)\n",
    "    x_list = np.array(x_list)\n",
    "    return temp_list,S,x_list,h_list\n",
    "    \n",
    "\n",
    "def appen_test(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data.append(temp_list)\n",
    "    testing_label.append(S)\n",
    "    temp_list = np.array(temp_list)\n",
    "    return temp_list,S\n",
    "    \n",
    "\n",
    "def read_testing_data():\n",
    "    for i in range(10000):\n",
    "        appen_test(Generate_distribution(Agent_number_n));\n",
    "                            \n",
    "\n",
    "testing_data=[]\n",
    "testing_label=[]\n",
    "S=1.0\n",
    "read_testing_data();\n",
    "\n",
    "testing_data=np.array(testing_data)\n",
    "testing_label=np.array(testing_label)\n",
    "print(testing_data)\n",
    "print(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T12:19:57.111Z"
    }
   },
   "outputs": [],
   "source": [
    "def h_3_star(a, b, t):\n",
    "    return a - min(a, t) + b - min(b, t) + max(min(a, t)+min(b, t), 2*t/3) + 1/2 * max(min(a, t)+min(b, t), t) - 1/2 * max(max(min(a, t), min(b, t)), 2*t/3) - t/6\n",
    "\n",
    "\n",
    "def f_function(a, b, z):\n",
    "    if(z >= 1):\n",
    "        return (a+b)/2 + z/3\n",
    "    else:\n",
    "        return z/3 + h_3_star(a, b, 1-z)/2\n",
    "\n",
    "def h_function(input_list):\n",
    "    #input_list = sorted(input_list)\n",
    "    g_list = []\n",
    "    for j1 in range(len(input_list) ):\n",
    "        for j2 in range(len(input_list)):\n",
    "            if(j1 != j2):\n",
    "                a = input_list[j1]\n",
    "                b = input_list[j2]\n",
    "                z = sum(input_list)- a-b\n",
    "\n",
    "                g_list.append( f_function(a, b, z) * (Agent_number_n-1))\n",
    "    h = sum(g_list) * 3 /  (Agent_number_n) /  (Agent_number_n-1) /  (Agent_number_n - 2)\n",
    "    return h\n",
    "                \n",
    "                \n",
    "x_list = []\n",
    "y_list = []\n",
    "z_list = []\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        x_list.append(testing_data[index][i][0])\n",
    "        y_list.append(testing_data[index][i][1])\n",
    "        h = h_function(testing_data[index][i])\n",
    "        z_list.append(float(h))\n",
    "        h_list.append(float(h))\n",
    "    result_list.append(sum(h_list)/testing_label[index]) \n",
    "    \n",
    "    \n",
    "print(max(result_list), min(result_list), max(result_list)-min(result_list),sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T12:19:57.112Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T12:19:57.115Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.normal_(m.bias, mean=0.0, std=0.01)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.input_dim = (Agent_number_n-1)\n",
    "        self.hidden_dim = 100\n",
    "        self.output_dim = 1\n",
    "        self.hidden_layer_count = 6\n",
    "\n",
    "        current_dim = self.input_dim\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(self.hidden_layer_count):\n",
    "            self.layers.append(torch.nn.Linear(current_dim, self.hidden_dim))\n",
    "            current_dim = self.hidden_dim\n",
    "        self.layers.append(torch.nn.Linear(current_dim, self.output_dim))\n",
    "\n",
    "    def calculate(self, value_list):\n",
    "        h = value_list\n",
    "        for layer in self.layers:\n",
    "            h = torch.relu(layer(h))\n",
    "        return h\n",
    "\n",
    "    def forward(self, input_list, input_label, label):\n",
    "        global iteration, echo, target_order\n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).to(dev).type(torch.float32)\n",
    "        h_list = []\n",
    "\n",
    "        for i in range(Agent_number_n):\n",
    "            h = self.calculate(input_list[i])\n",
    "            h_list.append(h)\n",
    "#             loss3 += torch.square(h_function_2(input_list)-h2[1])\n",
    "\n",
    "        input_label = torch.from_numpy(\n",
    "            np.array(input_label)).to(dev).type(torch.float32)\n",
    "        sum_h = torch.sum(torch.cat(h_list)).to(dev)\n",
    "\n",
    "        loss1 = torch.where((Agent_number_n-1)*input_label > sum_h,\n",
    "                            torch.square(\n",
    "                                ((Agent_number_n-1)*input_label-sum_h)),\n",
    "                            torch.zeros(1).to(dev)\n",
    "                            )\n",
    "#         loss2 = torch.relu((sum_h-(Agent_number_n-Alpha)*input_label))/10000\n",
    "\n",
    "        loss2 = torch.where((Agent_number_n-Alpha)*input_label<sum_h,\n",
    "                        torch.square((sum_h-(Agent_number_n-Alpha)*input_label))/10000,\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "#         loss1 = torch.relu(((Agent_number_n-1)*input_label-sum_h))\n",
    "\n",
    "#         loss2 = torch.relu((sum_h-(Agent_number_n-Alpha)*input_label))/10000\n",
    "\n",
    "        return loss1, loss2\n",
    "    def supervised_loss(self, input_list,label):\n",
    "        global iteration,echo,target_order\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).to(dev).type(torch.float32)\n",
    "        loss = 0 \n",
    "        for i in range(Agent_number_n):\n",
    "            h = self.calculate(input_list[i])\n",
    "            loss += torch.square(h - label[i])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T12:19:57.117Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "net  = Net()\n",
    "net.apply(weight_init)\n",
    "\n",
    "#net = torch.load(\"save/Deep_learning_uniform_10_1\")\n",
    "net.to(dev)\n",
    "#optimizer = opt.RMSprop(net.parameters(), lr=0.00001)\n",
    "#optimizer = opt.SGD(net.parameters(), lr=0.00005)\n",
    "optimizer = opt.Adam(net.parameters(), lr=LR)\n",
    "#optimizer = opt.Adadelta(net.parameters(), lr=1.0)\n",
    "print(net)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.95)\n",
    "\n",
    "\n",
    "index_train_list = []\n",
    "index_test_list = []\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T12:19:57.118Z"
    }
   },
   "outputs": [],
   "source": [
    "#supervised\n",
    "index_supervisedtrain_list = []\n",
    "supervisedtrain_losses = []\n",
    "for iteration in range(1000):\n",
    "\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "    \n",
    "    loss_sum = 0\n",
    "    denominator = 0\n",
    "    for index in range(0, BATCH_SIZE):\n",
    "        training_data_i, training_S, training_data,label = appen_train(\n",
    "            Generate_distribution(Agent_number_n))\n",
    "        h_loss = net.supervised_loss(training_data_i, label)\n",
    "        denominator += 1\n",
    "        loss_sum += h_loss\n",
    "\n",
    "    loss_sum = torch.sum(loss_sum)\n",
    "    loss = (loss_sum) / denominator \n",
    "    total_batch_loss += float(loss_sum)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (iteration%50 == 0):\n",
    "        print(iteration,loss,total_batch_loss)\n",
    "        index_supervisedtrain_list.append(iteration)\n",
    "        supervisedtrain_losses.append(total_batch_loss)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T12:19:57.120Z"
    }
   },
   "outputs": [],
   "source": [
    "for iteration in range(int(echo)):\n",
    "\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0\n",
    "\n",
    "    loss2_list = []\n",
    "    loss1_sum = 0\n",
    "    loss2_sum = 0\n",
    "    denominator = 0\n",
    "    for index in range(0, BATCH_SIZE):\n",
    "        training_data_i, training_label, training_data,label = appen_train(\n",
    "            Generate_distribution(Agent_number_n))\n",
    "        h_loss1, h_loss2 = net(training_data_i, training_label,\n",
    "                                       training_data)\n",
    "        denominator += 1\n",
    "        loss1_sum += h_loss1\n",
    "        loss2_sum += h_loss2\n",
    "\n",
    "    loss_sum = torch.sum(loss1_sum + loss2_sum)\n",
    "    loss = (loss_sum) / denominator\n",
    "    total_batch_loss = float(loss)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    temp_number = iteration\n",
    "\n",
    "    index_train_list.append(iteration)\n",
    "    train_losses.append(total_batch_loss)\n",
    "\n",
    "    if (iteration%50 == 0):\n",
    "        print(temp_number, loss, float(loss1_sum), float(loss2_sum))\n",
    "\n",
    "        print(\"batch iteration\", iteration)\n",
    "        print(\"batch_loss: %.2f \" % total_batch_loss)\n",
    "\n",
    "        result_list = []\n",
    "        for index in range(len(testing_data)):\n",
    "            h_list = []\n",
    "            for i in range(Agent_number_n):\n",
    "                h = net.calculate(\n",
    "                    torch.tensor(testing_data[index][i]).to(dev).type(\n",
    "                        torch.float32))\n",
    "                h_list.append(float(h))\n",
    "            result_list.append(sum(h_list) / testing_label[index])\n",
    "        print(max(result_list), min(result_list),\n",
    "              max(result_list) - min(result_list),\n",
    "              (sum(result_list) / len(result_list) - min(result_list))+ Agent_number_n-1 - min(min(result_list),Agent_number_n-1) )\n",
    "\n",
    "        index_test_list.append(iteration)\n",
    "        test_losses.append(\n",
    "            (sum(result_list) / len(result_list) - min(result_list))+ Agent_number_n-1 - min(min(result_list),Agent_number_n-1) )\n",
    "        print()\n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T12:19:57.121Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylim(0, 1.0)\n",
    "plt.plot(index_test_list,test_losses)\n",
    "plt.ylabel('Testing Loss')\n",
    "plt.xlabel('Batch Epoch')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T12:19:57.123Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('save/test_loss_unfeed_uniform_10.csv', 'w', newline='') as csvfile_unfeed:\n",
    "    spamwriter = csv.writer(csvfile_unfeed)\n",
    "    spamwriter.writerow(index_test_list)\n",
    "    spamwriter.writerow(test_losses)\n",
    "\n",
    "with open('save/test_loss_feed_uniform_10.csv') as csvfile_feed:\n",
    "    reader = csv.reader(csvfile_feed)\n",
    "    list_feed = []\n",
    "    for row in reader:\n",
    "        row = np.array(row)\n",
    "        temp_list = []\n",
    "        for i in range(len(row)):\n",
    "            temp_list.append(float(row[i]))\n",
    "\n",
    "        list_feed.append(temp_list)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.plot(index_test_list,test_losses,label='neural network')\n",
    "    plt.plot(list_feed[0],list_feed[1],label='feed distribution')\n",
    "    plt.ylabel('Testing Loss')\n",
    "    plt.xlabel('Batch Epoch')\n",
    "    #plt.title('Two or more lines on same plot with suitable legends ')\n",
    "    # show a legend on the plot\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T12:19:57.124Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(list_feed[0]))\n",
    "print(len(list_feed[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T12:19:57.126Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylim(0, 1.0)\n",
    "\n",
    "plt.plot(index_train_list,train_losses)\n",
    "plt.ylabel('training loss')\n",
    "\n",
    "plt.plot(index_test_list,test_losses)\n",
    "plt.ylabel('training loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T12:19:57.128Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net, \"save/Deep_learning_uniform_10_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T12:19:57.130Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = net.calculate(torch.tensor(testing_data[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list.append(sum(h_list)/testing_label[index])\n",
    "    \n",
    "\n",
    "print(max(result_list),min(result_list),max(result_list)-min(result_list),sum(result_list)/len(result_list)-min(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T12:19:57.132Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
