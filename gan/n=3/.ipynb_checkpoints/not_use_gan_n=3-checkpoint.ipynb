{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T06:33:07.006289Z",
     "start_time": "2021-06-14T06:33:04.960690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pygame\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm \n",
    "import matplotlib.cm as cm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy.interpolate import griddata\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "print(dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T06:33:07.022262Z",
     "start_time": "2021-06-14T06:33:07.008285Z"
    }
   },
   "outputs": [],
   "source": [
    "global temp_list\n",
    "temp_list = []\n",
    "Agent_number_n=3;\n",
    "Alpha = 0.665 \n",
    "\n",
    "# Hyper Parameters\n",
    "echo = 1001\n",
    "BATCH_SIZE = 64\n",
    "LR_G = 0.001           # learning rate for generator\n",
    "LR_D = 0.001           # learning rate for discriminator\n",
    "N_IDEAS = Agent_number_n             # think of this as number of ideas for generating an art work (Generator)\n",
    "ART_COMPONENTS = Agent_number_n     # it could be total point G can draw in the canvas\n",
    "\n",
    "Is_GAN = False # if use Gan\n",
    "\n",
    "def Generate_distribution(Agent_number_n):\n",
    "    return sorted(np.random.rand(Agent_number_n), reverse=True)\n",
    "    #return np.random.normal(normalloc,normalscale,Agent_number_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T06:33:07.293046Z",
     "start_time": "2021-06-14T06:33:07.023767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.46842027 0.43205788]\n",
      "  [0.70616443 0.43205788]\n",
      "  [0.70616443 0.46842027]]\n",
      "\n",
      " [[0.49764727 0.3793524 ]\n",
      "  [0.72495191 0.3793524 ]\n",
      "  [0.72495191 0.49764727]]\n",
      "\n",
      " [[0.76456992 0.36253586]\n",
      "  [0.78580639 0.36253586]\n",
      "  [0.78580639 0.76456992]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.64008836 0.58746407]\n",
      "  [0.9739205  0.58746407]\n",
      "  [0.9739205  0.64008836]]\n",
      "\n",
      " [[0.32554622 0.06602763]\n",
      "  [0.89220849 0.06602763]\n",
      "  [0.89220849 0.32554622]]\n",
      "\n",
      " [[0.58116102 0.26390185]\n",
      "  [0.7133743  0.26390185]\n",
      "  [0.7133743  0.58116102]]]\n",
      "[1.60664258 1.60195157 1.91291217 ... 2.20147293 1.28378235 1.55843718]\n"
     ]
    }
   ],
   "source": [
    "def h_3_star(a, b, t):\n",
    "    return a - min(a, t) + b - min(b, t) + max(min(a, t)+min(b, t), 2*t/3) + 1/2 * max(min(a, t)+min(b, t), t) - 1/2 * max(max(min(a, t), min(b, t)), 2*t/3) - t/6\n",
    "\n",
    "\n",
    "def f_function(a, b, z):\n",
    "    if(z >= 1):\n",
    "        return (a+b)/2 + z/3\n",
    "    else:\n",
    "        return z/3 + h_3_star(a, b, 1-z)/2\n",
    "\n",
    "def h_function_label(input_list):\n",
    "    #input_list = sorted(input_list)\n",
    "    g_list = []\n",
    "    for j1 in range(len(input_list) ):\n",
    "        for j2 in range(len(input_list)):\n",
    "            if(j1 != j2):\n",
    "                a = input_list[j1]\n",
    "                b = input_list[j2]\n",
    "                z = sum(input_list)- a-b\n",
    "\n",
    "                g_list.append( f_function(a, b, z) * (Agent_number_n-1))\n",
    "    h = sum(g_list) * 3 /  (Agent_number_n) /  (Agent_number_n-1) /  (Agent_number_n - 2)\n",
    "    return h\n",
    "\n",
    "def appen(_x_list,y):\n",
    "    global temp_list\n",
    "    temp_list.append(_x_list)\n",
    "    \n",
    "def appen_train(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "        \n",
    "        h = h_function_label(temp)\n",
    "        h_list.append(float(h))\n",
    "    temp_list = np.array(temp_list)\n",
    "    x_list = np.array(x_list)\n",
    "    return temp_list,S,x_list,h_list\n",
    "    \n",
    "\n",
    "def appen_test(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data.append(temp_list)\n",
    "    testing_label.append(S)\n",
    "    temp_list = np.array(temp_list)\n",
    "    return temp_list,S\n",
    "    \n",
    "\n",
    "def read_testing_data():\n",
    "    for i in range(10000):\n",
    "        appen_test(Generate_distribution(Agent_number_n));\n",
    "                            \n",
    "\n",
    "testing_data=[]\n",
    "testing_label=[]\n",
    "S=1.0\n",
    "read_testing_data();\n",
    "\n",
    "testing_data=np.array(testing_data)\n",
    "testing_label=np.array(testing_label)\n",
    "print(testing_data)\n",
    "print(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T06:33:08.125474Z",
     "start_time": "2021-06-14T06:33:07.294045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.333310993472154 2.0 0.33331099347215387 2.102278070942321\n"
     ]
    }
   ],
   "source": [
    "def h_3_star(a, b, t):\n",
    "    return a - min(a, t) + b - min(b, t) + max(min(a, t)+min(b, t), 2*t/3) + 1/2 * max(min(a, t)+min(b, t), t) - 1/2 * max(max(min(a, t), min(b, t)), 2*t/3) - t/6\n",
    "\n",
    "\n",
    "def f_function(a, b, z):\n",
    "    if(z >= 1):\n",
    "        return (a+b)/2 + z/3\n",
    "    else:\n",
    "        return z/3 + h_3_star(a, b, 1-z)/2\n",
    "\n",
    "def h_function(input_list):\n",
    "    #input_list = sorted(input_list)\n",
    "    g_list = []\n",
    "    for j1 in range(len(input_list) ):\n",
    "        for j2 in range(len(input_list)):\n",
    "            if(j1 != j2):\n",
    "                a = input_list[j1]\n",
    "                b = input_list[j2]\n",
    "                z = sum(input_list)- a-b\n",
    "\n",
    "                g_list.append( f_function(a, b, z) * (Agent_number_n-1))\n",
    "    h = sum(g_list) * 3 /  (Agent_number_n) /  (Agent_number_n-1) /  (Agent_number_n - 2)\n",
    "    return h\n",
    "                \n",
    "                \n",
    "x_list = []\n",
    "y_list = []\n",
    "z_list = []\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        x_list.append(testing_data[index][i][0])\n",
    "        y_list.append(testing_data[index][i][1])\n",
    "        h = h_function(testing_data[index][i])\n",
    "        z_list.append(float(h))\n",
    "        h_list.append(float(h))\n",
    "    result_list.append(sum(h_list)/testing_label[index]) \n",
    "    \n",
    "    \n",
    "print(max(result_list), min(result_list), max(result_list)-min(result_list),sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T06:33:09.324314Z",
     "start_time": "2021-06-14T06:33:08.127468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T06:33:09.354760Z",
     "start_time": "2021-06-14T06:33:09.326310Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.input_dim = (Agent_number_n-1)\n",
    "        self.hidden_dim = 128\n",
    "        self.output_dim = 1\n",
    "        self.hidden_layer_count = 6 \n",
    "        \n",
    "        current_dim = self.input_dim\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(self.hidden_layer_count):\n",
    "            self.layers.append(torch.nn.Linear(current_dim, self.hidden_dim))\n",
    "            current_dim = self.hidden_dim\n",
    "        self.layers.append(torch.nn.Linear(current_dim, self.output_dim))\n",
    "\n",
    "    def calculate(self, value_list):\n",
    "        h = value_list\n",
    "        LeakyReLU = torch.nn.LeakyReLU()\n",
    "        for layer in self.layers:\n",
    "            h = torch.relu(layer(h))\n",
    "        return h\n",
    "\n",
    "    def forward(self, input_list,input_label,list_x):\n",
    "        global iteration,echo,target_order\n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        loss3 = 0\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).to(dev).type(torch.float32)\n",
    "        h_list = []\n",
    "\n",
    "        for i in range(Agent_number_n):\n",
    "            h = self.calculate(input_list[i])\n",
    "            h_list.append(h)\n",
    "#             loss3 += torch.square(h_function_2(input_list)-h2[1])\n",
    "            \n",
    "        input_label = torch.from_numpy(\n",
    "            np.array(input_label)).to(dev).type(torch.float32)\n",
    "        sum_h = torch.sum(torch.cat(h_list)).to(dev)\n",
    "\n",
    "\n",
    "        loss1 = torch.where((Agent_number_n-1)*input_label>sum_h,\n",
    "                        torch.square(((Agent_number_n-1)*input_label-sum_h)),\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "        loss2 = torch.where((Agent_number_n-Alpha)*input_label<sum_h,\n",
    "                        torch.square((sum_h-(Agent_number_n-Alpha)*input_label))/100,\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "\n",
    "        return loss1,loss2\n",
    "    \n",
    "    def supervised_loss(self, input_list,label):\n",
    "        global iteration,echo,target_order\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).to(dev).type(torch.float32)\n",
    "        loss = 0 \n",
    "        for i in range(Agent_number_n):\n",
    "            h = self.calculate(input_list[i])\n",
    "            loss += torch.square(h - label[i])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T06:33:09.369722Z",
     "start_time": "2021-06-14T06:33:09.357753Z"
    }
   },
   "outputs": [],
   "source": [
    "def redistribution_value_function(input_tensor):\n",
    "    S = torch.max(torch.sum(input_tensor), torch.ones(1).to(dev))\n",
    "    temp_list = []\n",
    "\n",
    "\n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        \n",
    "        for j in range(Agent_number_n):\n",
    "            if(i != j):\n",
    "                temp .append(input_tensor[j])\n",
    "                \n",
    "        temp = torch.stack(temp)\n",
    "        temp_list.append(temp)\n",
    "    return torch.stack(temp_list), S\n",
    "\n",
    "GeneratorNet = nn.Sequential(                      # Generator\n",
    "    # random ideas (could from normal distribution)\n",
    "    nn.Linear(N_IDEAS, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    # making a painting from these random ideas\n",
    "    nn.Linear(64, ART_COMPONENTS),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T06:33:10.944796Z",
     "start_time": "2021-06-14T06:33:09.372714Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "DiscriminatorNet  = Net()\n",
    "DiscriminatorNet.apply(weight_init)\n",
    "GeneratorNet.apply(weight_init)\n",
    "# DiscriminatorNet = torch.load(\"save/Deep_learning_D_4_ungan\")\n",
    "# if(Is_GAN):\n",
    "#     GeneratorNet = torch.load(\"save/Deep_learning_G_4)\n",
    "DiscriminatorNet.to(dev)\n",
    "GeneratorNet.to(dev)\n",
    "\n",
    "opt_D = torch.optim.Adam(DiscriminatorNet.parameters(), lr=LR_D)\n",
    "opt_G = torch.optim.Adam(GeneratorNet.parameters(), lr=LR_G)\n",
    "\n",
    "\n",
    "scheduler_D = torch.optim.lr_scheduler.StepLR(opt_D, step_size=100, gamma=0.98)\n",
    "scheduler_G = torch.optim.lr_scheduler.StepLR(opt_G, step_size=100, gamma=0.98)\n",
    "\n",
    "index_train_list = []\n",
    "index_test_list = []\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-14T06:33:04.935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(3.5829, device='cuda:0', grad_fn=<DivBackward0>) 229.3056182861328\n",
      "100 tensor(0.0138, device='cuda:0', grad_fn=<DivBackward0>) 0.8818714618682861\n",
      "200 tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) 0.023326456546783447\n"
     ]
    }
   ],
   "source": [
    "#supervised\n",
    "index_supervisedtrain_list = []\n",
    "supervisedtrain_losses = []\n",
    "for iteration in range(int(echo)):\n",
    "\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "    \n",
    "    loss_sum = 0\n",
    "    denominator = 0\n",
    "    for index in range(0, BATCH_SIZE):\n",
    "        training_data_i, training_S, training_data,label = appen_train(\n",
    "            Generate_distribution(Agent_number_n))\n",
    "        h_loss = DiscriminatorNet.supervised_loss(training_data_i, label)\n",
    "        denominator += 1\n",
    "        loss_sum += h_loss\n",
    "\n",
    "    loss_sum = torch.sum(loss_sum)\n",
    "    loss = (loss_sum) / denominator \n",
    "    total_batch_loss += float(loss_sum)\n",
    "\n",
    "    opt_D.zero_grad()\n",
    "    loss.backward()\n",
    "    opt_D.step()\n",
    "\n",
    "    if (iteration%100 == 0):\n",
    "        print(iteration,loss,total_batch_loss)\n",
    "        index_supervisedtrain_list.append(iteration)\n",
    "        supervisedtrain_losses.append(total_batch_loss)\n",
    "    scheduler_D.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-14T06:33:04.937Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylim(0, 0.1)\n",
    "plt.plot(index_supervisedtrain_list ,supervisedtrain_losses)\n",
    "plt.ylabel('supervised train loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-14T06:33:04.939Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#unsupervised\n",
    "train_losses = []\n",
    "for iteration in range(int(echo)):\n",
    "\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "        \n",
    "    loss2_list = []\n",
    "    loss1_sum = 0\n",
    "    loss2_sum = 0\n",
    "    denominator = 0\n",
    "    for index in range(0, BATCH_SIZE):\n",
    "        training_data_i, training_label, training_data, label = appen_train(\n",
    "            Generate_distribution(Agent_number_n))\n",
    "        h_loss1, h_loss2 = DiscriminatorNet(training_data_i, training_label,\n",
    "                                       training_data)\n",
    "        denominator += 1\n",
    "        loss1_sum += h_loss1\n",
    "        loss2_sum += h_loss2\n",
    "\n",
    "    loss_sum = torch.sum(loss1_sum + loss2_sum)\n",
    "    loss = (loss_sum) / denominator \n",
    "    total_batch_loss +=float(loss_sum)\n",
    "\n",
    "    opt_D.zero_grad()\n",
    "    loss.backward()\n",
    "    opt_D.step()\n",
    "\n",
    "    temp_number = iteration\n",
    "    index_train_list.append(iteration)\n",
    "    train_losses.append(total_batch_loss)\n",
    "\n",
    "    if (iteration%100 == 0):\n",
    "        print(temp_number,loss,float(loss1_sum),float(loss2_sum))\n",
    "    ## Gan \n",
    "        if(Is_GAN):## Gan Work traning GeneratorNet\n",
    "\n",
    "            DiscriminatorNet.requires_grad = True\n",
    "            GeneratorNet.requires_grad = True\n",
    "\n",
    "\n",
    "            for step in range(100):\n",
    "                # real painting from artist\n",
    "                G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                                      requires_grad=True).to(dev)  # random ideas\\n\n",
    "                # fake painting from G (random ideas)\n",
    "\n",
    "                G_values = GeneratorNet(G_ideas)\n",
    "                G_values , indices = torch.sort(G_values, descending=True)\n",
    "            #     print(artist_paintings)\n",
    "            #     print(G_paintings)\n",
    "\n",
    "                result_list = []\n",
    "                for index in range(BATCH_SIZE):\n",
    "                    h_list = []\n",
    "                    value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                        G_values[index])\n",
    "                    for i in range(Agent_number_n):\n",
    "                        h = DiscriminatorNet.calculate(\n",
    "                            value_list_tensor[i].cuda().type(torch.float32))\n",
    "                        h_list.append(h)\n",
    "                    h_list = torch.stack(h_list)\n",
    "                    result_list.append(torch.sum(h_list)/S_tensor.cuda())\n",
    "                result_list = torch.stack(result_list)\n",
    "\n",
    "                diff_loss = torch.max(result_list)-torch.min(result_list)\n",
    "                G_loss = torch.max(- diff_loss)\n",
    "\n",
    "                opt_G.zero_grad()\n",
    "                G_loss.backward()\n",
    "                opt_G.step()\n",
    "\n",
    "            # real painting from artist\n",
    "                G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                                      requires_grad=True).to(dev)  # random ideas\\n\n",
    "                # fake painting from G (random ideas)\n",
    "\n",
    "                G_values = GeneratorNet(G_ideas)\n",
    "                G_values , indices = torch.sort(G_values, descending=True)\n",
    "            #     print(artist_paintings)\n",
    "            #     print(G_paintings)\n",
    "\n",
    "                result_list = []\n",
    "                for index in range(BATCH_SIZE):\n",
    "                    h_list = []\n",
    "                    value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                        G_values[index])\n",
    "                    for i in range(Agent_number_n):\n",
    "                        h = DiscriminatorNet.calculate(\n",
    "                            value_list_tensor[i].cuda().type(torch.float32))\n",
    "                        h_list.append(h)\n",
    "                    h_list = torch.stack(h_list)\n",
    "                    result_list.append(torch.sum(h_list)/S_tensor.cuda())\n",
    "                result_list = torch.stack(result_list)\n",
    "\n",
    "                diff_loss = torch.max(result_list)-torch.min(result_list)\n",
    "\n",
    "                D_loss = torch.where((Agent_number_n-1)>torch.min(result_list),\n",
    "                    torch.square(((Agent_number_n-1)-torch.min(result_list))),\n",
    "                    torch.zeros(1).to(dev)\n",
    "                  )   + torch.where((Agent_number_n-Alpha)<torch.max(result_list),\n",
    "                                torch.square((torch.max(result_list)-(Agent_number_n-Alpha)))/10000,\n",
    "                                torch.zeros(1).to(dev)\n",
    "                              )\n",
    "\n",
    "\n",
    "                opt_D.zero_grad()\n",
    "                D_loss.backward()\n",
    "                opt_D.step()\n",
    "                \n",
    "            print(\"Gan:\",G_loss,D_loss)\n",
    "            print()\n",
    "\n",
    "        result_list = []\n",
    "        for index in range(len(testing_data)):\n",
    "            h_list = []\n",
    "            for i in range(Agent_number_n):\n",
    "                h = DiscriminatorNet.calculate(\n",
    "                    torch.tensor(testing_data[index][i]).to(dev).type(\n",
    "                        torch.float32))\n",
    "                h_list.append(float(h))\n",
    "            result_list.append(sum(h_list) / testing_label[index])\n",
    "        print(max(result_list), min(result_list),\n",
    "              max(result_list) - min(result_list),\n",
    "              (sum(result_list) / len(result_list) - min(result_list))+ Agent_number_n-1 - min(min(result_list),Agent_number_n-1) )\n",
    "\n",
    "        index_test_list.append(iteration)\n",
    "        test_losses.append(\n",
    "            (sum(result_list) / len(result_list) - min(result_list))+ Agent_number_n-1 - min(min(result_list),Agent_number_n-1) )\n",
    "        print()\n",
    "        index_test_list.append(iteration)\n",
    "        test_losses.append(\n",
    "            max(result_list)-min(result_list) )\n",
    "        \n",
    "        print()\n",
    "\n",
    "    scheduler_D.step()\n",
    "    scheduler_G.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-14T06:33:04.942Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylim(0, 1.0)\n",
    "plt.plot(index_test_list,test_losses)\n",
    "plt.ylabel('test loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-14T06:33:04.945Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(DiscriminatorNet, \"save/Deep_learning_D_3_ungan\")\n",
    "if(Is_GAN):\n",
    "    torch.save(GeneratorNet, \"save/Deep_learning_G_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-14T06:33:04.948Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list.append(sum(h_list)/testing_label[index])\n",
    "    \n",
    "\n",
    "print(max(result_list),min(result_list),max(result_list)-min(result_list))\n",
    "print(sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-14T06:33:04.950Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-14T06:33:04.951Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate 10000 testing data on GeneratorNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-14T06:33:04.953Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "GeneratorNet = torch.load(\"save/Deep_learning_G_3\")\n",
    "def appen_test_G(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data_G.append(temp_list)\n",
    "    testing_label_G.append(S)\n",
    "# fake painting from G (random ideas)\n",
    "\n",
    "def read_testing_data_G():\n",
    "    for i in range(10000):\n",
    "        #appen_test_G(sorted(np.random.rand(Agent_number_n), reverse=True));\n",
    "        G_ideas = torch.randn(N_IDEAS).to(dev)  # random ideas\\n\n",
    "        G_values = GeneratorNet(G_ideas)\n",
    "        G_values , indices = torch.sort(G_values, descending=True)\n",
    "        appen_test_G(G_values.detach().cpu().numpy()) \n",
    "        \n",
    "testing_data_G = []\n",
    "testing_label_G = []\n",
    "read_testing_data_G()\n",
    "testing_data_G=np.array(testing_data_G)\n",
    "testing_label_G=np.array(testing_label_G)\n",
    "print(testing_data_G)\n",
    "print(testing_label_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-14T06:33:04.955Z"
    }
   },
   "outputs": [],
   "source": [
    "result_list_G = []\n",
    "for index in range(len(testing_data_G)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data_G[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list_G.append(sum(h_list)/testing_label_G[index])\n",
    "    \n",
    "\n",
    "print(max(result_list_G),min(result_list_G),max(result_list_G)-min(result_list_G))\n",
    "print(sum(result_list_G)/len(result_list_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-14T06:33:04.956Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list_G,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list_G)/len(result_list_G), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list_G.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list_G)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list_G)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-14T06:33:04.957Z"
    }
   },
   "outputs": [],
   "source": [
    "final_list = result_list + result_list_G\n",
    "\n",
    "\n",
    "plt.hist(final_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(final_list)/len(final_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "final_list.sort()\n",
    "\n",
    "plt.axvline(x=final_list[int(len(final_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=final_list[int(len(final_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
