{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:20:36.654920Z",
     "start_time": "2021-06-13T14:20:35.021199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pygame\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm \n",
    "import matplotlib.cm as cm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy.interpolate import griddata\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "print(dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:20:36.670095Z",
     "start_time": "2021-06-13T14:20:36.655880Z"
    }
   },
   "outputs": [],
   "source": [
    "global temp_list\n",
    "temp_list = []\n",
    "Agent_number_n=10;\n",
    "Alpha = 0.88 \n",
    "\n",
    "# Hyper Parameters\n",
    "echo = 1001\n",
    "BATCH_SIZE = 64\n",
    "LR_G = 0.001           # learning rate for generator\n",
    "LR_D = 0.001           # learning rate for discriminator\n",
    "N_IDEAS = Agent_number_n             # think of this as number of ideas for generating an art work (Generator)\n",
    "ART_COMPONENTS = Agent_number_n     # it could be total point G can draw in the canvas\n",
    "\n",
    "Is_GAN = False # if use Gan\n",
    "\n",
    "def Generate_distribution(Agent_number_n):\n",
    "    return sorted(np.random.rand(Agent_number_n), reverse=True)\n",
    "    #return np.random.normal(normalloc,normalscale,Agent_number_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:20:37.214473Z",
     "start_time": "2021-06-13T14:20:36.672073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.92908944 0.9238923  0.81454866 ... 0.33441051 0.28301784 0.06169448]\n",
      "  [0.92985081 0.9238923  0.81454866 ... 0.33441051 0.28301784 0.06169448]\n",
      "  [0.92985081 0.92908944 0.81454866 ... 0.33441051 0.28301784 0.06169448]\n",
      "  ...\n",
      "  [0.92985081 0.92908944 0.9238923  ... 0.58110395 0.28301784 0.06169448]\n",
      "  [0.92985081 0.92908944 0.9238923  ... 0.58110395 0.33441051 0.06169448]\n",
      "  [0.92985081 0.92908944 0.9238923  ... 0.58110395 0.33441051 0.28301784]]\n",
      "\n",
      " [[0.74991026 0.63953542 0.46576121 ... 0.23968198 0.12710764 0.09434247]\n",
      "  [0.79403216 0.63953542 0.46576121 ... 0.23968198 0.12710764 0.09434247]\n",
      "  [0.79403216 0.74991026 0.46576121 ... 0.23968198 0.12710764 0.09434247]\n",
      "  ...\n",
      "  [0.79403216 0.74991026 0.63953542 ... 0.41964813 0.12710764 0.09434247]\n",
      "  [0.79403216 0.74991026 0.63953542 ... 0.41964813 0.23968198 0.09434247]\n",
      "  [0.79403216 0.74991026 0.63953542 ... 0.41964813 0.23968198 0.12710764]]\n",
      "\n",
      " [[0.81575326 0.70601747 0.6585112  ... 0.44410111 0.42441597 0.387479  ]\n",
      "  [0.89873791 0.70601747 0.6585112  ... 0.44410111 0.42441597 0.387479  ]\n",
      "  [0.89873791 0.81575326 0.6585112  ... 0.44410111 0.42441597 0.387479  ]\n",
      "  ...\n",
      "  [0.89873791 0.81575326 0.70601747 ... 0.48064727 0.42441597 0.387479  ]\n",
      "  [0.89873791 0.81575326 0.70601747 ... 0.48064727 0.44410111 0.387479  ]\n",
      "  [0.89873791 0.81575326 0.70601747 ... 0.48064727 0.44410111 0.42441597]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.92853397 0.81243669 0.67868578 ... 0.07876478 0.02079504 0.0161285 ]\n",
      "  [0.97444739 0.81243669 0.67868578 ... 0.07876478 0.02079504 0.0161285 ]\n",
      "  [0.97444739 0.92853397 0.67868578 ... 0.07876478 0.02079504 0.0161285 ]\n",
      "  ...\n",
      "  [0.97444739 0.92853397 0.81243669 ... 0.20643223 0.02079504 0.0161285 ]\n",
      "  [0.97444739 0.92853397 0.81243669 ... 0.20643223 0.07876478 0.0161285 ]\n",
      "  [0.97444739 0.92853397 0.81243669 ... 0.20643223 0.07876478 0.02079504]]\n",
      "\n",
      " [[0.83046764 0.74821658 0.59614141 ... 0.28230738 0.24288464 0.19053614]\n",
      "  [0.90121843 0.74821658 0.59614141 ... 0.28230738 0.24288464 0.19053614]\n",
      "  [0.90121843 0.83046764 0.59614141 ... 0.28230738 0.24288464 0.19053614]\n",
      "  ...\n",
      "  [0.90121843 0.83046764 0.74821658 ... 0.46167855 0.24288464 0.19053614]\n",
      "  [0.90121843 0.83046764 0.74821658 ... 0.46167855 0.28230738 0.19053614]\n",
      "  [0.90121843 0.83046764 0.74821658 ... 0.46167855 0.28230738 0.24288464]]\n",
      "\n",
      " [[0.75547795 0.64465803 0.62555856 ... 0.11202111 0.07455058 0.00895727]\n",
      "  [0.9552004  0.64465803 0.62555856 ... 0.11202111 0.07455058 0.00895727]\n",
      "  [0.9552004  0.75547795 0.62555856 ... 0.11202111 0.07455058 0.00895727]\n",
      "  ...\n",
      "  [0.9552004  0.75547795 0.64465803 ... 0.18323557 0.07455058 0.00895727]\n",
      "  [0.9552004  0.75547795 0.64465803 ... 0.18323557 0.11202111 0.00895727]\n",
      "  [0.9552004  0.75547795 0.64465803 ... 0.18323557 0.11202111 0.07455058]]]\n",
      "[6.02371502 4.41845449 6.00394907 ... 4.55444911 5.23809859 4.05154284]\n"
     ]
    }
   ],
   "source": [
    "def h_3_star(a, b, t):\n",
    "    return a - min(a, t) + b - min(b, t) + max(min(a, t)+min(b, t), 2*t/3) + 1/2 * max(min(a, t)+min(b, t), t) - 1/2 * max(max(min(a, t), min(b, t)), 2*t/3) - t/6\n",
    "\n",
    "\n",
    "def f_function(a, b, z):\n",
    "    if(z >= 1):\n",
    "        return (a+b)/2 + z/3\n",
    "    else:\n",
    "        return z/3 + h_3_star(a, b, 1-z)/2\n",
    "\n",
    "def h_function_label(input_list):\n",
    "    #input_list = sorted(input_list)\n",
    "    g_list = []\n",
    "    for j1 in range(len(input_list) ):\n",
    "        for j2 in range(len(input_list)):\n",
    "            if(j1 != j2):\n",
    "                a = input_list[j1]\n",
    "                b = input_list[j2]\n",
    "                z = sum(input_list)- a-b\n",
    "\n",
    "                g_list.append( f_function(a, b, z) * (Agent_number_n-1))\n",
    "    h = sum(g_list) * 3 /  (Agent_number_n) /  (Agent_number_n-1) /  (Agent_number_n - 2)\n",
    "    return h\n",
    "\n",
    "def appen(_x_list,y):\n",
    "    global temp_list\n",
    "    temp_list.append(_x_list)\n",
    "    \n",
    "def appen_train(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "        \n",
    "        h = h_function_label(temp)\n",
    "        h_list.append(float(h))\n",
    "    temp_list = np.array(temp_list)\n",
    "    x_list = np.array(x_list)\n",
    "    return temp_list,S,x_list,h_list\n",
    "    \n",
    "\n",
    "def appen_test(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data.append(temp_list)\n",
    "    testing_label.append(S)\n",
    "    temp_list = np.array(temp_list)\n",
    "    return temp_list,S\n",
    "    \n",
    "\n",
    "def read_testing_data():\n",
    "    for i in range(10000):\n",
    "        appen_test(Generate_distribution(Agent_number_n));\n",
    "                            \n",
    "\n",
    "testing_data=[]\n",
    "testing_label=[]\n",
    "S=1.0\n",
    "read_testing_data();\n",
    "\n",
    "testing_data=np.array(testing_data)\n",
    "testing_label=np.array(testing_label)\n",
    "print(testing_data)\n",
    "print(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:12.169972Z",
     "start_time": "2021-06-13T14:20:37.216471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.025175795443372 8.999999999999995 0.02517579544337778 9.000027992251558\n"
     ]
    }
   ],
   "source": [
    "def h_3_star(a, b, t):\n",
    "    return a - min(a, t) + b - min(b, t) + max(min(a, t)+min(b, t), 2*t/3) + 1/2 * max(min(a, t)+min(b, t), t) - 1/2 * max(max(min(a, t), min(b, t)), 2*t/3) - t/6\n",
    "\n",
    "\n",
    "def f_function(a, b, z):\n",
    "    if(z >= 1):\n",
    "        return (a+b)/2 + z/3\n",
    "    else:\n",
    "        return z/3 + h_3_star(a, b, 1-z)/2\n",
    "\n",
    "def h_function(input_list):\n",
    "    #input_list = sorted(input_list)\n",
    "    g_list = []\n",
    "    for j1 in range(len(input_list) ):\n",
    "        for j2 in range(len(input_list)):\n",
    "            if(j1 != j2):\n",
    "                a = input_list[j1]\n",
    "                b = input_list[j2]\n",
    "                z = sum(input_list)- a-b\n",
    "\n",
    "                g_list.append( f_function(a, b, z) * (Agent_number_n-1))\n",
    "    h = sum(g_list) * 3 /  (Agent_number_n) /  (Agent_number_n-1) /  (Agent_number_n - 2)\n",
    "    return h\n",
    "                \n",
    "                \n",
    "x_list = []\n",
    "y_list = []\n",
    "z_list = []\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        x_list.append(testing_data[index][i][0])\n",
    "        y_list.append(testing_data[index][i][1])\n",
    "        h = h_function(testing_data[index][i])\n",
    "        z_list.append(float(h))\n",
    "        h_list.append(float(h))\n",
    "    result_list.append(sum(h_list)/testing_label[index]) \n",
    "    \n",
    "    \n",
    "print(max(result_list), min(result_list), max(result_list)-min(result_list),sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:13.101281Z",
     "start_time": "2021-06-13T14:21:12.170710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:13.116206Z",
     "start_time": "2021-06-13T14:21:13.102242Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.input_dim = (Agent_number_n-1)\n",
    "        self.hidden_dim = 128\n",
    "        self.output_dim = 1\n",
    "        self.hidden_layer_count = 6 \n",
    "        \n",
    "        current_dim = self.input_dim\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(self.hidden_layer_count):\n",
    "            self.layers.append(torch.nn.Linear(current_dim, self.hidden_dim))\n",
    "            current_dim = self.hidden_dim\n",
    "        self.layers.append(torch.nn.Linear(current_dim, self.output_dim))\n",
    "\n",
    "    def calculate(self, value_list):\n",
    "        h = value_list\n",
    "        LeakyReLU = torch.nn.LeakyReLU()\n",
    "        for layer in self.layers:\n",
    "            h = torch.relu(layer(h))\n",
    "        return h\n",
    "\n",
    "    def forward(self, input_list,input_label,list_x):\n",
    "        global iteration,echo,target_order\n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        loss3 = 0\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).to(dev).type(torch.float32)\n",
    "        h_list = []\n",
    "\n",
    "        for i in range(Agent_number_n):\n",
    "            h = self.calculate(input_list[i])\n",
    "            h_list.append(h)\n",
    "#             loss3 += torch.square(h_function_2(input_list)-h2[1])\n",
    "            \n",
    "        input_label = torch.from_numpy(\n",
    "            np.array(input_label)).to(dev).type(torch.float32)\n",
    "        sum_h = torch.sum(torch.cat(h_list)).to(dev)\n",
    "\n",
    "\n",
    "        loss1 = torch.where((Agent_number_n-1)*input_label>sum_h,\n",
    "                        torch.square(((Agent_number_n-1)*input_label-sum_h)),\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "        loss2 = torch.where((Agent_number_n-Alpha)*input_label<sum_h,\n",
    "                        torch.square((sum_h-(Agent_number_n-Alpha)*input_label))/100,\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "\n",
    "        return loss1,loss2\n",
    "    \n",
    "    def supervised_loss(self, input_list,label):\n",
    "        global iteration,echo,target_order\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).to(dev).type(torch.float32)\n",
    "        loss = 0 \n",
    "        for i in range(Agent_number_n):\n",
    "            h = self.calculate(input_list[i])\n",
    "            loss += torch.square(h - label[i])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:13.131815Z",
     "start_time": "2021-06-13T14:21:13.118184Z"
    }
   },
   "outputs": [],
   "source": [
    "def redistribution_value_function(input_tensor):\n",
    "    S = torch.max(torch.sum(input_tensor), torch.ones(1).to(dev))\n",
    "    temp_list = []\n",
    "\n",
    "\n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        \n",
    "        for j in range(Agent_number_n):\n",
    "            if(i != j):\n",
    "                temp .append(input_tensor[j])\n",
    "                \n",
    "        temp = torch.stack(temp)\n",
    "        temp_list.append(temp)\n",
    "    return torch.stack(temp_list), S\n",
    "\n",
    "GeneratorNet = nn.Sequential(                      # Generator\n",
    "    # random ideas (could from normal distribution)\n",
    "    nn.Linear(N_IDEAS, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    # making a painting from these random ideas\n",
    "    nn.Linear(64, ART_COMPONENTS),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:14.789451Z",
     "start_time": "2021-06-13T14:21:13.133583Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "DiscriminatorNet  = Net()\n",
    "DiscriminatorNet.apply(weight_init)\n",
    "GeneratorNet.apply(weight_init)\n",
    "# DiscriminatorNet = torch.load(\"save/Deep_learning_D_10_2\")\n",
    "# if(Is_GAN):\n",
    "#     GeneratorNet = torch.load(\"save/Deep_learning_G_10_2\")\n",
    "DiscriminatorNet.to(dev)\n",
    "GeneratorNet.to(dev)\n",
    "\n",
    "opt_D = torch.optim.Adam(DiscriminatorNet.parameters(), lr=LR_D)\n",
    "opt_G = torch.optim.Adam(GeneratorNet.parameters(), lr=LR_G)\n",
    "\n",
    "\n",
    "scheduler_D = torch.optim.lr_scheduler.StepLR(opt_D, step_size=100, gamma=0.98)\n",
    "scheduler_G = torch.optim.lr_scheduler.StepLR(opt_G, step_size=100, gamma=0.98)\n",
    "\n",
    "index_train_list = []\n",
    "index_test_list = []\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:15.628686Z",
     "start_time": "2021-06-13T14:21:14.793453Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0cdad87c013a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         training_data_i, training_S, training_data,label = appen_train(\n\u001b[0;32m     13\u001b[0m             Generate_distribution(Agent_number_n))\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mh_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDiscriminatorNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupervised_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mdenominator\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloss_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mh_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-91a196676522>\u001b[0m in \u001b[0;36msupervised_loss\u001b[1;34m(self, input_list, label)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAgent_number_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "#supervised\n",
    "index_supervisedtrain_list = []\n",
    "supervisedtrain_losses = []\n",
    "for iteration in range(int(echo)):\n",
    "\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "    \n",
    "    loss_sum = 0\n",
    "    denominator = 0\n",
    "    for index in range(0, BATCH_SIZE):\n",
    "        training_data_i, training_S, training_data,label = appen_train(\n",
    "            Generate_distribution(Agent_number_n))\n",
    "        h_loss = DiscriminatorNet.supervised_loss(training_data_i, label)\n",
    "        denominator += 1\n",
    "        loss_sum += h_loss\n",
    "\n",
    "    loss_sum = torch.sum(loss_sum)\n",
    "    loss = (loss_sum) / denominator \n",
    "    total_batch_loss += float(loss_sum)\n",
    "\n",
    "    opt_D.zero_grad()\n",
    "    loss.backward()\n",
    "    opt_D.step()\n",
    "\n",
    "    temp_number = iteration\n",
    "    index_train_list.append(iteration)\n",
    "    train_losses.append(total_batch_loss)\n",
    "    scheduler_D.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:15.632676Z",
     "start_time": "2021-06-13T14:20:34.993Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylim(0, 1.0)\n",
    "plt.plot(index_supervisedtrain_list ,supervisedtrain_losses)\n",
    "plt.ylabel('supervised train loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:15.633686Z",
     "start_time": "2021-06-13T14:20:34.995Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#unsupervised\n",
    "train_losses = []\n",
    "for iteration in range(int(echo)):\n",
    "\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "        \n",
    "    loss2_list = []\n",
    "    loss1_sum = 0\n",
    "    loss2_sum = 0\n",
    "    denominator = 0\n",
    "    for index in range(0, BATCH_SIZE):\n",
    "        training_data_i, training_label, training_data, label = appen_train(\n",
    "            Generate_distribution(Agent_number_n))\n",
    "        h_loss1, h_loss2 = DiscriminatorNet(training_data_i, training_label,\n",
    "                                       training_data)\n",
    "        denominator += 1\n",
    "        loss1_sum += h_loss1\n",
    "        loss2_sum += h_loss2\n",
    "\n",
    "    loss_sum = torch.sum(loss1_sum + loss2_sum)\n",
    "    loss = (loss_sum) / denominator \n",
    "    total_batch_loss +=float(loss_sum)\n",
    "\n",
    "    opt_D.zero_grad()\n",
    "    loss.backward()\n",
    "    opt_D.step()\n",
    "\n",
    "    temp_number = iteration\n",
    "    index_train_list.append(iteration)\n",
    "    train_losses.append(total_batch_loss)\n",
    "\n",
    "    if (iteration%100 == 0):\n",
    "        print(temp_number,loss,float(loss1_sum),float(loss2_sum))\n",
    "    ## Gan \n",
    "        if(Is_GAN):## Gan Work traning GeneratorNet\n",
    "\n",
    "            DiscriminatorNet.requires_grad = True\n",
    "            GeneratorNet.requires_grad = True\n",
    "\n",
    "\n",
    "            for step in range(100):\n",
    "                # real painting from artist\n",
    "                G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                                      requires_grad=True).to(dev)  # random ideas\\n\n",
    "                # fake painting from G (random ideas)\n",
    "\n",
    "                G_values = GeneratorNet(G_ideas)\n",
    "                G_values , indices = torch.sort(G_values, descending=True)\n",
    "            #     print(artist_paintings)\n",
    "            #     print(G_paintings)\n",
    "\n",
    "                result_list = []\n",
    "                for index in range(BATCH_SIZE):\n",
    "                    h_list = []\n",
    "                    value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                        G_values[index])\n",
    "                    for i in range(Agent_number_n):\n",
    "                        h = DiscriminatorNet.calculate(\n",
    "                            value_list_tensor[i].cuda().type(torch.float32))\n",
    "                        h_list.append(h)\n",
    "                    h_list = torch.stack(h_list)\n",
    "                    result_list.append(torch.sum(h_list)/S_tensor.cuda())\n",
    "                result_list = torch.stack(result_list)\n",
    "\n",
    "                diff_loss = torch.max(result_list)-torch.min(result_list)\n",
    "                G_loss = torch.max(- diff_loss)\n",
    "\n",
    "                opt_G.zero_grad()\n",
    "                G_loss.backward()\n",
    "                opt_G.step()\n",
    "\n",
    "            # real painting from artist\n",
    "                G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                                      requires_grad=True).to(dev)  # random ideas\\n\n",
    "                # fake painting from G (random ideas)\n",
    "\n",
    "                G_values = GeneratorNet(G_ideas)\n",
    "                G_values , indices = torch.sort(G_values, descending=True)\n",
    "            #     print(artist_paintings)\n",
    "            #     print(G_paintings)\n",
    "\n",
    "                result_list = []\n",
    "                for index in range(BATCH_SIZE):\n",
    "                    h_list = []\n",
    "                    value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                        G_values[index])\n",
    "                    for i in range(Agent_number_n):\n",
    "                        h = DiscriminatorNet.calculate(\n",
    "                            value_list_tensor[i].cuda().type(torch.float32))\n",
    "                        h_list.append(h)\n",
    "                    h_list = torch.stack(h_list)\n",
    "                    result_list.append(torch.sum(h_list)/S_tensor.cuda())\n",
    "                result_list = torch.stack(result_list)\n",
    "\n",
    "                diff_loss = torch.max(result_list)-torch.min(result_list)\n",
    "\n",
    "                D_loss = torch.where((Agent_number_n-1)>torch.min(result_list),\n",
    "                    torch.square(((Agent_number_n-1)-torch.min(result_list))),\n",
    "                    torch.zeros(1).to(dev)\n",
    "                  )   + torch.where((Agent_number_n-Alpha)<torch.max(result_list),\n",
    "                                torch.square((torch.max(result_list)-(Agent_number_n-Alpha)))/10000,\n",
    "                                torch.zeros(1).to(dev)\n",
    "                              )\n",
    "\n",
    "\n",
    "                opt_D.zero_grad()\n",
    "                D_loss.backward()\n",
    "                opt_D.step()\n",
    "                \n",
    "            print(\"Gan:\",G_loss,D_loss)\n",
    "            print()\n",
    "\n",
    "        result_list = []\n",
    "        for index in range(len(testing_data)):\n",
    "            h_list = []\n",
    "            for i in range(Agent_number_n):\n",
    "                h = DiscriminatorNet.calculate(\n",
    "                    torch.tensor(testing_data[index][i]).to(dev).type(\n",
    "                        torch.float32))\n",
    "                h_list.append(float(h))\n",
    "            result_list.append(sum(h_list) / testing_label[index])\n",
    "        print(max(result_list), min(result_list),\n",
    "              max(result_list) - min(result_list),\n",
    "              (sum(result_list) / len(result_list) - min(result_list))+ Agent_number_n-1 - min(min(result_list),Agent_number_n-1) )\n",
    "\n",
    "        index_test_list.append(iteration)\n",
    "        test_losses.append(\n",
    "            (sum(result_list) / len(result_list) - min(result_list))+ Agent_number_n-1 - min(min(result_list),Agent_number_n-1) )\n",
    "        print()\n",
    "        index_test_list.append(iteration)\n",
    "        test_losses.append(\n",
    "            max(result_list)-min(result_list) )\n",
    "        \n",
    "        print()\n",
    "\n",
    "    scheduler_D.step()\n",
    "    scheduler_G.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:15.634672Z",
     "start_time": "2021-06-13T14:20:34.997Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylim(0, 1.0)\n",
    "plt.plot(index_test_list,test_losses)\n",
    "plt.ylabel('test loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:15.635668Z",
     "start_time": "2021-06-13T14:20:34.999Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(DiscriminatorNet, \"save/Deep_learning_D_10_2\")\n",
    "if(Is_GAN):\n",
    "    torch.save(GeneratorNet, \"save/Deep_learning_G_10_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:15.637662Z",
     "start_time": "2021-06-13T14:20:35.000Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list.append(sum(h_list)/testing_label[index])\n",
    "    \n",
    "\n",
    "print(max(result_list),min(result_list),max(result_list)-min(result_list))\n",
    "print(sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:15.638662Z",
     "start_time": "2021-06-13T14:20:35.002Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:15.639678Z",
     "start_time": "2021-06-13T14:20:35.003Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate 10000 testing data on GeneratorNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:15.641652Z",
     "start_time": "2021-06-13T14:20:35.005Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#GeneratorNet = torch.load(\"save/Deep_learning_G_10_1\")\n",
    "def appen_test_G(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data_G.append(temp_list)\n",
    "    testing_label_G.append(S)\n",
    "# fake painting from G (random ideas)\n",
    "\n",
    "def read_testing_data_G():\n",
    "    for i in range(10000):\n",
    "        #appen_test_G(sorted(np.random.rand(Agent_number_n), reverse=True));\n",
    "        G_ideas = torch.randn(N_IDEAS).to(dev)  # random ideas\\n\n",
    "        G_values = GeneratorNet(G_ideas)\n",
    "        G_values , indices = torch.sort(G_values, descending=True)\n",
    "        appen_test_G(G_values.detach().cpu().numpy()) \n",
    "        \n",
    "testing_data_G = []\n",
    "testing_label_G = []\n",
    "read_testing_data_G()\n",
    "testing_data_G=np.array(testing_data_G)\n",
    "testing_label_G=np.array(testing_label_G)\n",
    "print(testing_data_G)\n",
    "print(testing_label_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:15.642662Z",
     "start_time": "2021-06-13T14:20:35.008Z"
    }
   },
   "outputs": [],
   "source": [
    "result_list_G = []\n",
    "for index in range(len(testing_data_G)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data_G[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list_G.append(sum(h_list)/testing_label_G[index])\n",
    "    \n",
    "\n",
    "print(max(result_list_G),min(result_list_G),max(result_list_G)-min(result_list_G))\n",
    "print(sum(result_list_G)/len(result_list_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:15.644644Z",
     "start_time": "2021-06-13T14:20:35.010Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list_G,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list_G)/len(result_list_G), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list_G.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list_G)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list_G)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T14:21:15.645641Z",
     "start_time": "2021-06-13T14:20:35.013Z"
    }
   },
   "outputs": [],
   "source": [
    "final_list = result_list + result_list_G\n",
    "\n",
    "\n",
    "plt.hist(final_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(final_list)/len(final_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "final_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(final_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(final_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
