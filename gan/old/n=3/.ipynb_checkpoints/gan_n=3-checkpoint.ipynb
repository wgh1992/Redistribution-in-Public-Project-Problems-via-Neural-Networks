{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T11:32:51.805466Z",
     "start_time": "2021-06-10T11:32:50.175282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pygame\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm \n",
    "import matplotlib.cm as cm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy.interpolate import griddata\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "print(dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T11:32:51.830263Z",
     "start_time": "2021-06-10T11:32:51.807496Z"
    }
   },
   "outputs": [],
   "source": [
    "global temp_list\n",
    "temp_list = []\n",
    "Agent_number_n=3;\n",
    "Alpha = 0.666 \n",
    "\n",
    "# Hyper Parameters\n",
    "echo = 10001 \n",
    "BATCH_SIZE = 64\n",
    "LR_G = 0.001           # learning rate for generator\n",
    "LR_D = 0.001           # learning rate for discriminator\n",
    "N_IDEAS = Agent_number_n             # think of this as number of ideas for generating an art work (Generator)\n",
    "ART_COMPONENTS = Agent_number_n     # it could be total point G can draw in the canvas\n",
    "\n",
    "Is_GAN = True # if use Gan\n",
    "\n",
    "def Generate_distribution(Agent_number_n):\n",
    "    return sorted(np.random.rand(Agent_number_n), reverse=True)\n",
    "    #return np.random.normal(normalloc,normalscale,Agent_number_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T11:32:52.024449Z",
     "start_time": "2021-06-10T11:32:51.830263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.8657132  0.20610024]\n",
      "  [0.60466908 0.20610024]\n",
      "  [0.60466908 0.8657132 ]]\n",
      "\n",
      " [[0.81320959 0.37562245]\n",
      "  [0.59801476 0.37562245]\n",
      "  [0.59801476 0.81320959]]\n",
      "\n",
      " [[0.99096299 0.14715245]\n",
      "  [0.46944378 0.14715245]\n",
      "  [0.46944378 0.99096299]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.49357472 0.06930237]\n",
      "  [0.94713965 0.06930237]\n",
      "  [0.94713965 0.49357472]]\n",
      "\n",
      " [[0.29919109 0.21946603]\n",
      "  [0.63379549 0.21946603]\n",
      "  [0.63379549 0.29919109]]\n",
      "\n",
      " [[0.96543641 0.84016379]\n",
      "  [0.40433671 0.84016379]\n",
      "  [0.40433671 0.96543641]]]\n",
      "[1.67648253 1.7868468  1.60755922 ... 1.51001674 1.15245262 2.2099369 ]\n"
     ]
    }
   ],
   "source": [
    "def appen(_x_list,y):\n",
    "    global temp_list\n",
    "    temp_list.append(_x_list)\n",
    "    \n",
    "def appen_train(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    \n",
    "    temp_list = np.array(temp_list)\n",
    "    x_list = np.array(x_list)\n",
    "    return temp_list,S,x_list\n",
    "    \n",
    "\n",
    "def appen_test(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data.append(temp_list)\n",
    "    testing_label.append(S)\n",
    "    temp_list = np.array(temp_list)\n",
    "    return temp_list,S\n",
    "    \n",
    "    \n",
    "# def read_training_data():\n",
    "#     for i in range(100000):\n",
    "#         appen_train(sorted(np.random.rand(Agent_number_n), reverse=True));\n",
    "\n",
    "def read_testing_data():\n",
    "    for i in range(10000):\n",
    "        appen_test(Generate_distribution(Agent_number_n));\n",
    "        \n",
    "        \n",
    "                            \n",
    "# training_data=[]\n",
    "# training_label=[]\n",
    "# S=1.0\n",
    "# read_training_data();\n",
    "\n",
    "testing_data=[]\n",
    "testing_label=[]\n",
    "S=1.0\n",
    "read_testing_data();\n",
    "\n",
    "# training_data=np.array(training_data)\n",
    "# training_label=np.array(training_label)\n",
    "testing_data=np.array(testing_data)\n",
    "testing_label=np.array(testing_label)\n",
    "# print(training_data)\n",
    "print(testing_data)\n",
    "# print(training_label)\n",
    "print(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T11:32:52.729718Z",
     "start_time": "2021-06-10T11:32:52.024449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.333149054167669 2.0 0.33314905416766916 2.103010836407417\n"
     ]
    }
   ],
   "source": [
    "def h_3_star(a, b, t):\n",
    "    return a - min(a, t) + b - min(b, t) + max(min(a, t)+min(b, t), 2*t/3) + 1/2 * max(min(a, t)+min(b, t), t) - 1/2 * max(max(min(a, t), min(b, t)), 2*t/3) - t/6\n",
    "\n",
    "\n",
    "def f_function(a, b, z):\n",
    "    if(z >= 1):\n",
    "        return (a+b)/2 + z/3\n",
    "    else:\n",
    "        return z/3 + h_3_star(a, b, 1-z)/2\n",
    "\n",
    "def h_function(input_list):\n",
    "    #input_list = sorted(input_list)\n",
    "    g_list = []\n",
    "    for j1 in range(len(input_list) ):\n",
    "        for j2 in range(len(input_list)):\n",
    "            if(j1 != j2):\n",
    "                a = input_list[j1]\n",
    "                b = input_list[j2]\n",
    "                z = sum(input_list)- a-b\n",
    "\n",
    "                g_list.append( f_function(a, b, z) * (Agent_number_n-1))\n",
    "    h = sum(g_list) * 3 /  (Agent_number_n) /  (Agent_number_n-1) /  (Agent_number_n - 2)\n",
    "    return h\n",
    "                \n",
    "                \n",
    "x_list = []\n",
    "y_list = []\n",
    "z_list = []\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        x_list.append(testing_data[index][i][0])\n",
    "        y_list.append(testing_data[index][i][1])\n",
    "        h = h_function(testing_data[index][i])\n",
    "        z_list.append(float(h))\n",
    "        h_list.append(float(h))\n",
    "    result_list.append(sum(h_list)/testing_label[index]) \n",
    "    \n",
    "    \n",
    "print(max(result_list), min(result_list), max(result_list)-min(result_list),sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T11:32:53.674944Z",
     "start_time": "2021-06-10T11:32:52.730715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEpCAYAAABbU781AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfbxWdZ3v/9cb5E5QQQEF0bYYKiBqgv5EzZjxdgqzNM9RxwaqGcqxTjTHJp3pcXRKfzkdx7HmVBPdDHZK0lFnMkvHtLDJ1ARTQEglJWRAQcQb7u8+54+1wMvtvlns6+a7r73ez8djP67rWtd3rfXel9vrw3et73ctRQRmZma10Ct1ADMz6zlcVMzMrGZcVMzMrGZcVMzMrGZcVMzMrGZcVMzMrGZcVMzMrGZcVMw6ICnyn52SDu+g3S8q2k5vYESzbsVFxaxz2wEBH2vrTUljgPfk7cxKzUXFrHMvAfOAj0jaq433/5ys6Nzd0FRm3ZCLilkx3wIOAqZWLpTUB5gG/Bp4qr2VJe0v6UuSlkjaJOk1SQ9IOquNtvtJ+qykn0taIWmrpDWS7pJ0UjvbD0lzJQ2VNEvSKklbJD0l6SNttJekaZJ+nW97s6QXJP2HpP++h5+N2W4uKmbFzAE2kPVKKr0fOJCs6LRJ0juA+cCVwBrgn4FbgbHAvZL+otUqY4HrgJ3AT4AbgZ8Bfwz8p6Rz2tnVYOAhYDJwO/A9YCTwXUnTWrW9DphNVihvy/dxP3AwcGF7v4tZZ+QLSpq1T1IA/xURoyR9G5gOtETEivz9e8m+xEcAfwP8LfCRiJhdsY25wGnAJRHxw4rlg4G5wJH5Nl/Kl+8H9ImIl1tlGQX8BngtIsa2kRPgO8DHI2JHvnwcsAB4JiLGVbRfC2wCjoiIja22NbT1vs2Kck/FrLhvAb2Bj8LuHsiZwA9afzHvIulYspP4d1QWFICIeBW4GugPXFCx/LW2vtTzQnY7cJSkQ9vY3Ubgr3YVlHydxWS9l7GS9mnVfhuwo9UyXFCsGm2ddDSzNkTEo5IWAh+VdC3ZobBedHDoi6wXA7CfpGvaeH9Y/ti653EK8Ol8/eFA31brHQwsb7Xs2Yh4vY19vJA/DgbeyJ//APgU8JSkfwUeBB6OiNc6+F3MOuWiYrZnvgV8FTgH+AgwPyJ+20H7A/LHM/Of9gza9UTSB8l6JJvJzqX8nux8zk5gClnPp18b23i1nW3vGurcu2LZZ/LtfpTsXM+VwHZJPwX+Z0Qs7SCrWbtcVMz2zP8F/h74Jllv4QudtN/1L/9PR8RXC+7ji8BWYFJELKl8Q9I3yYpKVfJDZF8BviJpOHAqcBHZSfrxksZHxJZq92Pl43MqZnsgPw9yOzCKrPcwp5NVHskf370Hu3knsLiNgtKL7Mu/piJidUTcGRH/Dfg5cDhwdK33Y+XgomK25z4PfBA4OyLe6KhhRMwD/hM4X9JH22ojaULeW9hlGTBG0siKNiI7qT+OKknqJ+n0fJuVy/sA++cv2xx4YNYZH/4y20MRsZy3nyTvyCVkPYDvSPofwKNk5z9GAceQ9QomA6vz9v9INpflt5LuIBuldQpZQfkxcG6Vv8IAsjkpyyQ9CvyBbATamWQDBu5q3UsyK8pFxazOImKFpIlko60uAP6U7KT5i8Bi4J+AhRXtvylpCzCTbLb+JrLezkfy9astKhuAzwF/BJwMfIBsVNjvgcuA71a5fSsxT340M7Oa8TkVMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVMzOrmdLPqB86dGi0tLR0ad033oB9Wt/2yOpry1rYuQV69YN+B3Te3qwn6IZfNvPnz385Ioa1Xl76otLS0sK8efO6tO7KlTByZOftrIbunwKrH4Th74Ez5qZOY9YY3fDLRtIf2lruw19VmDUrdQIzK4Um+rJJXlQkfVfSakmLKpbtL+lnkp7NH4dUvHeVpKWSnpZ0dsXyiZIW5u99tfVlvevhAB99MbNGaKIvm+RFBZhNdmvWSlcCD0TEGOCB/DWSxpHdnW58vs7XJe26Reo3gBnAmPyn9TZrbsqUeu/BzIym+rJJfk4lIn4pqaXV4vPI7sUNcDMwl+xS3ecBP8xvc/q8pKXAiZKWAftGxMMAkr5Hdjnve+qZ/Y47YMKEeu7B9sS2bdtYsWIFmzdvTh3FWunfvz+jRo2iT58+qaM0pyb6skleVNpxYESsAoiIVRV3xTuYN2/PCrAiX7Ytf956eV010T8eeo7R02H4FBjU8ra3VqxYwT777ENLSwsNOPppBUUEa9euZcWKFRx22GGp4zSnJvqy6a5FpT1tfVNEB8vb3og0g+xQGYceemiXw6xc2eVVratGT2/3rc2bN7ugdEOSOOCAA1izZk3qKM2rib5susM5lba8JGkEQP646zarK4BDKtqNAlbmy0e1sbxNETErIiZFxKRhw942zLqwZ57p8qpWJy4o3ZP/u1Spib5sumtRuYvsNqrkjz+qWH6RpH6SDiM7If+b/FDZG5JOykd9/VnFOnUzY0a992DWvilTpnR5jpU1mSb6skleVCTNAR4GjpS0QtLHgOuBMyU9C5yZvyYingJuI7uv973A5RGxI9/UZcC3gaVk99qu60l6aKqh4z3Hc7NhwTXZo1lZNNGXTfKiEhEXR8SIiOgTEaMi4jsRsTYiTo+IMfnjKxXtr4uIwyPiyIi4p2L5vIg4On/vkxHR7jmVWvmnRxbWexfW2nOzYdHfdcuismHDBt73vvdx7LHHcvTRR3PrrbcC8IUvfIETTjiBo48+mhkzZrDrT3PKlCl85jOf4bTTTmPs2LE89thjnH/++YwZM4bPf/7zACxbtoyjjjqKadOmccwxx/ChD32IjRs3vm3f9913H5MnT+b444/nwgsvZP369W9rU2R/AN///vc58cQTOe644/j4xz/Ojh3Zv9suu+wyJk2axPjx47n66qt3t29paeHqq6/m+OOPZ8KECfzud7+r3YdqmREjUicoLHlRaWZ9D3o1dQTrRu69915GjhzJk08+yaJFizjnnGyq1Cc/+Ukee+wxFi1axKZNm7j77rt3r9O3b19++ctf8olPfILzzjuPr33tayxatIjZs2ezdu1aAJ5++mlmzJjBggUL2Hffffn617/+lv2+/PLLXHvttdx///08/vjjTJo0iRtvvLHNjJ3tb8mSJdx666089NBDPPHEE/Tu3Zsf/OAHAFx33XXMmzePBQsW8OCDD7JgwYLd2x06dCiPP/44l112GTfccENNP1cDJk1KnaCwZhv91a1sWnpg6gjWkedmd96jGXIcTLzpzdfrnoD5M9tuO3p6h6PPJkyYwBVXXMHnPvc5pk6dyrvf/W4AfvGLX/DlL3+ZjRs38sorrzB+/HjOPfdcAN7//vfvXnf8+PGMyP9FOnr0aF544QUGDx7MIYccwimnnALApZdeyle/+lWuuOKK3ft95JFHWLx48e42W7duZfLkyW1m7Gx/v/rVr5g/fz4nnHACAJs2bWL48GxE/2233casWbPYvn07q1atYvHixRxzzDEAnH/++QBMnDiRO++8s93PyLroxz+GiRNTpyjERaUK/VteBo5IHcPas35ZdvHJPbH11fbXGT6lw1WPOOII5s+fz09/+lOuuuoqzjrrLP76r/+av/zLv2TevHkccsghXHPNNW+ZnNmvXz8AevXqtfv5rtfbt28H3j5yqvXriODMM89kzpw5nf56ne0vIpg2bRpf+tKX3rLe888/zw033MBjjz3GkCFDmD59epu/R+/evXfntho666zUCQrz4a8qbF83MHUE68igluxqxh39DDnurev0Hdx+2zYmXFZauXIle++9N5deeilXXHEFjz/++O4v3qFDh7J+/Xpuv/32Pf41li9fzsMPPwzAnDlzOPXUU9/y/kknncRDDz3E0qVLAdi4cSPPdHEI6umnn87tt9/O6tXZKP5XXnmFP/zhD7z++usMHDiQ/fbbj5deeol77qn7OBir1ERDit1TqcL21wakjmAd6eRwVZuGHNflS+ovXLiQz372s/Tq1Ys+ffrwjW98g8GDB/MXf/EXTJgwgZaWlt2HlfbE2LFjufnmm/n4xz/OmDFjuOyyy97y/rBhw5g9ezYXX3wxW7ZsAeDaa6/liCP2vBc9btw4rr32Ws466yx27txJnz59+NrXvsZJJ53Eu971LsaPH8/o0aN3H2qzBlm2LHWCwtSAQVLd2qRJk6KrY/1HXX4/K752Ro0TWYc6uJ/KkiVLGDt2bJJY9bJs2TKmTp3KokWLOm/czfXE/z4N0z3vpzI/It42gsCHv6qw/smuX+LFzKywJpqn4sNfVdhrv02pI5TPrnMgrc+F9FAtLS09opdiVeriLc9TcFGpwl5DNqSOUD6Vw3/NyqIL58dS8eGvKmxeNjR1BGul7OcIuyv/d6nSffelTlCYi0oVBrzzpdQRrEL//v1Zu3atv8C6mV33U+nfv3/qKM0rnyzbDHz4qwpbXxycOkL5rHsim6DYd/DbzquMGjWKFStW+L4d3dCuOz9aF82b5xn1ZbBjfb/OG1ltzZ/Z7pDiPn36+M6C1jOtWpU6QWE+/FWFQccuTx3BzMrA91MpB89TMbOGaKJ5Ki4qVeizv4cUm1kDeEhxOfQetLnzRmZm1epml2jpiItKFTYvPyB1BDMrg7lzUycozEWlCnsf+WLqCGZWBhdckDpBYS4qVXBPxcwawj2Vcti5qU/qCGZWBmvXpk5QmCc/ViGbp9I8ozJ6hC7eQMusqXmeSjl4noqZNYTnqZRDn2FvpI5gZmUwYULqBIW5qFShV5/tqSOYWRkMGpQ6QWEuKlXYsnJI6gjlc/8UuEXZo1lZPPxw6gSFuahUYeDYlakjmFkZXHxx6gSFuahUYdPvh6eOYGZlcPfdqRMU5qJShdjhj8/MGmDLltQJCvO3YhUGjvPhLzNrgEsuSZ2gMBeVKqxf6NujmlkDzJ6dOkFhLipV6HvQa6kjmFkZNMn96cFFxczMaqhbFxVJn5H0lKRFkuZI6i9pf0k/k/Rs/jikov1VkpZKelrS2fXOt/XF/eq9CzMzmD8/dYLCuu0FJSUdDPwPYFxEbJJ0G3ARMA54ICKul3QlcCXwOUnj8vfHAyOB+yUdERE76pVx0IQV+IKSDTbxJtj6KvQdnDqJWeNMn546QWHduqdCVvQGSNoL2BtYCZwH3Jy/fzPwgfz5ecAPI2JLRDwPLAVOrGe4DYub5xafPcaQ4+DAKdmjWVncckvqBIV126ISEf8F3AAsB1YBr0XEfcCBEbEqb7MK2DUD8WDghYpNrMiX1Y1676zn5s3MMv36pU5QWLctKvm5kvOAw8gOZw2UdGlHq7SxLNrZ9gxJ8yTNW7NmTZczDjh8dZfXNTMrbOrU1AkK67ZFBTgDeD4i1kTENuBO4GTgJUkjAPLHXd/sK4BDKtYfRXa47G0iYlZETIqIScOGDetywA1LfPir4ebPzC4mOX9m6iRmjTNnTuoEhXXnorIcOEnS3pIEnA4sAe4CpuVtpgE/yp/fBVwkqZ+kw4AxwG/qGbDfyHX13Ly1Zd0TsPrB7NGsLCZPTp2gsE5Hf0k6AvgG2bmMoyUdA7w/Iq6tZ7CIeFTS7cDjwHbgt8AsYBBwm6SPkRWeC/P2T+UjxBbn7S+v58gvgJ3buu3gOTPrSdavT52gsCI9lW8BVwHbACJiAdnQ3bqLiKsj4qiIODoiPpyP7FobEadHxJj88ZWK9tdFxOERcWRE3FPvfNvW7FPvXZiZwcKFqRMUVqSo7B0RrQ8j+ZaHwKBjl6eOYGZlMGNG6gSFFSkqL0s6nHwklaQPkQ3xLb31Tx6aOoKZlcGsWakTFFbkpMDlZOcyjpL0X8DzQEdDe0uj14BtqSOYWRkccEDqBIV1WlQi4jngDEkDgV4R8Ub9YzWH/oeuTR3BzMpgypTUCQrr9PCXpP9f0uCI2BARb0gaIqmuI7+axcanD0odwczK4I47UicorMg5lT+JiFd3vYiIdcB76xepebinksDo6XD01dmjWVk0UU+lyDmV3pL6RcQWAEkDgOa5EE0d7VjfP3WE8nExsTJa2Ty3Li9SVL4PPCDpX8hGgH2UN68SXGrbXhmYOoKZlcEzz6ROUFiRE/VflrSQ7DIpAr4YEf9R92RNIJun4vupmFmdNdE8lULXGclnp9d9hnqz8TyVBJ6bDeuXwaAWHwqz8pg1C665JnWKQoqM/jo/v3Xva5Jel/SGpNcbEa676z1oS+oI5fPcbFj0d9mjWVmMGJE6QWFFeipfBs6NiCX1DtNs+h70aueNzMyqNWlS6gSFFRlS/JILSts2LT0wdQQzK4Mf/zh1gsKK9FTmSboV+Hdg9/GeiLizbqmaRP+Wl/GJejOru7POSp2gsCJFZV9gI1D5WwXZnRhLbfs6Dyk2swZ45hk4+eTUKQopMqT4I40I0oy2vzYgdQQzK4Nly1InKKzI6K8jJD0gaVH++hhJn69/tO7P91Mxs4Zoonkq3frOj92d56mYWUP0sPup7B0Rv5FUucx3fgT22m9T6gjlM+S4tz6alUFLS+oEhRUpKr7zYzv2GrIhdYTymXhT6gRmjXdE84wyLXL463Lgm7x558eZwCfqmqpJbF42NHUEMyuD++5LnaCwDnsqknoDl0WE7/zYhgHvfAnPUzGzujv33NQJCuuwpxIRO4CJ+fMNLihvtfXFwakjlM+6J+CludmjWVnMm5c6QWFFzqn8VtJdwL8Cu08ieEY97Fjve5U13PyZsPpBGP4eOGNu6jRmjbGqeU5jFykq+wNrgT+uWOYZ9fh+KmbWIE00T8Uz6qvgeSpm1hBNdD+VTotKxW2E3yIiPlqXRE2kz/4eUmxmDdBEQ4qLHP66u+J5f+CDwMr6xGkuvQdtTh3BzMpg5MjUCQorcvjrjsrXkuYA99ctURPZvPyA1BHMrAzmzoUpU1KnKKTI5MfWxgA+mQDsfeSLqSOYWRlccEHqBIUVOafyBm89p/Ii8Lm6JWoi7qmYWUPMnQsTJqROUUiRw1/7NCJIM9q5qU/qCGZWBmvXpk5QWJGeygeBn0fEa/nrwcCUiPj3eofr7jxPJQFPeLQyaqJ5KkXOqVy9q6AARMSrwNX1i/QmSYMl3S7pd5KWSJosaX9JP5P0bP44pKL9VZKWSnpa0tn1zud5KmbWEE10P5UiRaWtNkWGItfCV4B7I+Io4FhgCXAl8EBEjAEeyF8jaRzZzcPGA+cAX88viFk3fYb5Umhm1gBNcj4FihWVeZJulHS4pNGS/hGYX+9gkvYFTgO+AxARW/Ne0nnAzXmzm4EP5M/PA34YEVsi4nlgKXBiPTP26uN7lZlZAwwalDpBYUWKyqeArcCtwG3AJrJ7rNTbaGAN8C+Sfivp2/nl9w+MiFUA+ePwvP3BwAsV66/Il9XNlpVDOm9ktXX/FLhF2aNZWTz8cOoEhRUZ/bWB/BBTg+0FHA98KiIelfSVTnKojWVvu7wMgKQZwAyAQw/t+nmRgWNX4hP1ZlZ3F1+cOkFhnfZU8pPhgyteD5H0H/WNBWQ9jRUR8Wj++nayIvOSpBF5lhHA6or2h1SsP4p2LicTEbMiYlJETBo2bFiXA276/fDOG5mZVevuuztv000UOfw1ND+XAUBErOPNQ051ExEvAi9IOjJfdDqwGLgLmJYvmwb8KH9+F3CRpH6SDiOb+f+bumbc0ZULEpiZ7aEtW1InKKzIKK6dkg6NiOUAkt5BO4eV6uBTwA8k9QWeAz5CVghvk/QxYDlwIUBEPCXpNrLCsx24PL9zZd0MHLcSOKqeuzAzg0suSZ2gsCJF5W+BX0l6MH99Gvn5iHqLiCeASW28dXo77a8DrqtrqArrF45q1K7MrMxmz+4591OJiHslHQ+clC/6TES8XN9YzaHvQa913sjMrFoTJ6ZOUFjRSYwnk/VQdmmes0ZmZtYwRUZ/XQ98muxcxWLg05K+VO9gzWDri/uljmBmZTC/7vPNa6ZIT+W9wHERsRNA0s3Ab4Gr6hmsGQyasALPU2mwiTfB1leh7+DO25r1FNOnp05QWNExsZX/B/uf57kNi5vnFp89xpDj4MAp2aNZWdxyS+oEhRXpqXwJ+K2kX5DNWj8N91IAUO+dqSOYWRn065c6QWFFRn/NkTQXOIGsqHwun5hYegMOXw2MSx3DzHq6qVNTJyis0OGviFgVEXdFxI9cUN60YYkPfzXc/JnZxSTnz0ydxKxx5sxJnaCwRt0XpUfqN3Jd6gjls+4JWP1g5+3MepLJk1MnKKzdnkp+/SzrwM5trslm1gDr16dOUFhHh79uB5D0QIOyNJ1ta/ZJHcHMymDhwtQJCuvon9q9JF0NHCHpr1q/GRE31i9Wcxh07HI8T8XM6m5GQy63WBMd9VQuAjaTFZ592vgpvfVPdv0GX2Zmhc2alTpBYe32VCLiaeDvJS2IiHsamKlp9BqwLXUEMyuDAw5InaCwIkOKfy3pRknz8p9/kORZ9UD/Q9emjmBmZTBlSuoEhRUpKt8F3gD+W/7zOvAv9QzVLDY+fVDqCGZWBnfckTpBYUXGxB4eERdUvP47SU/UK1AzcU8lgdHTYfgUGNSSOIhZAzVRT6VIUdkk6dSI+BWApFOATfWN1Rx2rO+fOkL5jJ6eOoFZ461cmTpBYUWKyieA71WcR1kHTKtfpOax7ZWBqSOYWRk880zqBIUVuaDkk8CxkvbNX79e91RNwvNUzKwhesg8lbeIiNddUN7K81QSeG42LLgmezQri54wT8U613vQltQRyue52dkFJYe/x+dXrDxGjEidoLDCPRV7u74HvZo6gpmVwaRJqRMU1mlRySc8Xi5pSCMCNZNNSw9MHcHMyuDHP06doLAiPZWLgJHAY5J+KOlsSapzrqbQv+Xl1BHMrAzOOit1gsI6LSoRsTQi/pZsmNMtZDPsl0v6O0n71ztgd7Z9nYcUm1kDNNGQ4kLnVCQdA/wD8L+BO4APkV2u5ef1i9b9bX9tQOoIZlYGy5alTlBYp6O/JM0HXgW+A1wZEbuGPD2az64vLc9TMbOG6GHzVC6MiNMj4paKggJARJxfp1xNwfNUzKwhmmieSpGi8ueSBu96IWmIpGvrmKlp7LWfL4HWcEOOy+aoDDkudRKzxmlpSZ2gsCKTH/8kIv5m14uIWCfpvcDn6xerOew1ZEPqCOUz8abUCcwa74jmOcxepKfSW1K/XS8kDQD6ddC+NDYvG5o6gpmVwX33pU5QWJGeyveBByT9CxDAR4Gb65qqSQx450v4RL2Z1d2556ZOUFiReSpfBq4DxgLjgS/myxpCUm9Jv5V0d/56f0k/k/Rs/jikou1VkpZKelrS2fXOtvXFwZ03stpa9wS8NDd7NCuLefNSJyis0AUlI+Ie4J46Z2nPp4ElwL756yuBByLieklX5q8/J2kc2ez/8WRXALhf0hERsaNewXas91HAhps/880LSp4xN3Uas8ZYtSp1gsKKXPvr/LxX8Jqk1yW9Iakhl8CXNAp4H/DtisXn8ebht5uBD1Qs/2FEbImI54GlwIn1zJfNUzEzq7MeNk/ly8D7I2K/iNg3IvaJiH07Xas2bgL+GthZsezAiFgFkD8Oz5cfDLxQ0W5FvqxuPE/FzBqih81TeSkiltQ9SSuSpgKrI2J+0VXaWBbtbHtGfvXleWvWrOlyxj77e0ixmTVAEw0pLnJOZZ6kW4F/B3bPqI+IO+uWKnMK8P58Tkx/YF9J3wdekjQiIlZJGgGsztuvAA6pWH8UsLKtDUfELGAWwKRJk9osPEX0HrS5q6uamRU3cmTqBIUV6ansC2wEzgLOzX+m1jMUQERcFRGjIqKF7AT8zyPiUuAuYFrebBrwo/z5XcBFkvpJOgwYA/ymnhk3Lz+gnps3M8vMnZs6QWGd9lQi4iONCLIHrgduk/QxYDlwIUBEPCXpNmAxsB24vJ4jvwD2PvJFPE/FzOruggtSJyisyOivIyQ9IGlR/voYSQ29REtEzI2IqfnztfkFLsfkj69UtLsuIg6PiCPzYdB15Z6KmTVEE/VUihz++hZwFbANICIWkB2OKr2dm/qkjmBmZbB2beoEhRU5Ub93RPym1R2Et9cpT1Px/VQS8IRHK6MeNk/lZUmHkw/PlfQhoHmmd9aR56mYWUM00TyVIj2Vy8mG3x4l6b+A54FL65qqSfQZ9kbqCGZWBhMmpE5QWJHRX88BZ0gaCPSKCH+T5nr18VFAM2uAQYNSJyisyD3q/1er1wBExBfqlKlpbFk5pPNGVlv3T/EFJa18Hn4Yzq77hddrosg5lQ0VPzuAPwFa6pipaQwc2+aEfTOz2rr44tQJCity+OsfKl9LuoFs9nrpbfr98M4bmZlV6+674cgjU6copEhPpbW9gdG1DtKMYkdXPj4zsz20ZUvnbbqJIudUFvLm1X57A8OA0p9PARg4biVwVOoYZtbTXXJJ6gSFFRlSXHnxyO1kl8L3sCdg/cJRqSOYWRnMng3XXJM6RSFFikrrIcT7Vs6ur7z2Vtn0Pei11BHMrAwmTkydoLAiReVxsvuUrCO7EdZgsqsDQ3ZYzOdXzMwMKHai/l7g3IgYGhEHkB0OuzMiDouIUheUrS/ulzqCmZXB/KI3wE2vSE/lhIj4xK4XEXGPpC/WMVPTGDRhBb6gZINNvAm2vgp9B6dOYtY406enTlBY0QtKfl5Si6R3SPpboHmuw1xHGxY3zy0+e4whx8GBU7JHs7K45ZbUCQorUlQuJhtG/G/5z7B8Wemp987UEcysDPr1S52gsCIz6l8BPi1pUESsb0CmpjHg8NXAuNQxzKynmzq18zbdRJHbCZ8saTHZvd+RdKykr9c9WRPYsMSHvxpu/szsopLzZ6ZOYtY4c+akTlBYkRP1/wicTX69r4h4UtJpdU3VJPqNXJc6QvmseyK7SrFZmUyenDpBYYUuXhURL7RatKMOWZrOzm1FarKZWZXWN8+ZhyJF5QVJJwMhqa+kK4Aldc7VFLat2Sd1BDMrg4ULUycorEhR+QTZLYUPBlYAx+WvS2/Qscs7b2RmVq0ZM1InKKzDoiKpN3BTRPxpRBwYEcMj4tKI8IW05hMAAA3sSURBVDwVYP2Th6aOYGZlMGtW6gSFdVhUImIHMExS3wblaSq9BmxLHcHMyuCAA1InKKzImeZlwEOS7iK7pTAAEXFjvUI1i/6HusNmZg0wZUrqBIUVOaeyErg7b7tPxU/pbXz6oNQRzKwM7rgjdYLC2u2pSPq/EfFh4NWI+EoDMzUN91QSGD0dhk+BQS2Jg5g1UBP1VDo6/DVR0juAj0r6Htm9VHYr8825dtmxvn/qCOUzenrqBGaNt3Jl6gSFdVRU/pnsXiqjgfm8taj45lzAtlcGpo5gZmXwzDOpExTW7jmViPhqRIwFvhsRo/Obch3mm3O9yfNUzKwheso8FYCIuKwRQZqR56kk8NxsWHBN9mhWFk00T8UXr6pC70FbUkcon+dmZxeUHP4en1+x8hgxInWCwgpdUNLa1vegV1NHMLMymDQpdYLCum1RkXSIpF9IWiLpKUmfzpfvL+lnkp7NH4dUrHOVpKWSnpZ0dr0zblp6YL13YWYGP/5x6gSFdduiAmwH/mc+WOAk4HJJ44ArgQciYgzwQP6a/L2LgPHAOcDX82uX1U3/lpfruXkzs8xZZ6VOUFi3LSoRsSoiHs+fv0F2uf2DgfOAm/NmNwMfyJ+fB/wwIrZExPPAUuDEembcvs5Dis2sAXrCkOLuRFIL8C7gUeDAiFgFWeEBhufNDgYqbya2Il9WN9tfG1DPzZuZZZYtS52gsG5fVCQNAu4AZkbE6x01bWNZtLPNGZLmSZq3Zs2aLmfzPBUza4ieNE8lJUl9yArKDyLiznzxS5JG5O+PAFbny1cAh1SsPorsYphvExGzImJSREwaNmxYl/N5noqZNUQTzVPptkVFkoDvAEtaXWb/LmBa/nwa8KOK5RdJ6ifpMGAM8Jt6Ztxrv0313Ly1Zchx2RyVIcelTmLWOC0tqRMU1p0nP54CfBhYKOmJfNnfANcDt0n6GLAcuBAgIp6SdBuwmGzk2OX5TcbqZq8hGzpvZLU18abUCcwa74gjUicorNsWlYj4FW2fJwE4vZ11rgOuq1uoVjYvG9qoXZlZmd13H5x8cuoUhXTbw1/NYMA7X0odwczK4NxzUycozEWlCltfHJw6QvmsewJemps9mpXFvHmpExTmolKFHev7pY5QPvNnwgN/lD2alcWqVakTFOaiUgXPUzGzhvA8lXLwPBUzawjPUymHPvt7SLGZNUATDSl2UalC70GbU0cwszIYOTJ1gsJcVKqwefkBqSOYWRnMnZs6QWEuKlXY+8gXU0cwszK44ILUCQpzUamCeypm1hDuqZTDzk19UkcwszJYuzZ1gsK67bW/mkE2T6V5RmX0CGfMTZ3ArPE8T6UcPE/FzBrC81TKoc+wN1JHMLMymDAhdYLCXFSq0KvP9tQRzKwMBg1KnaAwF5UqbFk5JHWE8rl/Ctyi7NGsLB5+OHWCwlxUqjBw7MrUEcysDC6+OHWCwlxUqrDp98NTRzCzMrj77tQJCnNRqULs8MdnZg2wZUvqBIX5W7EKA8f58JeZNcAll6ROUJiLShXWLxyVOoKZlcHs2akTFOaiUoW+B72WOoKZlcHEiakTFOaiYmZmNeOiUoWtL+6XOoKZlcH8+akTFOYLSlZh0IQV+IKSDTbxJtj6KvQdnDqJWeNMn546QWHuqVRhw+LmucVnjzHkODhwSvZoVha33JI6QWEuKlVQ752pI9Rcy5U/SR3BzFrr1y91gsJcVKow4PDVqSMU1l6xcBExawJTp6ZOUJiLShU2LGn84a/KIlC0ULS1TmfFpL12yYvQ/JnZxSTnz0ybw6yR5sxJnaAwF5Uq9Bu5bo/aF/mCbuvLvMiylit/svunK3k6W7fy/c7ytPd7Fi1oHVr3BKx+MHs0K4vJk1MnKMxFpQo7t3Vt8Fx7xaStL+OOCk9n22tvWWfr7+n2i/SYihSkjrZVRPJelFm9rF+fOkFhLipV2LZmn93POyoURXsdtVbtdous31lx2JPeT3u9nbaK6yPPrS3wG3RdVz67oocUzfbYwoWpExTmolKFQccub7d3UfRcxJ72MvZUM3+RtVVcKotJkUNtrZ93tKzIe3tiTw9HFt3/nmZv5r8By82YkTpBYT2uqEg6R9LTkpZKurKe+1r/5KFAjc4VWJd1VFja6vEU7VW2t62i55c6y9vW+bCuHmos0q6j3mB72ytyPqyrxbO99bvy/1OP/39v1qzUCQpTRKTOUDOSegPPAGcCK4DHgIsjYnF760yaNCnmzZvXpf3tf+ZT7DtxWZfWta754egrOWnQIh5ZfzQXPXd9Tba57Pr3Ff5S2pO2tVarfbe1ncply65/H9D5F3VneXZtp1LlPlqu/Emh/bbezq71Kp+33kZHWq9fdL2k/umf4FOfSp3iLSTNj4hJb1vew4rKZOCaiDg7f30VQER8qb11qikqIz/2S/oOe6NL61rX1KOoNIuUBS21rv7ulcULOi6Urdvu0l4hbK8wtlX0KrfVVpb22uy2cCFMmLCnv35dlaWofAg4JyL+PH/9YeD/i4hPtrdONUVl8KnPMPjUZ7u0rnVNmYuKlc+uIjXzVz/gplP/tN33O1p313Oobc+sLEXlQuDsVkXlxIj4VKt2M4BdZ76OBJ7u4i6HAi93cd2UmjF3M2YG526kZswMzZv7HRExrPXCnnaV4hXAIRWvRwFvu+dvRMwCqj7zJWleW5W6u2vG3M2YGZy7kZoxMzRv7vb0tNFfjwFjJB0mqS9wEXBX4kxmZqXRo3oqEbFd0ieB/wB6A9+NiKcSxzIzK40eVVQAIuKnwE8btLvmGTz+Vs2Yuxkzg3M3UjNmhubN3aYedaLezMzS6mnnVMzMLCEXlVYkHSLpF5KWSHpK0qfbaCNJX80vBbNA0vEV7zXsMjE1zr1M0kJJT0jq2sSd+uU+StLDkrZIuqLVe9358+4od8M/74KZ/zT/21gg6deSjq14rzt/1h3l7s5/2+flmZ+QNE/SqRXvJfm8qxYR/qn4AUYAx+fP9yG77Mu4Vm3eC9wDCDgJeDRf3hv4PTAa6As82Xrd7pg7f28ZMLSbft7DgROA64ArKpZ398+7zdypPu+CmU8GhuTP/6SJ/rbbzJ3qs96D3IN48zTEMcDvUn/e1f64p9JKRKyKiMfz528AS4CDWzU7D/heZB4BBksaAZwILI2I5yJiK/DDvG13z51MkdwRsToiHgO2tVq9W3/eHeROomDmX0fErrvPPUI21wu6/2fdXu5kCuZeH3kVAQYCu54n+7yr5aLSAUktwLuAR1u9dTDwQsXrFfmy9pY3VBdyQ/bHfJ+k+fkVBxqug9zt6e6fd0eSft4FM3+MrGcLzfVZV+aGbv63LemDkn4H/AT4aL64W3zeXdHjhhTXiqRBwB3AzIh4vfXbbawSHSxvmC7mBjglIlZKGg78TNLvIuKX9cz6lmAd5253tTaWdafPuyPJPu8imSX9EdmX865j/E3xWbeRG7r533ZE/Bvwb5JOA74InEE3+Ly7yj2VNkjqQ/ZH8IOIuLONJu1dDqbQZWLqpYrcRMSux9XAv5F1vxuiQO72dPfPu12pPu8imSUdA3wbOC8idt0Vrdt/1u3kbpq/7bzQHS5pKIk/72q4qLQiScB3gCURcWM7ze4C/iwfTXUS8FpErCLhZWKqyS1poKR98u0MBM4CFnWj3O3p7p93e+sm+byLZJZ0KHAn8OGIeKbirW79WbeXu7v/bUt6Z94OZaMx+wJraeJLTnnyYyv5kL7/BBYCO/PFfwMcChAR/5z/Efwf4BxgI/CRiJiXr/9e4CbevEzMdd09t6TRZP+Cg+yQ6C3dLPdBwDxg37zNerKRMK9388+7zdxkV6Vt+OddMPO3gQuAP+Tvb4/8Yofd/LNuM3cT/G1/DvgzssEcm4DPRsSv8vWTfN7VclExM7Oa8eEvMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVMzOrGRcVsyYkaa6kSalzmLXmomJmZjXjomJWI/n90H8i6UlJiyT9d0n/S9Jj+etZFfcjnyvpHyX9UtISSSdIulPSs5Kuzdu0SPqdpJslLZB0u6S929jvWZIelvS4pH+VNChffr2kxfm6NzT207CyclExq51zgJURcWxEHA3cC/yfiDghfz0AmFrRfmtEnAb8M/Aj4HLgaGC6pAPyNkcCsyLiGOB14C8rdyhpKPB54IyIOB6YB/yVpP2BDwLj83Wvrc+vbPZWLipmtbMQOEPS30t6d0S8BvyRpEclLQT+GBhf0f6uivWeiohVEbEFeA44JH/vhYh4KH/+feDUVvs8CRgHPCTpCWAa8A6yArQZ+Lak84GNNf1NzdqxV+oAZj1FRDwjaSLwXuBLku4j631MiogXJF0D9K9YZUv+uLPi+a7Xu/7fjNa7afVawM8i4uLWeSSdCJwOXAR8kqyomdWVeypmNSJpJLAxIr4P3AAcn7/1cn6e40Nd2Oyhkibnzy8GftXq/UeAUyS9M8+wt6Qj8v3tFxE/BWYCx3Vh32Z7zD0Vs9qZAPxvSTuBbcBlwAfIDm8tAx7rwjaXANMkfRN4FvhG5ZsRsUbSdGCOpH754s8DbwA/ktSfrDfzmS7s22yPKaJ1b9rMugNJLcDd+Ul+s6bgw19mZlYz7qmYmVnNuKdiZmY146JiZmY146JiZmY146JiZmY146JiZmY146JiZmY18/8A6JS46kr9exsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T11:32:53.692941Z",
     "start_time": "2021-06-10T11:32:53.676957Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.input_dim = (Agent_number_n-1)\n",
    "        self.hidden_dim = 64\n",
    "        self.output_dim = 1\n",
    "        self.hidden_layer_count = 6 \n",
    "        \n",
    "        current_dim = self.input_dim\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(self.hidden_layer_count):\n",
    "            self.layers.append(torch.nn.Linear(current_dim, self.hidden_dim))\n",
    "            current_dim = self.hidden_dim\n",
    "        self.layers.append(torch.nn.Linear(current_dim, self.output_dim))\n",
    "\n",
    "    def calculate(self, value_list):\n",
    "        h = value_list\n",
    "        for layer in self.layers:\n",
    "            h = torch.relu(layer(h))\n",
    "        return h\n",
    "\n",
    "    def forward(self, input_list,input_label,label):\n",
    "        global iteration,echo,target_order\n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        loss3 = 0\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).to(dev).type(torch.float32)\n",
    "        h_list = []\n",
    "\n",
    "        for i in range(Agent_number_n):\n",
    "            h = self.calculate(input_list[i])\n",
    "            h_list.append(h)\n",
    "#             loss3 += torch.square(h_function_2(input_list)-h2[1])\n",
    "            \n",
    "        input_label = torch.from_numpy(\n",
    "            np.array(input_label)).to(dev).type(torch.float32)\n",
    "        sum_h = torch.sum(torch.cat(h_list)).to(dev)\n",
    "\n",
    "\n",
    "        loss1 = torch.where((Agent_number_n-1)*input_label>sum_h,\n",
    "                        torch.square(((Agent_number_n-1)*input_label-sum_h)),\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "        loss2 = torch.where((Agent_number_n-Alpha)*input_label<sum_h,\n",
    "                        torch.square((sum_h-(Agent_number_n-Alpha)*input_label))/10000,\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "\n",
    "        return loss1,loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T11:32:53.715100Z",
     "start_time": "2021-06-10T11:32:53.695990Z"
    }
   },
   "outputs": [],
   "source": [
    "def redistribution_value_function(input_tensor):\n",
    "    S = torch.max(torch.sum(input_tensor), torch.ones(1).to(dev))\n",
    "    temp_list = []\n",
    "\n",
    "\n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        \n",
    "        for j in range(Agent_number_n):\n",
    "            if(i != j):\n",
    "                temp .append(input_tensor[j])\n",
    "                \n",
    "        temp = torch.stack(temp)\n",
    "        temp_list.append(temp)\n",
    "    return torch.stack(temp_list), S\n",
    "\n",
    "GeneratorNet = nn.Sequential(                      # Generator\n",
    "    # random ideas (could from normal distribution)\n",
    "    nn.Linear(N_IDEAS, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    # making a painting from these random ideas\n",
    "    nn.Linear(64, ART_COMPONENTS),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T11:32:54.847729Z",
     "start_time": "2021-06-10T11:32:53.717147Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "DiscriminatorNet  = Net()\n",
    "DiscriminatorNet.apply(weight_init)\n",
    "GeneratorNet.apply(weight_init)\n",
    "#DiscriminatorNet = torch.load(\"save/Deep_learning_D_3_1\")\n",
    "#GeneratorNet = torch.load(\"save/Deep_learning_G_3_1\")\n",
    "DiscriminatorNet.to(dev)\n",
    "GeneratorNet.to(dev)\n",
    "\n",
    "opt_D = torch.optim.Adam(DiscriminatorNet.parameters(), lr=LR_D)\n",
    "opt_G = torch.optim.Adam(GeneratorNet.parameters(), lr=LR_G)\n",
    "\n",
    "\n",
    "scheduler_D = torch.optim.lr_scheduler.StepLR(opt_D, step_size=100, gamma=0.98)\n",
    "scheduler_G = torch.optim.lr_scheduler.StepLR(opt_G, step_size=100, gamma=0.98)\n",
    "\n",
    "index_train_list = []\n",
    "index_test_list = []\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-10T11:32:50.137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.2199e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 7.807487349964504e-07\n",
      "Gan: tensor(-1.1563, device='cuda:0', grad_fn=<MaxBackward1>) tensor([0.0004], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "4.563679612575127 3.1763148307800293 1.3873647817950978 0.8637841410686837\n",
      "\n",
      "\n",
      "100 tensor(5.7758e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.00036965051549486816\n",
      "Gan: tensor(-0.7071, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.1628e-05], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.9932062042560754 2.150183136049144 0.8430230682069313 0.34230566420415354\n",
      "\n",
      "\n",
      "200 tensor(1.2997e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 8.318346226587892e-05\n",
      "Gan: tensor(-0.4886, device='cuda:0', grad_fn=<MaxBackward1>) tensor([7.1252e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.7079930937686476 2.080212373794187 0.6277807199744605 0.2563256535993874\n",
      "\n",
      "\n",
      "300 tensor(2.2088e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0001413628488080576\n",
      "Gan: tensor(-0.4860, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.7604e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5742143665433366 1.9560589192037117 0.6181554473396249 0.31292607829810426\n",
      "\n",
      "\n",
      "400 tensor(3.5429e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.267463059979491e-05\n",
      "Gan: tensor(-0.5550, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.9357e-05], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.8778162026956697 2.213221490383148 0.6645947123125215 0.3094468856335775\n",
      "\n",
      "\n",
      "500 tensor(1.9596e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.254121343663428e-05\n",
      "Gan: tensor(-0.5034, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.1154e-05], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.7762090956818573 2.116067042976691 0.6601420527051665 0.2563525920958938\n",
      "\n",
      "\n",
      "600 tensor(5.3567e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.428256241022609e-05\n",
      "Gan: tensor(-0.3911, device='cuda:0', grad_fn=<MaxBackward1>) tensor([2.2588e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.586496715492142 2.0087945093507287 0.5777022061414132 0.23542730169206783\n",
      "\n",
      "\n",
      "700 tensor(3.0785e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.970243829418905e-05\n",
      "Gan: tensor(-0.3988, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.5088e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.6379038945626117 2.1032424386845756 0.534661455878036 0.23164677742561235\n",
      "\n",
      "\n",
      "800 tensor(7.8702e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 5.0369344535283744e-06\n",
      "Gan: tensor(-0.3746, device='cuda:0', grad_fn=<MaxBackward1>) tensor([7.1591e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5029030992966668 1.9975532053304002 0.5053498939662666 0.2200916213972004\n",
      "\n",
      "\n",
      "900 tensor(1.0010e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 6.406670763681177e-06\n",
      "Gan: tensor(-0.4070, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.0762e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.553255163297588 2.020241253516732 0.5330139097808559 0.22564929991917282\n",
      "\n",
      "\n",
      "1000 tensor(4.5406e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.905976771216956e-06\n",
      "Gan: tensor(-0.3562, device='cuda:0', grad_fn=<MaxBackward1>) tensor([8.3453e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.505445349299555 1.9987577670826586 0.5066875822168964 0.21483490444298736\n",
      "\n",
      "\n",
      "1100 tensor(1.0546e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 6.749637577740941e-06\n",
      "Gan: tensor(-0.4037, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.4235e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5751675680987653 2.0463319420814514 0.5288356260173139 0.22290717815009353\n",
      "\n",
      "\n",
      "1200 tensor(2.2547e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.4430057717618183e-06\n",
      "Gan: tensor(-0.5560, device='cuda:0', grad_fn=<MaxBackward1>) tensor([9.2252e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.741922717508938 1.9901936826800917 0.7517290348288461 0.2875218363660008\n",
      "\n",
      "\n",
      "1300 tensor(6.0606e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.878783172694966e-05\n",
      "Gan: tensor(-0.4024, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.7513e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.647687155465634 2.0066277097899143 0.6410594456757197 0.23930185502753298\n",
      "\n",
      "\n",
      "1400 tensor(3.2580e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.085137202811893e-05\n",
      "Gan: tensor(-0.6710, device='cuda:0', grad_fn=<MaxBackward1>) tensor([7.9018e-05], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "3.389387268126276 2.6540127396583557 0.7353745284679203 0.35466211616114185\n",
      "\n",
      "\n",
      "1500 tensor(6.3199e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 4.044705565320328e-05\n",
      "Gan: tensor(-0.5391, device='cuda:0', grad_fn=<MaxBackward1>) tensor([5.5922e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.7923129924496872 2.011547565460205 0.7807654269894821 0.4002601875374521\n",
      "\n",
      "\n",
      "1600 tensor(7.6094e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 4.869998974754708e-06\n",
      "Gan: tensor(-0.5752, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.3176e-05], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.8976911554105658 2.120807987205199 0.7768831682053667 0.26633918889685493\n",
      "\n",
      "\n",
      "1700 tensor(5.0398e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.225455293431878e-05\n",
      "Gan: tensor(-0.4588, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.2861e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.663904684604511 2.0337879006958364 0.6301167839086745 0.2156003830233888\n",
      "\n",
      "\n",
      "1800 tensor(1.3201e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 8.448590961052105e-06\n",
      "Gan: tensor(-0.3575, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.0454e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.6517915330344373 2.077499508857727 0.5742920241767102 0.21223978790404985\n",
      "\n",
      "\n",
      "1900 tensor(3.7178e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.3794123080733698e-06\n",
      "Gan: tensor(-0.3461, device='cuda:0', grad_fn=<MaxBackward1>) tensor([5.9550e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5562200804290134 2.0163800716400146 0.5398400087889987 0.19652072956668576\n",
      "\n",
      "\n",
      "2000 tensor(1.3527e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 8.657276566736982e-07\n",
      "Gan: tensor(-0.5239, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.1270e-05], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.8178410964406404 2.150039285669742 0.6678018107708983 0.236813886272643\n",
      "\n",
      "\n",
      "2100 tensor(2.3751e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.5200353118416388e-05\n",
      "Gan: tensor(-0.3794, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.0146e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5718165968234135 2.049817579702546 0.5219990171208675 0.17159556978535395\n",
      "\n",
      "\n",
      "2200 tensor(2.3852e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.5265327419911046e-06\n",
      "Gan: tensor(-0.3762, device='cuda:0', grad_fn=<MaxBackward1>) tensor([5.1400e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4916322101117987 1.9897408241967067 0.501891385915092 0.17619698841592912\n",
      "\n",
      "\n",
      "2300 tensor(1.8983e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.2149320127718966e-06\n",
      "Gan: tensor(-0.3502, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.3488e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.527200799388224 2.0182925392933777 0.5089082600948465 0.15669192607977367\n",
      "\n",
      "\n",
      "2400 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "Gan: tensor(-0.3447, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.7589e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5005253043673306 2.0011572523038117 0.49936805206351886 0.15461094977113232\n",
      "\n",
      "\n",
      "2500 tensor(2.5224e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.6143510947586037e-05\n",
      "Gan: tensor(-0.3419, device='cuda:0', grad_fn=<MaxBackward1>) tensor([4.2145e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.536973420032364 1.9947720170021057 0.5422014030302584 0.18054837000336832\n",
      "\n",
      "\n",
      "2600 tensor(2.5963e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.6616322682239115e-06\n",
      "Gan: tensor(-0.3392, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.7536e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5219390287734864 1.980993628501892 0.5409454002715943 0.19855428895766325\n",
      "\n",
      "\n",
      "2700 tensor(8.5875e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 5.496016797224001e-07\n",
      "Gan: tensor(-0.3404, device='cuda:0', grad_fn=<MaxBackward1>) tensor([6.0504e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5390045394813012 1.997288703918457 0.5417158355628442 0.1739472214711495\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800 tensor(2.3094e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.4780139281356242e-06\n",
      "Gan: tensor(-0.3393, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.6077e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.523547222741433 1.9965003728866577 0.5270468498547753 0.16270055542912543\n",
      "\n",
      "\n",
      "2900 tensor(1.6325e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.0447954537085025e-06\n",
      "Gan: tensor(-0.3443, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.5319e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.545734416656554 2.0154430866241455 0.5302913300324086 0.16243778760999472\n",
      "\n",
      "\n",
      "3000 tensor(4.2085e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.6934214929497102e-06\n",
      "Gan: tensor(-0.3396, device='cuda:0', grad_fn=<MaxBackward1>) tensor([4.5930e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5223910725495577 1.9987040162086487 0.5236870563409091 0.16350614539680253\n",
      "\n",
      "\n",
      "3100 tensor(6.9967e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 4.477909101296973e-07\n",
      "Gan: tensor(-0.3385, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.2633e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.515396822561041 1.9945214986801147 0.5208753238809263 0.16852010656991512\n",
      "\n",
      "\n",
      "3200 tensor(1.4018e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 8.971640568233852e-07\n",
      "Gan: tensor(-0.3370, device='cuda:0', grad_fn=<MaxBackward1>) tensor([2.5941e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5061602863007253 1.9861724376678467 0.5199878486328786 0.1809410431165004\n",
      "\n",
      "\n",
      "3300 tensor(4.3241e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.767427304206649e-06\n",
      "Gan: tensor(-0.3365, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.9118e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4976873950839606 1.9923657178878784 0.5053216771960822 0.16298112333084047\n",
      "\n",
      "\n",
      "3400 tensor(3.8021e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.433317831673776e-07\n",
      "Gan: tensor(-0.3357, device='cuda:0', grad_fn=<MaxBackward1>) tensor([8.6727e-10], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4861734175370533 1.9919013905453735 0.4942720269916798 0.1530654480807081\n",
      "\n",
      "\n",
      "3500 tensor(7.9869e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 5.111642735755595e-07\n",
      "Gan: tensor(-0.3360, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.8089e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5027514927198977 1.9931172728538513 0.5096342198660464 0.16404734481426475\n",
      "\n",
      "\n",
      "3600 tensor(2.4777e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.5857432345001143e-07\n",
      "Gan: tensor(-0.3343, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.3704e-12], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.48586152035194 1.9885223507881165 0.4973391695638236 0.1604399255897584\n",
      "\n",
      "\n",
      "3700 tensor(3.5317e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.2603107936447486e-06\n",
      "Gan: tensor(-0.3513, device='cuda:0', grad_fn=<MaxBackward1>) tensor([6.0263e-09], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4880032538120678 1.993160367012024 0.49484288680004385 0.15557168870996874\n",
      "\n",
      "\n",
      "3800 tensor(1.6964e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.085691891944407e-07\n",
      "Gan: tensor(-0.3456, device='cuda:0', grad_fn=<MaxBackward1>) tensor([7.1781e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.555969083092758 2.023577570915222 0.532391512177536 0.1856646003580793\n",
      "\n",
      "\n",
      "3900 tensor(1.5743e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.0075425507238833e-06\n",
      "Gan: tensor(-0.3295, device='cuda:0', grad_fn=<MaxBackward1>) tensor([0.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4558117357462192 1.9681981205940247 0.4876136151521946 0.19003226340478419\n",
      "\n",
      "\n",
      "4000 tensor(7.4429e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 4.763460765389027e-06\n",
      "Gan: tensor(-0.3501, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.2946e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5353841647929256 2.0163843035697937 0.5189998612231319 0.21873510513859395\n",
      "\n",
      "\n",
      "4100 tensor(1.0426e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 6.672427730336494e-07\n",
      "Gan: tensor(-0.3259, device='cuda:0', grad_fn=<MaxBackward1>) tensor([0.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.414270167416061 1.9536577463150024 0.4606124211010587 0.21989624423269616\n",
      "\n",
      "\n",
      "4200 tensor(6.1780e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.953923624067102e-06\n",
      "Gan: tensor(-0.3319, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.3372e-11], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4175397021588294 1.972875547240558 0.4446641549182715 0.17439831473447898\n",
      "\n",
      "\n",
      "4300 tensor(2.9413e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.8824595144906198e-06\n",
      "Gan: tensor(-0.3278, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.7692e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.554167832461085 1.9706732034683228 0.5834946289927623 0.31637077140542447\n",
      "\n",
      "\n",
      "4400 tensor(3.7483e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.398929609626066e-06\n",
      "Gan: tensor(-0.5278, device='cuda:0', grad_fn=<MaxBackward1>) tensor([4.9457e-05], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "3.2183638962954126 2.5410714444564855 0.6772924518389272 0.22332061677988957\n",
      "\n",
      "\n",
      "4500 tensor(3.8815e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0002484163560438901\n",
      "Gan: tensor(-0.6138, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.0326e-05], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.681268572807312 2.00731342339332 0.6739551494139921 0.24132252989416747\n",
      "\n",
      "\n",
      "4600 tensor(1.0158e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 6.500934978248551e-05\n",
      "Gan: tensor(-0.4619, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.5917e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.6004122421808935 2.06030285313165 0.5401093890492437 0.18410538165609935\n",
      "\n",
      "\n",
      "4700 tensor(8.8192e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 5.644309567287564e-06\n",
      "Gan: tensor(-0.3959, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.6655e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5567116588008445 2.0379682360268143 0.5187434227740302 0.17761970427704687\n",
      "\n",
      "\n",
      "4800 tensor(4.2311e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.707892235775944e-06\n",
      "Gan: tensor(-0.3967, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.0656e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5170507062115126 1.9985277491353728 0.5185229570761398 0.1800956814047756\n",
      "\n",
      "\n",
      "4900 tensor(9.9291e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 6.3546081037202384e-06\n",
      "Gan: tensor(-0.4176, device='cuda:0', grad_fn=<MaxBackward1>) tensor([4.0415e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5792434192077542 2.085447564707172 0.4937958545005823 0.18269153673485716\n",
      "\n",
      "\n",
      "5000 tensor(4.3159e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.7621993012871826e-06\n",
      "Gan: tensor(-0.3806, device='cuda:0', grad_fn=<MaxBackward1>) tensor([8.4654e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.481159744265768 2.001884487539966 0.47927525672580185 0.17540589177807986\n",
      "\n",
      "\n",
      "5100 tensor(5.3118e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.3995247576967813e-06\n",
      "Gan: tensor(-0.3786, device='cuda:0', grad_fn=<MaxBackward1>) tensor([7.6393e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4849530532188306 2.00920626057336 0.4757467926454706 0.17508882503592993\n",
      "\n",
      "\n",
      "5200 tensor(8.5286e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 5.458316536532948e-07\n",
      "Gan: tensor(-0.3701, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.0341e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4489193406069587 1.9735279497187266 0.4753913908882321 0.20359768097320474\n",
      "\n",
      "\n",
      "5300 tensor(1.4177e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 9.073547516891267e-06\n",
      "Gan: tensor(-0.3746, device='cuda:0', grad_fn=<MaxBackward1>) tensor([7.1803e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.54260751421286 2.038185111587295 0.5044224026255653 0.14947835630903317\n",
      "\n",
      "\n",
      "5400 tensor(2.0088e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.2856020248364075e-07\n",
      "Gan: tensor(-0.3722, device='cuda:0', grad_fn=<MaxBackward1>) tensor([7.2206e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5501409853121104 2.053001928193199 0.4971390571189116 0.1463377818959959\n",
      "\n",
      "\n",
      "5500 tensor(2.1118e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.3515200407709926e-06\n",
      "Gan: tensor(-0.3639, device='cuda:0', grad_fn=<MaxBackward1>) tensor([2.3053e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.509945072825959 2.019090563250959 0.4908545095750001 0.14420160303880092\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600 tensor(1.7031e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.0899741198500124e-07\n",
      "Gan: tensor(-0.3586, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.1449e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4884190180863413 2.003261710036674 0.48515730804966717 0.14261144722795693\n",
      "\n",
      "\n",
      "5700 tensor(4.3076e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.756856645191874e-07\n",
      "Gan: tensor(-0.3623, device='cuda:0', grad_fn=<MaxBackward1>) tensor([4.4580e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5113202020662064 2.0343968429551316 0.47692335911107486 0.13696618839197416\n",
      "\n",
      "\n",
      "5800 tensor(2.0439e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.3081205452181166e-06\n",
      "Gan: tensor(-0.3527, device='cuda:0', grad_fn=<MaxBackward1>) tensor([6.5791e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4718385163789067 2.001570483591608 0.47026803278729856 0.1362727649550557\n",
      "\n",
      "\n",
      "5900 tensor(1.4152e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 9.057293937075883e-08\n",
      "Gan: tensor(-0.3517, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.2001e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.473101966304484 2.0104666913804072 0.46263527492407697 0.13280117127901825\n",
      "\n",
      "\n",
      "6000 tensor(2.1248e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.3598570092199225e-07\n",
      "Gan: tensor(-0.3479, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.2179e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.454413643297656 1.99823697330353 0.4561766699941263 0.13248235566763955\n",
      "\n",
      "\n",
      "6100 tensor(2.0959e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.3413595070232986e-06\n",
      "Gan: tensor(-0.3594, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.9797e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.561448826635915 2.0526750683784485 0.5087737582574667 0.2017581781276765\n",
      "\n",
      "\n",
      "6200 tensor(1.9547e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.2509798352766666e-06\n",
      "Gan: tensor(-0.3949, device='cuda:0', grad_fn=<MaxBackward1>) tensor([8.5430e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5240210460552883 2.052490437807444 0.47153060824784454 0.14421166018786247\n",
      "\n",
      "\n",
      "6300 tensor(5.7693e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.6923455581927556e-07\n",
      "Gan: tensor(-0.3535, device='cuda:0', grad_fn=<MaxBackward1>) tensor([2.1224e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.492858611149733 2.036158109229955 0.45670050191977785 0.13805209177033362\n",
      "\n",
      "\n",
      "6400 tensor(5.2406e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.353999318278511e-07\n",
      "Gan: tensor(-0.3509, device='cuda:0', grad_fn=<MaxBackward1>) tensor([2.2267e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.466189034481498 2.012573336699271 0.4536156977822272 0.13749908279307865\n",
      "\n",
      "\n",
      "6500 tensor(1.1139e-10, device='cuda:0', grad_fn=<DivBackward0>) 0.0 7.1290253700340145e-09\n",
      "Gan: tensor(-0.3508, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.4293e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4768618365650252 2.031095812757507 0.44576602380751806 0.1328662395438478\n",
      "\n",
      "\n",
      "6600 tensor(5.3162e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.402363120130758e-07\n",
      "Gan: tensor(-0.3540, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.2444e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4491828848508503 2.0064148742517296 0.44276801059912074 0.13314521377148436\n",
      "\n",
      "\n",
      "6700 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "Gan: tensor(-0.3558, device='cuda:0', grad_fn=<MaxBackward1>) tensor([8.1126e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.45253077858282 2.011519921345517 0.4410108572373028 0.1322926514991698\n",
      "\n",
      "\n",
      "6800 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "Gan: tensor(-0.3427, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.0634e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4380560267513482 1.998690582238021 0.43936544451332726 0.13328478302138547\n",
      "\n",
      "\n",
      "6900 tensor(1.0006e-10, device='cuda:0', grad_fn=<DivBackward0>) 0.0 6.404031971385393e-09\n",
      "Gan: tensor(-0.3434, device='cuda:0', grad_fn=<MaxBackward1>) tensor([6.1947e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.440651520309818 2.0007987848214954 0.4398527354883224 0.13201883297326455\n",
      "\n",
      "\n",
      "7000 tensor(1.3180e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 8.435051768174162e-08\n",
      "Gan: tensor(-0.3435, device='cuda:0', grad_fn=<MaxBackward1>) tensor([2.3376e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4405725103018243 1.9999821478440418 0.4405903624577825 0.13211299007261368\n",
      "\n",
      "\n",
      "7100 tensor(7.5136e-10, device='cuda:0', grad_fn=<DivBackward0>) 0.0 4.808716980164718e-08\n",
      "Gan: tensor(-0.3464, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.5883e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4557804868441813 2.0132920145988464 0.44248847224533483 0.13530420844012747\n",
      "\n",
      "\n",
      "7200 tensor(1.6683e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.0677026693883818e-06\n",
      "Gan: tensor(-0.3430, device='cuda:0', grad_fn=<MaxBackward1>) tensor([2.3774e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.456280706010894 2.0125381350517273 0.4437425709591669 0.13793833689835955\n",
      "\n",
      "\n",
      "7300 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "Gan: tensor(-0.3418, device='cuda:0', grad_fn=<MaxBackward1>) tensor([6.8919e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.445308139365204 2.0092309277562737 0.4360772116089304 0.12994596796990132\n",
      "\n",
      "\n",
      "7400 tensor(5.8943e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.7723606283179834e-07\n",
      "Gan: tensor(-0.3408, device='cuda:0', grad_fn=<MaxBackward1>) tensor([5.5827e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4282897979280795 1.9948801040462896 0.43340969388178996 0.1345326084485765\n",
      "\n",
      "\n",
      "7500 tensor(7.3981e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 4.7348032694571884e-07\n",
      "Gan: tensor(-0.3425, device='cuda:0', grad_fn=<MaxBackward1>) tensor([4.3590e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.448297913577796 2.0094204320283175 0.43887748154947825 0.1293888719558942\n",
      "\n",
      "\n",
      "7600 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "Gan: tensor(-0.3404, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.5118e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4397403307344856 2.0031537396903247 0.43658659104416087 0.12859810946367212\n",
      "\n",
      "\n",
      "7700 tensor(9.5985e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 6.143067139419145e-07\n",
      "Gan: tensor(-0.3468, device='cuda:0', grad_fn=<MaxBackward1>) tensor([2.8844e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4763645173911155 2.018944263458252 0.45742025393286356 0.14914721751269555\n",
      "\n",
      "\n",
      "7800 tensor(2.2713e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.4536493608829915e-07\n",
      "Gan: tensor(-0.3731, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.7761e-06], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.5634307645742584 2.0921208786960914 0.471309885878167 0.1378020865705296\n",
      "\n",
      "\n",
      "7900 tensor(7.1765e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 4.592987352225464e-06\n",
      "Gan: tensor(-0.3728, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.9527e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4812927888335357 2.0017320211503757 0.4795607676831599 0.14432828001763598\n",
      "\n",
      "\n",
      "8000 tensor(9.7363e-14, device='cuda:0', grad_fn=<DivBackward0>) 0.0 6.23122647230856e-12\n",
      "Gan: tensor(-0.3560, device='cuda:0', grad_fn=<MaxBackward1>) tensor([8.4359e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4688575013282494 1.9956387646420477 0.47321873668620174 0.14760782312613174\n",
      "\n",
      "\n",
      "8100 tensor(5.9402e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.801697232574952e-07\n",
      "Gan: tensor(-0.3756, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.2145e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4658360639289336 1.9977759893445777 0.46806007458435595 0.14387215139291376\n",
      "\n",
      "\n",
      "8200 tensor(1.5176e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 9.71243252934073e-07\n",
      "Gan: tensor(-0.3893, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.3563e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4749601514887343 2.0101456827352306 0.46481446875350363 0.1378621664132682\n",
      "\n",
      "\n",
      "8300 tensor(5.8369e-10, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.735641840307835e-08\n",
      "Gan: tensor(-0.3663, device='cuda:0', grad_fn=<MaxBackward1>) tensor([9.3609e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4613184077939736 1.9983033103636094 0.4630150974303642 0.13911410156063786\n",
      "\n",
      "\n",
      "8400 tensor(2.9752e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.9041021914745215e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gan: tensor(-0.3552, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.8654e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.473297153575168 2.015006608626826 0.4582905449483423 0.13624696172521444\n",
      "\n",
      "\n",
      "8500 tensor(3.6023e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.3054900566421566e-07\n",
      "Gan: tensor(-0.3515, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.2316e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.464585456828625 2.0099751931364778 0.4546102636921474 0.13446128777781174\n",
      "\n",
      "\n",
      "8600 tensor(1.3471e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 8.621388758456305e-08\n",
      "Gan: tensor(-0.3489, device='cuda:0', grad_fn=<MaxBackward1>) tensor([2.6269e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.44465552261753 1.991664800248165 0.4529907223693652 0.14284769671061404\n",
      "\n",
      "\n",
      "8700 tensor(1.8251e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.1680511988743092e-06\n",
      "Gan: tensor(-0.3479, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.6842e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4490778340911583 2.000184293103525 0.44889354098763334 0.1342144587463432\n",
      "\n",
      "\n",
      "8800 tensor(6.4561e-10, device='cuda:0', grad_fn=<DivBackward0>) 0.0 4.131906194970725e-08\n",
      "Gan: tensor(-0.3470, device='cuda:0', grad_fn=<MaxBackward1>) tensor([6.7925e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.440908080897572 1.9943204902713894 0.4465875906261827 0.13897037051929573\n",
      "\n",
      "\n",
      "8900 tensor(4.5899e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.937555336757214e-07\n",
      "Gan: tensor(-0.3489, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.2746e-07], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.453046918118184 2.008470783310365 0.4445761348078192 0.1316405176357991\n",
      "\n",
      "\n",
      "9000 tensor(4.2031e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.6899886051978683e-07\n",
      "Gan: tensor(-0.3507, device='cuda:0', grad_fn=<MaxBackward1>) tensor([4.1328e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4457634382352373 2.0033952373952886 0.44236820083994877 0.1308846371559116\n",
      "\n",
      "\n",
      "9100 tensor(1.8031e-11, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.1539527111636971e-09\n",
      "Gan: tensor(-0.3465, device='cuda:0', grad_fn=<MaxBackward1>) tensor([9.5422e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4517139867323934 2.0118265191609463 0.43988746757144703 0.12946072724827173\n",
      "\n",
      "\n",
      "9200 tensor(4.6261e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.9607053875224665e-07\n",
      "Gan: tensor(-0.3535, device='cuda:0', grad_fn=<MaxBackward1>) tensor([2.1406e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.43272802977036 1.9949084096487546 0.43781962012160536 0.13418409432183465\n",
      "\n",
      "\n",
      "9300 tensor(1.3708e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 8.772960882197367e-07\n",
      "Gan: tensor(-0.3446, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.2491e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.4403685046856793 2.0045723161784825 0.4357961885071968 0.12730024548906105\n",
      "\n",
      "\n",
      "9400 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "Gan: tensor(-0.3417, device='cuda:0', grad_fn=<MaxBackward1>) tensor([3.2295e-08], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "2.438659817089588 2.0045820540490626 0.43407776304052526 0.12652707560029386\n",
      "\n",
      "\n",
      "9500 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(int(echo)):\n",
    "\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "    \n",
    "    while(temp_number<len(training_data)-1):\n",
    "        \n",
    "        loss2_list = []\n",
    "        loss1_sum = 0\n",
    "        loss2_sum = 0\n",
    "        denominator = 0\n",
    "        for index in range(temp_number, min(BATCH_SIZE+temp_number,len(training_data))):\n",
    "#             training_data_i, training_label, training_data = appen_train(\n",
    "#                 Generate_distribution(Agent_number_n))\n",
    "            \n",
    "            training_data_i = training_data[index]\n",
    "            training_label = training_label[index]\n",
    "            training_data = 0\n",
    "            \n",
    "            h_loss1, h_loss2 = DiscriminatorNet(training_data_i, training_label,\n",
    "                                           training_data)\n",
    "            denominator += 1\n",
    "            loss1_sum += h_loss1\n",
    "            loss2_sum += h_loss2\n",
    "\n",
    "        loss_sum = torch.sum(loss1_sum + loss2_sum)\n",
    "        loss = (loss_sum) / denominator \n",
    "        total_batch_loss +=float(loss_sum)\n",
    "\n",
    "        opt_D.zero_grad()\n",
    "        loss.backward()\n",
    "        opt_D.step()\n",
    "\n",
    "        temp_number = iteration\n",
    "        index_train_list.append(iteration)\n",
    "        train_losses.append(total_batch_loss)\n",
    "\n",
    "        if (iteration%100 == 0):\n",
    "            print(temp_number,loss,float(loss1_sum),float(loss2_sum))\n",
    "        ## Gan \n",
    "            if(Is_GAN):## Gan Work traning GeneratorNet\n",
    "\n",
    "                DiscriminatorNet.requires_grad = True\n",
    "                GeneratorNet.requires_grad = True\n",
    "\n",
    "\n",
    "                for step in range(100):\n",
    "                    # real painting from artist\n",
    "                    G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                                          requires_grad=True).to(dev)  # random ideas\\n\n",
    "                    # fake painting from G (random ideas)\n",
    "\n",
    "                    G_values = GeneratorNet(G_ideas)\n",
    "                    G_values , indices = torch.sort(G_values, descending=True)\n",
    "                #     print(artist_paintings)\n",
    "                #     print(G_paintings)\n",
    "\n",
    "                    result_list = []\n",
    "                    for index in range(BATCH_SIZE):\n",
    "                        h_list = []\n",
    "                        value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                            G_values[index])\n",
    "                        for i in range(Agent_number_n):\n",
    "                            h = DiscriminatorNet.calculate(\n",
    "                                value_list_tensor[i].cuda().type(torch.float32))\n",
    "                            h_list.append(h)\n",
    "                        h_list = torch.stack(h_list)\n",
    "                        result_list.append(torch.sum(h_list)/S_tensor.cuda())\n",
    "                    result_list = torch.stack(result_list)\n",
    "\n",
    "                    diff_loss = torch.max(result_list)-torch.min(result_list)\n",
    "                    G_loss = torch.max(- diff_loss)\n",
    "\n",
    "                    opt_G.zero_grad()\n",
    "                    G_loss.backward()\n",
    "                    opt_G.step()\n",
    "\n",
    "                # real painting from artist\n",
    "                    G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                                          requires_grad=True).to(dev)  # random ideas\\n\n",
    "                    # fake painting from G (random ideas)\n",
    "\n",
    "                    G_values = GeneratorNet(G_ideas)\n",
    "                    G_values , indices = torch.sort(G_values, descending=True)\n",
    "                #     print(artist_paintings)\n",
    "                #     print(G_paintings)\n",
    "\n",
    "                    result_list = []\n",
    "                    for index in range(BATCH_SIZE):\n",
    "                        h_list = []\n",
    "                        value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                            G_values[index])\n",
    "                        for i in range(Agent_number_n):\n",
    "                            h = DiscriminatorNet.calculate(\n",
    "                                value_list_tensor[i].cuda().type(torch.float32))\n",
    "                            h_list.append(h)\n",
    "                        h_list = torch.stack(h_list)\n",
    "                        result_list.append(torch.sum(h_list)/S_tensor.cuda())\n",
    "                    result_list = torch.stack(result_list)\n",
    "\n",
    "                    diff_loss = torch.max(result_list)-torch.min(result_list)\n",
    "\n",
    "                    D_loss = torch.where((Agent_number_n-1)>torch.min(result_list),\n",
    "                        torch.square(((Agent_number_n-1)-torch.min(result_list))),\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )   + torch.where((Agent_number_n-Alpha)<torch.max(result_list),\n",
    "                                    torch.square((torch.max(result_list)-(Agent_number_n-Alpha)))/10000,\n",
    "                                    torch.zeros(1).to(dev)\n",
    "                                  )\n",
    "\n",
    "\n",
    "                    opt_D.zero_grad()\n",
    "                    D_loss.backward()\n",
    "                    opt_D.step()\n",
    "\n",
    "                print(\"Gan:\",G_loss,D_loss)\n",
    "                print()\n",
    "\n",
    "\n",
    "            result_list = []\n",
    "            for index in range(len(testing_data)):\n",
    "                h_list = []\n",
    "                for i in range(Agent_number_n):\n",
    "                    h = DiscriminatorNet.calculate(\n",
    "                        torch.tensor(testing_data[index][i]).to(dev).type(\n",
    "                            torch.float32))\n",
    "                    h_list.append(float(h))\n",
    "                result_list.append(sum(h_list) / testing_label[index])\n",
    "            print(max(result_list), min(result_list),\n",
    "                  max(result_list) - min(result_list),\n",
    "                  (sum(result_list) / len(result_list) - min(result_list))+ Agent_number_n-1 - min(min(result_list),Agent_number_n-1) )\n",
    "\n",
    "            index_test_list.append(iteration)\n",
    "            test_losses.append(\n",
    "                (sum(result_list) / len(result_list) - min(result_list))+ Agent_number_n-1 - min(min(result_list),Agent_number_n-1) )\n",
    "            print()\n",
    "            index_test_list.append(iteration)\n",
    "            test_losses.append(\n",
    "                max(result_list)-min(result_list) )\n",
    "\n",
    "\n",
    "            print()\n",
    "\n",
    "\n",
    "        scheduler_D.step()\n",
    "        scheduler_G.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-10T11:32:50.139Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylim(0, 1.0)\n",
    "plt.plot(index_test_list,test_losses)\n",
    "plt.ylabel('test loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-10T11:32:50.140Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(DiscriminatorNet, \"save/Deep_learning_D_3_1\")\n",
    "if(Is_GAN):\n",
    "    torch.save(GeneratorNet, \"save/Deep_learning_G_3_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-10T11:32:50.142Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list.append(sum(h_list)/testing_label[index])\n",
    "    \n",
    "\n",
    "print(max(result_list),min(result_list),max(result_list)-min(result_list))\n",
    "print(sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-10T11:32:50.143Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-10T11:32:50.145Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate 10000 testing data on GeneratorNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-10T11:32:50.146Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "GeneratorNet = torch.load(\"save/Deep_learning_G_3_1\")\n",
    "def appen_test_G(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data_G.append(temp_list)\n",
    "    testing_label_G.append(S)\n",
    "# fake painting from G (random ideas)\n",
    "\n",
    "def read_testing_data_G():\n",
    "    for i in range(10000):\n",
    "        #appen_test_G(sorted(np.random.rand(Agent_number_n), reverse=True));\n",
    "        G_ideas = torch.randn(N_IDEAS).to(dev)  # random ideas\\n\n",
    "        G_values = GeneratorNet(G_ideas)\n",
    "        G_values , indices = torch.sort(G_values, descending=True)\n",
    "        appen_test_G(G_values.detach().cpu().numpy()) \n",
    "        \n",
    "testing_data_G = []\n",
    "testing_label_G = []\n",
    "read_testing_data_G()\n",
    "testing_data_G=np.array(testing_data_G)\n",
    "testing_label_G=np.array(testing_label_G)\n",
    "print(testing_data_G)\n",
    "print(testing_label_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-10T11:32:50.147Z"
    }
   },
   "outputs": [],
   "source": [
    "result_list_G = []\n",
    "for index in range(len(testing_data_G)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data_G[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list_G.append(sum(h_list)/testing_label_G[index])\n",
    "    \n",
    "\n",
    "print(max(result_list_G),min(result_list_G),max(result_list_G)-min(result_list_G))\n",
    "print(sum(result_list_G)/len(result_list_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-10T11:32:50.149Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list_G)/len(result_list_G), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list_G)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list_G)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
