{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T15:58:56.530980Z",
     "start_time": "2021-06-12T15:58:54.710701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pygame\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm \n",
    "import matplotlib.cm as cm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy.interpolate import griddata\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "print(dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T15:58:56.546952Z",
     "start_time": "2021-06-12T15:58:56.532977Z"
    }
   },
   "outputs": [],
   "source": [
    "global temp_list\n",
    "temp_list = []\n",
    "Agent_number_n=3;\n",
    "Alpha = 0.66\n",
    "\n",
    "# Hyper Parameters\n",
    "echo = 10001\n",
    "BATCH_SIZE = 64\n",
    "LR_G = 0.001           # learning rate for generator\n",
    "LR_D = 0.001           # learning rate for discriminator\n",
    "N_IDEAS = Agent_number_n             # think of this as number of ideas for generating an art work (Generator)\n",
    "ART_COMPONENTS = Agent_number_n     # it could be total point G can draw in the canvas\n",
    "\n",
    "Is_GAN = False # if use Gan\n",
    "\n",
    "def Generate_distribution(Agent_number_n):\n",
    "    return sorted(np.random.rand(Agent_number_n), reverse=True)\n",
    "    #return np.random.normal(normalloc,normalscale,Agent_number_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T15:58:56.814395Z",
     "start_time": "2021-06-12T15:58:56.547950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.03259351 0.01274345]\n",
      "  [0.9634833  0.01274345]\n",
      "  [0.9634833  0.03259351]]\n",
      "\n",
      " [[0.69007733 0.3586272 ]\n",
      "  [0.84977322 0.3586272 ]\n",
      "  [0.84977322 0.69007733]]\n",
      "\n",
      " [[0.68708594 0.36056848]\n",
      "  [0.78285658 0.36056848]\n",
      "  [0.78285658 0.68708594]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.55719565 0.4524749 ]\n",
      "  [0.66771334 0.4524749 ]\n",
      "  [0.66771334 0.55719565]]\n",
      "\n",
      " [[0.60045112 0.03454238]\n",
      "  [0.93900344 0.03454238]\n",
      "  [0.93900344 0.60045112]]\n",
      "\n",
      " [[0.55995572 0.27453753]\n",
      "  [0.95322992 0.27453753]\n",
      "  [0.95322992 0.55995572]]]\n",
      "[1.00882026 1.89847774 1.83051099 ... 1.6773839  1.57399694 1.78772317]\n"
     ]
    }
   ],
   "source": [
    "def appen(_x_list,y):\n",
    "    global temp_list\n",
    "    temp_list.append(_x_list)\n",
    "    \n",
    "def appen_train(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    \n",
    "    temp_list = np.array(temp_list)\n",
    "    x_list = np.array(x_list)\n",
    "    return temp_list,S,x_list\n",
    "    \n",
    "\n",
    "def appen_test(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data.append(temp_list)\n",
    "    testing_label.append(S)\n",
    "    temp_list = np.array(temp_list)\n",
    "    return temp_list,S\n",
    "    \n",
    "\n",
    "def read_testing_data():\n",
    "    for i in range(10000):\n",
    "        appen_test(Generate_distribution(Agent_number_n));\n",
    "                            \n",
    "\n",
    "testing_data=[]\n",
    "testing_label=[]\n",
    "S=1.0\n",
    "read_testing_data();\n",
    "\n",
    "testing_data=np.array(testing_data)\n",
    "testing_label=np.array(testing_label)\n",
    "print(testing_data)\n",
    "print(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T15:58:57.679098Z",
     "start_time": "2021-06-12T15:58:56.816389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.333243922826174 2.0 0.3332439228261741 2.1016720719264863\n"
     ]
    }
   ],
   "source": [
    "def h_3_star(a, b, t):\n",
    "    return a - min(a, t) + b - min(b, t) + max(min(a, t)+min(b, t), 2*t/3) + 1/2 * max(min(a, t)+min(b, t), t) - 1/2 * max(max(min(a, t), min(b, t)), 2*t/3) - t/6\n",
    "\n",
    "\n",
    "def f_function(a, b, z):\n",
    "    if(z >= 1):\n",
    "        return (a+b)/2 + z/3\n",
    "    else:\n",
    "        return z/3 + h_3_star(a, b, 1-z)/2\n",
    "\n",
    "def h_function(input_list):\n",
    "    #input_list = sorted(input_list)\n",
    "    g_list = []\n",
    "    for j1 in range(len(input_list) ):\n",
    "        for j2 in range(len(input_list)):\n",
    "            if(j1 != j2):\n",
    "                a = input_list[j1]\n",
    "                b = input_list[j2]\n",
    "                z = sum(input_list)- a-b\n",
    "\n",
    "                g_list.append( f_function(a, b, z) * (Agent_number_n-1))\n",
    "    h = sum(g_list) * 3 /  (Agent_number_n) /  (Agent_number_n-1) /  (Agent_number_n - 2)\n",
    "    return h\n",
    "                \n",
    "                \n",
    "x_list = []\n",
    "y_list = []\n",
    "z_list = []\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        x_list.append(testing_data[index][i][0])\n",
    "        y_list.append(testing_data[index][i][1])\n",
    "        h = h_function(testing_data[index][i])\n",
    "        z_list.append(float(h))\n",
    "        h_list.append(float(h))\n",
    "    result_list.append(sum(h_list)/testing_label[index]) \n",
    "    \n",
    "    \n",
    "print(max(result_list), min(result_list), max(result_list)-min(result_list),sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T15:58:58.945768Z",
     "start_time": "2021-06-12T15:58:57.681094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T15:58:58.976699Z",
     "start_time": "2021-06-12T15:58:58.947780Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.input_dim = (Agent_number_n-1)\n",
    "        self.hidden_dim = 128\n",
    "        self.output_dim = 1\n",
    "        self.hidden_layer_count = 6 \n",
    "        \n",
    "        current_dim = self.input_dim\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(self.hidden_layer_count):\n",
    "            self.layers.append(torch.nn.Linear(current_dim, self.hidden_dim))\n",
    "            current_dim = self.hidden_dim\n",
    "        self.layers.append(torch.nn.Linear(current_dim, self.output_dim))\n",
    "\n",
    "    def calculate(self, value_list):\n",
    "        h = value_list\n",
    "        LeakyReLU = torch.nn.LeakyReLU()\n",
    "        for layer in self.layers:\n",
    "            h = torch.relu(layer(h))\n",
    "        return h\n",
    "\n",
    "    def forward(self, input_list,input_label,label):\n",
    "        global iteration,echo,target_order\n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        loss3 = 0\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).to(dev).type(torch.float32)\n",
    "        h_list = []\n",
    "\n",
    "        for i in range(Agent_number_n):\n",
    "            h = self.calculate(input_list[i])\n",
    "            h_list.append(h)\n",
    "#             loss3 += torch.square(h_function_2(input_list)-h2[1])\n",
    "            \n",
    "        input_label = torch.from_numpy(\n",
    "            np.array(input_label)).to(dev).type(torch.float32)\n",
    "        sum_h = torch.sum(torch.cat(h_list)).to(dev)\n",
    "\n",
    "\n",
    "        loss1 = torch.where((Agent_number_n-1)*input_label>sum_h,\n",
    "                        torch.square(((Agent_number_n-1)*input_label-sum_h)),\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "        loss2 = torch.where((Agent_number_n-Alpha)*input_label<sum_h,\n",
    "                        torch.square((sum_h-(Agent_number_n-Alpha)*input_label))/100,\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "\n",
    "        return loss1,loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T15:58:58.991688Z",
     "start_time": "2021-06-12T15:58:58.979697Z"
    }
   },
   "outputs": [],
   "source": [
    "def redistribution_value_function(input_tensor):\n",
    "    S = torch.max(torch.sum(input_tensor), torch.ones(1).to(dev))\n",
    "    temp_list = []\n",
    "\n",
    "\n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        \n",
    "        for j in range(Agent_number_n):\n",
    "            if(i != j):\n",
    "                temp .append(input_tensor[j])\n",
    "                \n",
    "        temp = torch.stack(temp)\n",
    "        temp_list.append(temp)\n",
    "    return torch.stack(temp_list), S\n",
    "\n",
    "GeneratorNet = nn.Sequential(                      # Generator\n",
    "    # random ideas (could from normal distribution)\n",
    "    nn.Linear(N_IDEAS, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    # making a painting from these random ideas\n",
    "    nn.Linear(64, ART_COMPONENTS),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T15:59:00.370015Z",
     "start_time": "2021-06-12T15:58:58.993655Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "DiscriminatorNet  = Net()\n",
    "DiscriminatorNet.apply(weight_init)\n",
    "GeneratorNet.apply(weight_init)\n",
    "# DiscriminatorNet = torch.load(\"save/Deep_learning_D_3_2\")\n",
    "# if(Is_GAN):\n",
    "#     GeneratorNet = torch.load(\"save/Deep_learning_G_3_2\")\n",
    "DiscriminatorNet.to(dev)\n",
    "GeneratorNet.to(dev)\n",
    "\n",
    "opt_D = torch.optim.Adam(DiscriminatorNet.parameters(), lr=LR_D)\n",
    "opt_G = torch.optim.Adam(GeneratorNet.parameters(), lr=LR_G)\n",
    "\n",
    "\n",
    "scheduler_D = torch.optim.lr_scheduler.StepLR(opt_D, step_size=100, gamma=0.98)\n",
    "scheduler_G = torch.optim.lr_scheduler.StepLR(opt_G, step_size=100, gamma=0.98)\n",
    "\n",
    "index_train_list = []\n",
    "index_test_list = []\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T17:15:01.740920Z",
     "start_time": "2021-06-12T15:59:00.372010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(10.0661, device='cuda:0', grad_fn=<DivBackward0>) 644.2283935546875 0.0\n",
      "0.15645235830002605 0.03659364394843578 0.11985871435159026 2.052926876003159\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:118: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>) 0.053095947951078415 0.04302610456943512\n",
      "3.109699431463902 1.2802867591381073 1.8294126723257946 1.8562496417081302\n",
      "\n",
      "\n",
      "200 tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.042459696531295776\n",
      "3.0686399645717826 1.3819192945957184 1.6867206699760642 1.6593033632926986\n",
      "\n",
      "\n",
      "300 tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) 0.0003577929164748639 0.02747081033885479\n",
      "2.9078044295310974 1.5105786323547363 1.397225797176361 1.3588309511361878\n",
      "\n",
      "\n",
      "400 tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>) 0.0038967786822468042 0.021148810163140297\n",
      "3.01182253017222 1.6355425715446472 1.3762799586275727 1.0455272193994372\n",
      "\n",
      "\n",
      "500 tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) 0.00034698910894803703 0.02024739794433117\n",
      "2.9899343952200566 1.7108255624771118 1.2791088327429447 0.8675831174954807\n",
      "\n",
      "\n",
      "600 tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>) 0.05063251778483391 0.013502107001841068\n",
      "3.020992333844768 1.7661494016647339 1.254842932180034 0.7751547987360068\n",
      "\n",
      "\n",
      "700 tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) 0.013971477746963501 0.005736359395086765\n",
      "2.951796162307829 1.8228620290756226 1.1289341332322063 0.6081193287288422\n",
      "\n",
      "\n",
      "800 tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.01208321750164032\n",
      "2.90852645783031 1.828307569026947 1.0802188888033628 0.5934903747883906\n",
      "\n",
      "\n",
      "900 tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.007217968814074993\n",
      "2.8966266087338526 1.8419446349143982 1.0546819738194544 0.5746328822352438\n",
      "\n",
      "\n",
      "1000 tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.007064108736813068\n",
      "2.8454796775484548 1.9195054173469543 0.9259742602015004 0.40727774510852033\n",
      "\n",
      "\n",
      "1100 tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) 0.004844788461923599 0.002329098293557763\n",
      "2.772089419927628 1.904758334159851 0.867331085767777 0.4063903400677802\n",
      "\n",
      "\n",
      "1200 tensor(2.5685e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0002953642688225955 0.0013484794180840254\n",
      "2.7203156768070302 1.914778232574463 0.8055374442325673 0.37455580700392854\n",
      "\n",
      "\n",
      "1300 tensor(3.1745e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0020316678564995527\n",
      "2.7132389449464256 1.991286814212799 0.7219521307336265 0.23766664854647956\n",
      "\n",
      "\n",
      "1400 tensor(4.4391e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0007681283168494701 0.0020728965755552053\n",
      "2.641488396512651 1.981046148243934 0.6604422482687169 0.22221875834564964\n",
      "\n",
      "\n",
      "1500 tensor(1.0293e-05, device='cuda:0', grad_fn=<DivBackward0>) 9.37152435653843e-06 0.0006493839318864048\n",
      "2.616985849010117 1.985153615474701 0.6318322335354161 0.2083769861136977\n",
      "\n",
      "\n",
      "1600 tensor(1.1459e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0005184886394999921 0.00021487008780241013\n",
      "2.5985858556088397 1.9905616280625178 0.6080242275463219 0.1971448848256412\n",
      "\n",
      "\n",
      "1700 tensor(2.3620e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0013452388811856508 0.00016645128198433667\n",
      "2.570349300698046 1.984239965352824 0.5861093353452218 0.19742071628462643\n",
      "\n",
      "\n",
      "1800 tensor(7.5228e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0004814576532226056\n",
      "2.554712115368181 1.9565880298614502 0.5981240855067309 0.2500622072974834\n",
      "\n",
      "\n",
      "1900 tensor(9.4859e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0002535506500862539 0.0003535446885507554\n",
      "2.5405999407588875 1.9904819867803032 0.5501179539785843 0.18998255972259104\n",
      "\n",
      "\n",
      "2000 tensor(1.3950e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0008928010356612504\n",
      "2.583358943462372 1.9923055421405518 0.59105340132182 0.20371545102869004\n",
      "\n",
      "\n",
      "2100 tensor(1.0085e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0006454225513152778\n",
      "2.571836542021979 2.025449931419214 0.5463866106027653 0.17536441248911672\n",
      "\n",
      "\n",
      "2200 tensor(4.4660e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.00028582365484908223\n",
      "2.512948499868291 1.9875928163528442 0.5253556835154467 0.19093220775683362\n",
      "\n",
      "\n",
      "2300 tensor(1.2745e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0004473094013519585 0.00036840044776909053\n",
      "2.5260836876597623 1.9913221375704864 0.534761550089276 0.17851354793244711\n",
      "\n",
      "\n",
      "2400 tensor(1.8427e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.00011792968143709004\n",
      "2.508158695191211 1.9896978735923767 0.5184608215988344 0.18661987971938965\n",
      "\n",
      "\n",
      "2500 tensor(3.7745e-06, device='cuda:0', grad_fn=<DivBackward0>) 9.959015005733818e-05 0.00014197739074006677\n",
      "2.5063349053159403 1.9832314848899841 0.5231034204259561 0.18946059519946612\n",
      "\n",
      "\n",
      "2600 tensor(8.7136e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0005161090521141887 4.156377326580696e-05\n",
      "2.5036737248127627 1.9884993254625978 0.515174399350165 0.1787424281720349\n",
      "\n",
      "\n",
      "2700 tensor(3.7858e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.4229069822467864e-05\n",
      "2.48157867708936 1.985581398010254 0.49599727907910607 0.17718472696123522\n",
      "\n",
      "\n",
      "2800 tensor(4.2563e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.00027240539202466607\n",
      "2.4982681742202866 1.9857560992240906 0.512512074996196 0.18564898937719665\n",
      "\n",
      "\n",
      "2900 tensor(9.2179e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 5.8994788560085e-05\n",
      "2.504131740204531 2.001231695076377 0.502900045128154 0.16761365326934463\n",
      "\n",
      "\n",
      "3000 tensor(1.9099e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.00012223509838804603\n",
      "2.515646407860739 1.9997685551643372 0.5158778526964016 0.17660786392344807\n",
      "\n",
      "\n",
      "3100 tensor(8.4964e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.00044775474816560745 9.60118995863013e-05\n",
      "2.486862621147112 1.9851071193211727 0.5017555018259392 0.18727488272232673\n",
      "\n",
      "\n",
      "3200 tensor(2.0991e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.00013434389256872237\n",
      "2.483040816782354 1.9881883440479342 0.4948524727344199 0.17605462731528387\n",
      "\n",
      "\n",
      "3300 tensor(1.2330e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 7.891084533184767e-05\n",
      "2.479847596451997 1.9978243008056449 0.48202329564635216 0.16740270389406797\n",
      "\n",
      "\n",
      "3400 tensor(1.3511e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 8.647310096421279e-06\n",
      "2.4655949916031785 1.9927428530542768 0.47285213854890173 0.17210504590714049\n",
      "\n",
      "\n",
      "3500 tensor(3.3698e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.1566627765423618e-05\n",
      "2.4753720838992197 1.998925112824466 0.47644697107475364 0.16273414088738347\n",
      "\n",
      "\n",
      "3600 tensor(2.4797e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.5869853768890607e-06\n",
      "2.455609818844636 1.9859445749027886 0.4696652439418474 0.17558543366215917\n",
      "\n",
      "\n",
      "3700 tensor(2.2495e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.4396757705981145e-06\n",
      "2.449186850160539 1.9895059946730842 0.45968085548745474 0.1689953682602039\n",
      "\n",
      "\n",
      "3800 tensor(1.8242e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.1674700544972438e-05\n",
      "2.480908729136927 2.0109806060791016 0.4699281230578256 0.1624232462143853\n",
      "\n",
      "\n",
      "3900 tensor(3.2604e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.00020866634440608323\n",
      "2.505672933637745 1.9997868537902832 0.5058860798474618 0.18153416625154772\n",
      "\n",
      "\n",
      "4000 tensor(4.1922e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.6830019123735838e-05\n",
      "2.451542214401101 1.9961663023435392 0.455375912057562 0.16407342997931584\n",
      "\n",
      "\n",
      "4100 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "2.472793431393695 1.9980234796293188 0.474769951764376 0.16344993737784064\n",
      "\n",
      "\n",
      "4200 tensor(5.6745e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.631662912084721e-05\n",
      "2.4560582627073195 2.0028588463892736 0.45319941631804594 0.15634536954780742\n",
      "\n",
      "\n",
      "4300 tensor(4.3004e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.002752250526100397\n",
      "2.68923953758997 2.0613632481904425 0.6278762893995276 0.21487592742001516\n",
      "\n",
      "\n",
      "4400 tensor(3.4145e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.1852596546523273e-05\n",
      "2.4750500670842515 2.007036609489246 0.46801345759500546 0.159036970956965\n",
      "\n",
      "\n",
      "4500 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "2.4530795674059784 1.989376962184906 0.46370260522107243 0.18020700352492858\n",
      "\n",
      "\n",
      "4600 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "2.4452454481004944 1.9967021333910724 0.448543314709422 0.16039950941380265\n",
      "\n",
      "\n",
      "4700 tensor(5.4212e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.46955239365343e-05\n",
      "2.5017987886473967 2.015912937264738 0.4858858513826587 0.1760507977197534\n",
      "\n",
      "\n",
      "4800 tensor(7.9291e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 5.074646651337389e-06\n",
      "2.4563988200755023 2.003177225589752 0.45322159448575006 0.15003545051657907\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900 tensor(1.2423e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 7.950870895001572e-06\n",
      "2.4425834404281366 1.996216893196106 0.4463665472320306 0.159237851485571\n",
      "\n",
      "\n",
      "5000 tensor(1.5047e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 9.630060731069534e-07\n",
      "2.4215984788493614 1.988707000440074 0.43289147840928743 0.16421971148550707\n",
      "\n",
      "\n",
      "5100 tensor(1.1768e-12, device='cuda:0', grad_fn=<DivBackward0>) 0.0 7.531525403337014e-11\n",
      "2.432033311119531 1.9865751266479492 0.4454581844715819 0.18351346942281577\n",
      "\n",
      "\n",
      "5200 tensor(7.6623e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 4.903885201201774e-05\n",
      "2.4448720122328162 1.9960466536915558 0.4488253585412605 0.16090623498659484\n",
      "\n",
      "\n",
      "5300 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "2.446806789011597 2.001691368879974 0.4451154201316232 0.14843966917238882\n",
      "\n",
      "\n",
      "5400 tensor(1.4092e-06, device='cuda:0', grad_fn=<DivBackward0>) 9.018709533847868e-05 0.0\n",
      "2.4348555532787923 1.9956759810447693 0.43917957223402304 0.15406470000356087\n",
      "\n",
      "\n",
      "5500 tensor(1.1769e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 7.5321913755033165e-06\n",
      "2.4470077911223806 2.007970773293171 0.43903701782920956 0.15109356483212943\n",
      "\n",
      "\n",
      "5600 tensor(2.8201e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.00018048871424980462\n",
      "2.4744941503116573 2.022150725231457 0.4523434250802003 0.16070917265192763\n",
      "\n",
      "\n",
      "5700 tensor(1.3170e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 8.429036597590311e-07\n",
      "2.430825939534033 1.999827633482978 0.4309983060510547 0.15193949180524924\n",
      "\n",
      "\n",
      "5800 tensor(4.4623e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.85588284896221e-05\n",
      "2.5025493510073304 2.0213696129514345 0.481179738055896 0.17333848669474428\n",
      "\n",
      "\n",
      "5900 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "2.4272135735571614 1.9963200688362122 0.4308935047209492 0.15233734785810515\n",
      "\n",
      "\n",
      "6000 tensor(9.9086e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 6.341490370687097e-05\n",
      "2.4306820120966814 1.9965807102654334 0.43410130183124807 0.15114247100624567\n",
      "\n",
      "\n",
      "6100 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "2.414411535239029 1.9870097637176514 0.4274017715213776 0.1728318929507755\n",
      "\n",
      "\n",
      "6200 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "2.4147725611445896 1.9953938672690128 0.4193786938755768 0.155998045537854\n",
      "\n",
      "\n",
      "6300 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "2.434133434584495 1.990250587463379 0.44388284712111625 0.18224007524253194\n",
      "\n",
      "\n",
      "6400 tensor(1.6316e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.000104422630101908\n",
      "2.4514618394797316 2.007455076437864 0.4440067630418678 0.1539614203109112\n",
      "\n",
      "\n",
      "6500 tensor(3.6281e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.3219655531647732e-07\n",
      "2.417492917685738 1.9993226718764976 0.4181702458092402 0.1474618938200154\n",
      "\n",
      "\n",
      "6600 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "2.4159295679351978 2.0003327419871773 0.4155968259480205 0.14518499598959833\n",
      "\n",
      "\n",
      "6700 tensor(3.8703e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0002477011876180768\n",
      "2.4696189260413406 2.0171061205791956 0.452512805462145 0.15547941418114597\n",
      "\n",
      "\n",
      "6800 tensor(5.0984e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.2629586712573655e-06\n",
      "2.444075771796207 2.019711990178432 0.424363781617775 0.14835494106865177\n",
      "\n",
      "\n",
      "6900 tensor(7.9225e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0005070404149591923\n",
      "2.5063538120400586 2.037196099758148 0.4691577122819104 0.15824087526622987\n",
      "\n",
      "\n",
      "7000 tensor(9.4783e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 6.06613903073594e-05\n",
      "2.4639924104000928 2.018060724325055 0.44593168607503797 0.14317905124677743\n",
      "\n",
      "\n",
      "7100 tensor(3.5146e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.249359749839641e-05\n",
      "2.452226933231752 2.022620740504088 0.42960619272766376 0.1407570194753056\n",
      "\n",
      "\n",
      "7200 tensor(2.3936e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.5319071735575562e-06\n",
      "2.457351778054582 2.028223693370819 0.42912808468376307 0.14391979111588604\n",
      "\n",
      "\n",
      "7300 tensor(4.9373e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.159866309943027e-06\n",
      "2.4370184825179373 2.013261935933026 0.42375654658491113 0.14781385559658444\n",
      "\n",
      "\n",
      "7400 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "2.4082363037243955 2.0022848956676977 0.4059514080566977 0.14142845792147218\n",
      "\n",
      "\n",
      "7500 tensor(4.9814e-10, device='cuda:0', grad_fn=<DivBackward0>) 0.0 3.188069896964407e-08\n",
      "2.409134195869481 1.9998301257875657 0.40930407008191527 0.14913208957990665\n",
      "\n",
      "\n",
      "7600 tensor(1.3084e-08, device='cuda:0', grad_fn=<DivBackward0>) 0.0 8.374047411052743e-07\n",
      "2.421923649399372 2.008560032637725 0.413363616761647 0.13832458894431454\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b8a478b86156>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         training_data_i, training_label, training_data = appen_train(\n\u001b[0;32m     12\u001b[0m             Generate_distribution(Agent_number_n))\n\u001b[1;32m---> 13\u001b[1;33m         h_loss1, h_loss2 = DiscriminatorNet(training_data_i, training_label,\n\u001b[0m\u001b[0;32m     14\u001b[0m                                        training_data)\n\u001b[0;32m     15\u001b[0m         \u001b[0mdenominator\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-d108f6b6729a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_list, input_label, label)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAgent_number_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0mh_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m#             loss3 += torch.square(h_function_2(input_list)-h2[1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-d108f6b6729a>\u001b[0m in \u001b[0;36mcalculate\u001b[1;34m(self, value_list)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mLeakyReLU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1676\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1678\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(int(echo)):\n",
    "\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "        \n",
    "    loss2_list = []\n",
    "    loss1_sum = 0\n",
    "    loss2_sum = 0\n",
    "    denominator = 0\n",
    "    for index in range(0, BATCH_SIZE):\n",
    "        training_data_i, training_label, training_data = appen_train(\n",
    "            Generate_distribution(Agent_number_n))\n",
    "        h_loss1, h_loss2 = DiscriminatorNet(training_data_i, training_label,\n",
    "                                       training_data)\n",
    "        denominator += 1\n",
    "        loss1_sum += h_loss1\n",
    "        loss2_sum += h_loss2\n",
    "\n",
    "    loss_sum = torch.sum(loss1_sum + loss2_sum)\n",
    "    loss = (loss_sum) / denominator \n",
    "    total_batch_loss +=float(loss_sum)\n",
    "\n",
    "    opt_D.zero_grad()\n",
    "    loss.backward()\n",
    "    opt_D.step()\n",
    "\n",
    "    temp_number = iteration\n",
    "    index_train_list.append(iteration)\n",
    "    train_losses.append(total_batch_loss)\n",
    "\n",
    "    if (iteration%100 == 0):\n",
    "        print(temp_number,loss,float(loss1_sum),float(loss2_sum))\n",
    "    ## Gan \n",
    "        if(Is_GAN):## Gan Work traning GeneratorNet\n",
    "\n",
    "            DiscriminatorNet.requires_grad = True\n",
    "            GeneratorNet.requires_grad = True\n",
    "\n",
    "\n",
    "            for step in range(100):\n",
    "                # real painting from artist\n",
    "                G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                                      requires_grad=True).to(dev)  # random ideas\\n\n",
    "                # fake painting from G (random ideas)\n",
    "\n",
    "                G_values = GeneratorNet(G_ideas)\n",
    "                G_values , indices = torch.sort(G_values, descending=True)\n",
    "            #     print(artist_paintings)\n",
    "            #     print(G_paintings)\n",
    "\n",
    "                result_list = []\n",
    "                for index in range(BATCH_SIZE):\n",
    "                    h_list = []\n",
    "                    value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                        G_values[index])\n",
    "                    for i in range(Agent_number_n):\n",
    "                        h = DiscriminatorNet.calculate(\n",
    "                            value_list_tensor[i].cuda().type(torch.float32))\n",
    "                        h_list.append(h)\n",
    "                    h_list = torch.stack(h_list)\n",
    "                    result_list.append(torch.sum(h_list)/S_tensor.cuda())\n",
    "                result_list = torch.stack(result_list)\n",
    "\n",
    "                diff_loss = torch.max(result_list)-torch.min(result_list)\n",
    "                G_loss = torch.max(- diff_loss)\n",
    "\n",
    "                opt_G.zero_grad()\n",
    "                G_loss.backward()\n",
    "                opt_G.step()\n",
    "\n",
    "            # real painting from artist\n",
    "                G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                                      requires_grad=True).to(dev)  # random ideas\\n\n",
    "                # fake painting from G (random ideas)\n",
    "\n",
    "                G_values = GeneratorNet(G_ideas)\n",
    "                G_values , indices = torch.sort(G_values, descending=True)\n",
    "            #     print(artist_paintings)\n",
    "            #     print(G_paintings)\n",
    "\n",
    "                result_list = []\n",
    "                for index in range(BATCH_SIZE):\n",
    "                    h_list = []\n",
    "                    value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                        G_values[index])\n",
    "                    for i in range(Agent_number_n):\n",
    "                        h = DiscriminatorNet.calculate(\n",
    "                            value_list_tensor[i].cuda().type(torch.float32))\n",
    "                        h_list.append(h)\n",
    "                    h_list = torch.stack(h_list)\n",
    "                    result_list.append(torch.sum(h_list)/S_tensor.cuda())\n",
    "                result_list = torch.stack(result_list)\n",
    "\n",
    "                diff_loss = torch.max(result_list)-torch.min(result_list)\n",
    "\n",
    "                D_loss = torch.where((Agent_number_n-1)>torch.min(result_list),\n",
    "                    torch.square(((Agent_number_n-1)-torch.min(result_list))),\n",
    "                    torch.zeros(1).to(dev)\n",
    "                  )   + torch.where((Agent_number_n-Alpha)<torch.max(result_list),\n",
    "                                torch.square((torch.max(result_list)-(Agent_number_n-Alpha)))/10000,\n",
    "                                torch.zeros(1).to(dev)\n",
    "                              )\n",
    "\n",
    "\n",
    "                opt_D.zero_grad()\n",
    "                D_loss.backward()\n",
    "                opt_D.step()\n",
    "                \n",
    "            print(\"Gan:\",G_loss,D_loss)\n",
    "            print()\n",
    "\n",
    "        result_list = []\n",
    "        for index in range(len(testing_data)):\n",
    "            h_list = []\n",
    "            for i in range(Agent_number_n):\n",
    "                h = DiscriminatorNet.calculate(\n",
    "                    torch.tensor(testing_data[index][i]).to(dev).type(\n",
    "                        torch.float32))\n",
    "                h_list.append(float(h))\n",
    "            result_list.append(sum(h_list) / testing_label[index])\n",
    "        print(max(result_list), min(result_list),\n",
    "              max(result_list) - min(result_list),\n",
    "              (sum(result_list) / len(result_list) - min(result_list))+ Agent_number_n-1 - min(min(result_list),Agent_number_n-1) )\n",
    "\n",
    "        index_test_list.append(iteration)\n",
    "        test_losses.append(\n",
    "            (sum(result_list) / len(result_list) - min(result_list))+ Agent_number_n-1 - min(min(result_list),Agent_number_n-1) )\n",
    "        print()\n",
    "        index_test_list.append(iteration)\n",
    "        test_losses.append(\n",
    "            max(result_list)-min(result_list) )\n",
    "        \n",
    "        print()\n",
    "\n",
    "    scheduler_D.step()\n",
    "    scheduler_G.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T17:15:01.750894Z",
     "start_time": "2021-06-12T15:58:54.677Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylim(0, 1.0)\n",
    "plt.plot(index_test_list,test_losses)\n",
    "plt.ylabel('test loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T17:15:03.305384Z",
     "start_time": "2021-06-12T17:15:03.287406Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(DiscriminatorNet, \"save/Deep_learning_D_3_2\")\n",
    "if(Is_GAN):\n",
    "    torch.save(GeneratorNet, \"save/Deep_learning_G_3_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T17:15:01.752888Z",
     "start_time": "2021-06-12T15:58:54.683Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list.append(sum(h_list)/testing_label[index])\n",
    "    \n",
    "\n",
    "print(max(result_list),min(result_list),max(result_list)-min(result_list))\n",
    "print(sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T17:15:01.753886Z",
     "start_time": "2021-06-12T15:58:54.685Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T17:15:01.754884Z",
     "start_time": "2021-06-12T15:58:54.688Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate 10000 testing data on GeneratorNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T17:15:01.755880Z",
     "start_time": "2021-06-12T15:58:54.690Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "GeneratorNet = torch.load(\"save/Deep_learning_G_3_1\")\n",
    "def appen_test_G(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data_G.append(temp_list)\n",
    "    testing_label_G.append(S)\n",
    "# fake painting from G (random ideas)\n",
    "\n",
    "def read_testing_data_G():\n",
    "    for i in range(10000):\n",
    "        #appen_test_G(sorted(np.random.rand(Agent_number_n), reverse=True));\n",
    "        G_ideas = torch.randn(N_IDEAS).to(dev)  # random ideas\\n\n",
    "        G_values = GeneratorNet(G_ideas)\n",
    "        G_values , indices = torch.sort(G_values, descending=True)\n",
    "        appen_test_G(G_values.detach().cpu().numpy()) \n",
    "        \n",
    "testing_data_G = []\n",
    "testing_label_G = []\n",
    "read_testing_data_G()\n",
    "testing_data_G=np.array(testing_data_G)\n",
    "testing_label_G=np.array(testing_label_G)\n",
    "print(testing_data_G)\n",
    "print(testing_label_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T17:15:01.756877Z",
     "start_time": "2021-06-12T15:58:54.694Z"
    }
   },
   "outputs": [],
   "source": [
    "result_list_G = []\n",
    "for index in range(len(testing_data_G)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data_G[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list_G.append(sum(h_list)/testing_label_G[index])\n",
    "    \n",
    "\n",
    "print(max(result_list_G),min(result_list_G),max(result_list_G)-min(result_list_G))\n",
    "print(sum(result_list_G)/len(result_list_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T17:15:01.758872Z",
     "start_time": "2021-06-12T15:58:54.697Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list_G,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list_G)/len(result_list_G), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list_G.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list_G)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list_G)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-12T17:15:01.760868Z",
     "start_time": "2021-06-12T15:58:54.701Z"
    }
   },
   "outputs": [],
   "source": [
    "final_list = result_list + result_list_G\n",
    "\n",
    "\n",
    "plt.hist(final_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(final_list)/len(final_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "final_list.sort()\n",
    "\n",
    "plt.axvline(x=final_list[int(len(final_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=final_list[int(len(final_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
