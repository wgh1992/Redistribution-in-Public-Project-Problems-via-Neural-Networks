{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:53.196570Z",
     "start_time": "2021-07-14T02:48:28.399004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pygame\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm \n",
    "import matplotlib.cm as cm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy.interpolate import griddata\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "print(dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:53.211958Z",
     "start_time": "2021-07-14T02:48:53.198531Z"
    }
   },
   "outputs": [],
   "source": [
    "global temp_list\n",
    "temp_list = []\n",
    "Agent_number_n=9;\n",
    "Alpha = 0.74\n",
    "\n",
    "# Hyper Parameters\n",
    "echo = 101 \n",
    "BATCH_SIZE = 64\n",
    "LR_G = 0.001           # learning rate for generator\n",
    "LR_D = 0.001           # learning rate for discriminator\n",
    "N_IDEAS = Agent_number_n             # think of this as number of ideas for generating an art work (Generator)\n",
    "ART_COMPONENTS = Agent_number_n     # it could be total point G can draw in the canvas\n",
    "\n",
    "Is_GAN = True # if use Gan\n",
    "\n",
    "def Generate_distribution(Agent_number_n):\n",
    "    return sorted(np.random.rand(Agent_number_n), reverse=True)\n",
    "    #return sorted(np.random.normal(normalloc,normalscale,Agent_number_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:53.227875Z",
     "start_time": "2021-07-14T02:48:53.213915Z"
    }
   },
   "outputs": [],
   "source": [
    "new_input = 3\n",
    "def Dimensionality_reduction(data_sorted):\n",
    "    out_data = torch.ones(new_input).cuda()\n",
    "    out_data[0] = torch.max(data_sorted) \n",
    "    out_data[1] = torch.sum(data_sorted) \n",
    "    \n",
    "    temp_list = []\n",
    "    for i in range(len(data_sorted)-1):\n",
    "        temp_list.append(data_sorted[i] - data_sorted[i + 1])\n",
    "    \n",
    "    temp_tensor = torch.stack(temp_list)    \n",
    "    out_data[2] = torch.max(temp_tensor) \n",
    "    return out_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:53.305703Z",
     "start_time": "2021-07-14T02:48:53.228873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.75879068 0.57170913 0.42410945 ... 0.32427633 0.04464197 0.01892827]\n",
      "  [0.85737631 0.57170913 0.42410945 ... 0.32427633 0.04464197 0.01892827]\n",
      "  [0.85737631 0.75879068 0.42410945 ... 0.32427633 0.04464197 0.01892827]\n",
      "  ...\n",
      "  [0.85737631 0.75879068 0.57170913 ... 0.3507477  0.04464197 0.01892827]\n",
      "  [0.85737631 0.75879068 0.57170913 ... 0.3507477  0.32427633 0.01892827]\n",
      "  [0.85737631 0.75879068 0.57170913 ... 0.3507477  0.32427633 0.04464197]]\n",
      "\n",
      " [[0.81826671 0.60727621 0.5719929  ... 0.29896319 0.18504818 0.14024323]\n",
      "  [0.93913325 0.60727621 0.5719929  ... 0.29896319 0.18504818 0.14024323]\n",
      "  [0.93913325 0.81826671 0.5719929  ... 0.29896319 0.18504818 0.14024323]\n",
      "  ...\n",
      "  [0.93913325 0.81826671 0.60727621 ... 0.47693709 0.18504818 0.14024323]\n",
      "  [0.93913325 0.81826671 0.60727621 ... 0.47693709 0.29896319 0.14024323]\n",
      "  [0.93913325 0.81826671 0.60727621 ... 0.47693709 0.29896319 0.18504818]]\n",
      "\n",
      " [[0.74715195 0.72371357 0.5025056  ... 0.35287821 0.15648536 0.06730707]\n",
      "  [0.80681941 0.72371357 0.5025056  ... 0.35287821 0.15648536 0.06730707]\n",
      "  [0.80681941 0.74715195 0.5025056  ... 0.35287821 0.15648536 0.06730707]\n",
      "  ...\n",
      "  [0.80681941 0.74715195 0.72371357 ... 0.36614225 0.15648536 0.06730707]\n",
      "  [0.80681941 0.74715195 0.72371357 ... 0.36614225 0.35287821 0.06730707]\n",
      "  [0.80681941 0.74715195 0.72371357 ... 0.36614225 0.35287821 0.15648536]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.95968932 0.84527328 0.50713605 ... 0.13989984 0.03260344 0.00301746]\n",
      "  [0.98130203 0.84527328 0.50713605 ... 0.13989984 0.03260344 0.00301746]\n",
      "  [0.98130203 0.95968932 0.50713605 ... 0.13989984 0.03260344 0.00301746]\n",
      "  ...\n",
      "  [0.98130203 0.95968932 0.84527328 ... 0.18167376 0.03260344 0.00301746]\n",
      "  [0.98130203 0.95968932 0.84527328 ... 0.18167376 0.13989984 0.00301746]\n",
      "  [0.98130203 0.95968932 0.84527328 ... 0.18167376 0.13989984 0.03260344]]\n",
      "\n",
      " [[0.73320518 0.71037172 0.56100315 ... 0.33401496 0.12841781 0.0943509 ]\n",
      "  [0.95071089 0.71037172 0.56100315 ... 0.33401496 0.12841781 0.0943509 ]\n",
      "  [0.95071089 0.73320518 0.56100315 ... 0.33401496 0.12841781 0.0943509 ]\n",
      "  ...\n",
      "  [0.95071089 0.73320518 0.71037172 ... 0.33741597 0.12841781 0.0943509 ]\n",
      "  [0.95071089 0.73320518 0.71037172 ... 0.33741597 0.33401496 0.0943509 ]\n",
      "  [0.95071089 0.73320518 0.71037172 ... 0.33741597 0.33401496 0.12841781]]\n",
      "\n",
      " [[0.72376921 0.68631037 0.68255481 ... 0.33573555 0.18071486 0.08511129]\n",
      "  [0.96812536 0.68631037 0.68255481 ... 0.33573555 0.18071486 0.08511129]\n",
      "  [0.96812536 0.72376921 0.68255481 ... 0.33573555 0.18071486 0.08511129]\n",
      "  ...\n",
      "  [0.96812536 0.72376921 0.68631037 ... 0.40425865 0.18071486 0.08511129]\n",
      "  [0.96812536 0.72376921 0.68631037 ... 0.40425865 0.33573555 0.08511129]\n",
      "  [0.96812536 0.72376921 0.68631037 ... 0.40425865 0.33573555 0.18071486]]]\n",
      "[3.70945055 4.59293747 4.10618381 5.35193766 5.17036527 3.28896475\n",
      " 4.09633693 4.50466604 3.73006021 5.4802499  3.91493559 5.11642994\n",
      " 5.13106215 4.69835935 3.67315713 5.03115513 3.90291962 3.67779161\n",
      " 5.00281333 3.08321616 5.9219164  5.875694   6.27137084 4.9134091\n",
      " 4.5300084  4.82451262 4.76785276 3.78052367 4.66168766 3.61851757\n",
      " 4.33868344 3.24188812 5.01536166 4.85494628 5.07295022 4.63725126\n",
      " 3.11626132 2.98004762 3.40447754 3.47219474 4.81557448 2.99258258\n",
      " 2.21420414 4.20649528 2.97482346 2.44469401 4.66315441 3.25692159\n",
      " 2.92820726 3.97389512 4.20887905 4.58183822 5.21430318 5.1995744\n",
      " 4.39168397 2.93447147 5.40547056 3.72853524 4.9751341  4.77567267\n",
      " 4.01357708 4.44309078 4.81714399 5.36525276 4.0306972  3.95034996\n",
      " 4.01938176 4.92636792 5.5503403  5.88622056 3.35538239 4.33493289\n",
      " 5.93802051 3.79925252 5.45424039 5.14570585 3.67860397 3.86905089\n",
      " 3.95212159 4.81318545 5.2052768  3.91454675 3.2363535  5.58322789\n",
      " 5.26748554 3.87534427 3.90637669 3.70766654 3.82439028 3.56356952\n",
      " 5.60052433 5.90522782 5.31060945 5.05632835 4.02017594 5.45851824\n",
      " 5.19914464 5.3894461  5.63848984 5.54119694 3.91729511 4.50189514\n",
      " 4.52324734 6.18630781 5.42345358 3.46279092 4.51002192 4.67211556\n",
      " 5.00246777 3.86926166 4.8499306  2.79100485 4.61639001 3.04353\n",
      " 3.98129769 5.66599054 5.48222978 4.41986619 4.58001929 5.30371377\n",
      " 2.48734315 5.19070146 3.7984737  4.71173078 4.36699521 4.17064982\n",
      " 5.91916566 5.5279008  5.33222211 4.26924275 4.13137156 4.32776783\n",
      " 4.80529229 4.3025926  4.46213437 4.40703652 2.72323143 5.19303773\n",
      " 5.58979886 4.60896605 5.22494021 3.57455617 4.05363895 2.91934187\n",
      " 3.51755593 2.67030135 3.53023765 3.84458202 4.42324598 5.34550156\n",
      " 6.59186499 5.05453642 5.4737391  4.00511555 4.05187568 4.83093521\n",
      " 3.55838369 4.60659416 4.46931058 4.6389509  4.19046373 2.01838679\n",
      " 5.0873053  3.33775917 5.81519284 4.44102525 3.13370796 4.2620385\n",
      " 4.31151597 4.76990688 4.51330071 4.15920677 4.66188673 4.24385421\n",
      " 3.9044114  5.06038322 2.58107724 4.35527338 4.58825057 4.47927364\n",
      " 4.94589855 5.53209024 5.02058028 5.16050506 5.20931308 5.29885535\n",
      " 4.39653972 4.81064402 4.24207603 4.15193279 4.67095672 3.40051322\n",
      " 4.35608159 6.25857745 6.23706568 3.35518856 2.75096463 2.93642083\n",
      " 4.27395451 4.1634977  4.17519869 5.40371544 3.93901269 3.15377559\n",
      " 5.8794046  5.96562832 4.72617584 4.45594016 2.87302218 4.8955057\n",
      " 5.2607358  3.78328571 4.09052987 3.22097595 4.84317238 5.5423713\n",
      " 5.75107414 4.05345425 3.95687921 4.17007378 5.15673076 4.00226622\n",
      " 5.77521084 3.64773789 4.71460471 4.55031151 3.70561676 5.97131272\n",
      " 5.7764203  7.20515213 4.81096338 3.18403643 4.09266855 5.47788039\n",
      " 6.03136663 4.56413547 2.7353153  5.20753088 2.77204945 3.98430446\n",
      " 3.13675619 5.09487989 5.42212937 5.93891157 3.45031205 2.17435713\n",
      " 3.77398644 5.49064031 4.67076734 2.87199332 3.96810605 4.42328292\n",
      " 4.9435539  4.25724767 5.88643602 5.27477594 4.09918361 6.31075942\n",
      " 3.77583497 4.01772917 5.79954327 3.35476973 4.30091978 5.52267484\n",
      " 4.36869337 3.80204784 4.98466176 4.50283453 6.11267347 4.32485797\n",
      " 4.59127527 4.77041668 5.00362906 4.24326493 5.39396182 4.83984312\n",
      " 5.4211876  6.23168023 4.90737687 4.13714676 5.32297557 4.29619571\n",
      " 4.06451165 4.05773351 6.09046661 4.79619585 6.28139448 4.60436609\n",
      " 3.7903011  3.71316742 5.265795   4.06903967 4.19073209 4.69255811\n",
      " 4.2630864  1.85605661 4.58070399 3.55949317 4.82647424 6.63813622\n",
      " 3.90973961 3.69866474 4.39243455 2.86899229 3.51379205 4.55827147\n",
      " 1.77731658 3.40316781 3.93366103 3.56818498 4.41008926 3.72095147\n",
      " 4.60280411 4.82361021 5.89513021 5.08745808 5.52918303 3.24602229\n",
      " 5.24964279 4.75495911 2.8943997  4.68942971 4.86790442 5.6618342\n",
      " 3.80215335 3.93493535 3.95442007 4.95704796 5.66357339 2.73512035\n",
      " 5.32810731 4.82407016 4.1182487  4.83175557 5.04892182 6.11040805\n",
      " 3.84767263 4.09013793 5.74209252 3.6304599  4.38286552 4.22891568\n",
      " 3.68154444 3.74844254 2.25371283 4.64376632 3.8653008  5.09111912\n",
      " 3.54233888 3.79554831 4.55132363 4.18203165 4.254467   4.71130962\n",
      " 4.74551668 4.53652644 5.79467719 4.66187637 4.54566905 3.15277772\n",
      " 4.05302613 3.58795091 5.44680085 3.38922914 3.84078517 4.93375464\n",
      " 3.83511343 3.9230786  3.24450265 3.87653073 5.50222374 4.41350133\n",
      " 3.91890243 5.24243592 3.59790331 3.00724093 4.55231743 3.30246686\n",
      " 2.28676276 4.2608249  4.46690802 5.43670276 5.91738544 4.84831605\n",
      " 4.60941049 4.42278671 3.6524265  4.39809231 3.73656499 4.02876333\n",
      " 3.58906891 3.60019017 3.00616782 5.40128008 3.97179912 5.53167679\n",
      " 4.30661261 5.14014039 4.65530388 3.3944428  4.12322449 4.01597049\n",
      " 4.92980236 3.56981492 5.23482952 4.30174872 4.70792988 5.24448932\n",
      " 3.90470363 5.67499698 3.26121478 3.42921316 5.54763988 4.5928381\n",
      " 4.49530502 3.92123709 5.07102194 4.58786952 4.71259669 4.62863403\n",
      " 3.53357586 5.00102317 3.49983712 4.14424196 4.75604545 4.02006784\n",
      " 3.84183536 5.39393983 3.73653718 4.88958275 6.09869716 4.18265668\n",
      " 5.47043388 4.67483987 3.97486285 3.29314244 2.29182277 3.76315344\n",
      " 4.29906453 4.47015484 3.69026948 4.98215186 3.46927545 4.15038197\n",
      " 3.64154682 4.28617531 4.01426831 4.19606397 4.1817553  6.05681936\n",
      " 4.4217215  6.1652676  5.21009106 3.51908885 3.41046279 3.75162223\n",
      " 5.04652704 4.8750907  3.96722522 4.43759966 3.08259262 3.78394985\n",
      " 3.71952624 2.89312164 4.09181344 4.19905486 5.14243918 4.47421262\n",
      " 1.93888686 4.81866431 3.76956849 6.38756527 5.39087588 3.74022774\n",
      " 4.90286637 5.43033875 5.81867486 4.64293307 4.58571794 4.0292586\n",
      " 4.49384516 4.57346506 5.86119885 5.33979563 4.70581874 5.48312112\n",
      " 4.44888417 5.9026349  5.33247699 5.34772966 4.98402342 4.73982801\n",
      " 4.82790555 4.94364333 3.55693365 4.20876161 4.92981023 4.95843214\n",
      " 7.33393824 4.40484921 4.36344961 3.68403695 4.76178688 4.78085817\n",
      " 4.39772341 3.84319986 3.9620766  4.27732462 5.45768943 3.17980538\n",
      " 5.38449309 4.57223149 5.81993979 2.99057696 4.56877212 4.63002102\n",
      " 3.15651005 4.48477329 4.31953169 3.9345649  4.92705807 4.69505031\n",
      " 4.1189736  5.15996725 4.73928914 3.03076491 3.81635145 2.77849097\n",
      " 4.81984051 5.59835214 5.84444956 4.39349006 4.21188927 4.58303909\n",
      " 4.71238667 5.22456529 3.25421957 3.77872889 4.65954332 5.29046265\n",
      " 5.04396278 4.17400786 5.41249081 3.50554821 4.37648375 4.95212608\n",
      " 5.69349843 4.12107113 3.8692833  5.59764213 4.93087638 4.3954056\n",
      " 2.76752667 4.49161657 5.10647913 4.56364963 2.85291166 3.67664369\n",
      " 3.55990857 4.78039089 2.7281149  4.3612104  5.42660203 3.9855924\n",
      " 4.77383264 2.79311118 5.75712365 4.05944778 5.76769957 5.36017981\n",
      " 6.94756869 2.77636136 5.36226862 6.57480579 5.72295273 6.15906562\n",
      " 3.81470854 4.25021963 4.06610507 4.11383929 4.00359494 3.56615056\n",
      " 2.89206467 5.89929027 4.62945324 5.60573373 4.40876236 5.68701331\n",
      " 4.43235363 5.08850594 4.91546359 5.00095203 5.42217852 2.86552474\n",
      " 4.18332883 4.79325229 4.68996915 4.64100052 4.66600069 4.30955633\n",
      " 4.74586869 4.20818272 5.1639385  2.6821118  5.15288516 3.64922973\n",
      " 4.47814143 5.29163436 4.57446585 5.67721774 3.7847423  5.23560545\n",
      " 5.17090058 2.70878023 5.23567779 4.52096294 3.38363883 5.24609712\n",
      " 3.20268391 4.21449557 4.85256694 4.42206222 5.26120358 5.87208841\n",
      " 4.75212525 5.43318824 4.67963908 4.55367343 4.58729403 5.3159277\n",
      " 5.47078854 3.78901323 5.43312681 4.09680449 3.55464844 4.73775126\n",
      " 3.69171563 2.60300066 3.30161801 4.05930368 3.53791671 4.64009403\n",
      " 5.58568571 3.83377221 4.11256679 4.48717865 4.01932801 5.6816249\n",
      " 4.40053844 4.76720889 4.02276126 5.48872852 2.57692492 3.81628034\n",
      " 3.88021357 3.66011526 6.02762886 3.52021705 5.23078962 3.80440832\n",
      " 4.8497428  4.53849154 3.93116006 4.69006338 4.72958266 4.53068984\n",
      " 4.24799647 4.82222773 4.83958378 3.18399535 4.31554751 5.03579556\n",
      " 3.14597737 4.23515961 3.89455316 5.8142492  4.92835389 4.24324988\n",
      " 4.26194425 3.55258911 5.56422366 4.02550996 3.64197276 4.34154177\n",
      " 4.25892205 4.76360675 5.57130808 4.71505321 3.15300379 3.41750426\n",
      " 5.24232787 2.62943946 4.27822857 4.89737435 4.44526587 4.79928093\n",
      " 4.22529585 3.65471123 5.60658749 3.50307448 4.73896416 3.41027269\n",
      " 5.07010191 3.11985843 3.72995596 5.00840354 4.48102021 3.96906218\n",
      " 4.10074019 4.05726288 3.77636217 4.69806018 3.1312375  5.68917976\n",
      " 4.56018517 3.49882561 4.62162183 3.52615407 7.16830935 4.43225088\n",
      " 4.92625007 4.55198241 4.46144241 4.10058289 4.52637796 3.76548723\n",
      " 5.31874982 5.12765131 4.83024456 3.56397261 3.1723754  5.17677516\n",
      " 4.14981236 4.39828563 4.15685775 5.71632671 4.87759199 4.81163276\n",
      " 6.01147725 4.99022879 4.60720118 4.51817487 3.63051459 4.99915803\n",
      " 4.28857125 5.18210411 4.92161455 3.63673084 3.9899872  2.30913597\n",
      " 5.27279866 3.24814642 4.6672142  4.96963169 3.73664762 5.08502745\n",
      " 5.02067687 3.95130032 5.16746116 3.26523948 4.96643587 6.05164167\n",
      " 2.85813685 5.58991596 3.4582863  4.7827057  5.8567743  6.24688565\n",
      " 3.06496294 4.78839861 2.45972583 6.01216318 4.3392721  3.94868475\n",
      " 3.13486289 5.31122102 4.52687761 4.11994868 4.44517819 4.75431577\n",
      " 4.60051515 3.2509318  5.36073191 4.20268191 4.64644765 4.05550316\n",
      " 4.93708038 5.2066062  5.94979247 3.00280708 5.22212101 4.69444829\n",
      " 6.57532324 4.4905242  4.32966907 4.29877372 3.05004742 5.99802657\n",
      " 4.5661932  5.19157178 3.47701581 4.65069497 5.08236699 4.39430097\n",
      " 4.8900052  4.05465289 4.65486853 5.27369767 4.02500675 4.6118593\n",
      " 4.47833127 5.60695302 2.99661885 5.13806649 4.77980913 3.57767359\n",
      " 3.19410046 5.16090508 4.8933294  3.62651257 3.73208127 4.36922049\n",
      " 5.13815793 4.16599869 5.20625291 3.85311003 4.85090874 4.26948683\n",
      " 4.61882829 4.89659228 5.49842635 4.88860506 3.65429888 3.60452587\n",
      " 5.19369638 4.3498121  3.98990729 4.98073312 4.73750479 2.77325995\n",
      " 4.48037282 4.42676776 4.76168171 5.34652175 4.22541544 3.89416314\n",
      " 3.65738157 3.14564964 3.9673089  2.47294625 5.02252309 4.40197443\n",
      " 5.19344054 5.30492773 4.23161731 4.01878849 3.00161912 4.04894797\n",
      " 4.30798997 4.90934465 5.39230542 4.52528291 5.99424804 4.15916815\n",
      " 4.45957744 3.85500505 6.03574702 3.94782508 4.68753047 2.67453357\n",
      " 6.29256158 3.70610428 6.10712834 3.8304366  4.14638099 4.51428078\n",
      " 4.19251859 2.71060882 4.20326144 4.72943646 4.47403324 3.74068202\n",
      " 5.43272757 3.95754063 5.2908263  4.77143424 5.37965671 6.32102875\n",
      " 5.944627   5.32514911 4.43854189 4.28685535 3.70639177 4.61380626\n",
      " 5.1420398  4.23144349 4.46331225 4.96645186 4.96268797 3.56595599\n",
      " 3.18520299 2.96726114 4.56133761 5.40741959 6.0336216  3.1166927\n",
      " 4.48337957 4.11831423 4.58128885 5.09469863 5.38673751 3.28641897\n",
      " 4.54451262 5.00504815 4.17414265 6.06154232 4.52470816 5.54027828\n",
      " 4.18693985 5.86599407 3.97182733 2.77367551 6.23822033 4.33680725\n",
      " 4.38456394 4.81708672 4.55204839 3.27510659 5.18775585 5.05215467\n",
      " 3.54719543 5.30385773 2.7612188  4.54662251 3.46238662 3.75859019\n",
      " 3.53669404 2.90785912 5.43247542 5.11146457 4.30480455 3.33263958\n",
      " 4.97005457 6.07312996 5.82048741 4.45634089 5.99555836 4.48715128\n",
      " 5.85092631 3.77320637 4.27364641 5.92344962 6.11047159 4.23237234\n",
      " 4.00022369 3.27092793 4.70954883 3.8196871  4.18210398 4.40354599\n",
      " 3.40419319 5.81443078 5.89768474 2.5146745  4.24030212 4.01341253\n",
      " 4.32715483 3.59006326 5.23095349 4.70143015 4.88959442 4.9808645\n",
      " 5.090367   6.13915943 5.28656301 5.37591209 4.87029409 3.10475732\n",
      " 4.4173725  5.0145922  4.89919807 5.26318388 3.89285046 3.52413283\n",
      " 5.15799365 4.82503966 4.33121794 4.2552219  5.5985328  4.40941055\n",
      " 3.29010763 5.91298668 3.97831218 4.62191077 4.07885445 6.61569681\n",
      " 5.19060057 4.0603666  4.27561179 4.70411684]\n"
     ]
    }
   ],
   "source": [
    "def h_3_star(a, b, t):\n",
    "    return a - min(a, t) + b - min(b, t) + max(min(a, t)+min(b, t), 2*t/3) + 1/2 * max(min(a, t)+min(b, t), t) - 1/2 * max(max(min(a, t), min(b, t)), 2*t/3) - t/6\n",
    "\n",
    "\n",
    "def f_function(a, b, z):\n",
    "    if(z >= 1):\n",
    "        return (a+b)/2 + z/3\n",
    "    else:\n",
    "        return z/3 + h_3_star(a, b, 1-z)/2\n",
    "\n",
    "def h_function_label(input_list):\n",
    "    #input_list = sorted(input_list)\n",
    "    g_list = []\n",
    "    for j1 in range(len(input_list) ):\n",
    "        for j2 in range(len(input_list)):\n",
    "            if(j1 != j2):\n",
    "                a = input_list[j1]\n",
    "                b = input_list[j2]\n",
    "                z = sum(input_list)- a-b\n",
    "\n",
    "                g_list.append( f_function(a, b, z) * (Agent_number_n-1))\n",
    "    h = sum(g_list) * 3 /  (Agent_number_n) /  (Agent_number_n-1) /  (Agent_number_n - 2)\n",
    "    return h\n",
    "\n",
    "def appen(_x_list,y):\n",
    "    global temp_list\n",
    "    temp_list.append(_x_list)\n",
    "    \n",
    "def appen_train(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "        \n",
    "        h = h_function_label(temp)\n",
    "        h_list.append(float(h))\n",
    "    temp_list = np.array(temp_list)\n",
    "    x_list = np.array(x_list)\n",
    "    return temp_list,S,x_list,h_list\n",
    "    \n",
    "\n",
    "def appen_test(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data.append(temp_list)\n",
    "    testing_label.append(S)\n",
    "    temp_list = np.array(temp_list)\n",
    "    return temp_list,S\n",
    "    \n",
    "\n",
    "def read_testing_data():\n",
    "    for i in range(1000):\n",
    "        appen_test(Generate_distribution(Agent_number_n));\n",
    "                        \n",
    "            \n",
    "\n",
    "testing_data=[]\n",
    "testing_label=[]\n",
    "S=1.0\n",
    "read_testing_data();\n",
    "\n",
    "testing_data=np.array(testing_data)\n",
    "testing_label=np.array(testing_label)\n",
    "print(testing_data)\n",
    "print(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:53.321625Z",
     "start_time": "2021-07-14T02:48:53.306666Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.normal_(m.bias, mean=0.0, std=0.01)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.input_dim = new_input# (Agent_number_n-1)\n",
    "        self.hidden_dim = 128\n",
    "        self.output_dim = 1\n",
    "        self.hidden_layer_count = 6 \n",
    "        \n",
    "        current_dim = self.input_dim\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(self.hidden_layer_count):\n",
    "            self.layers.append(torch.nn.Linear(current_dim, self.hidden_dim))\n",
    "            current_dim = self.hidden_dim\n",
    "        self.layers.append(torch.nn.Linear(current_dim, self.output_dim))\n",
    "\n",
    "    def calculate(self, value_list):\n",
    "        h = Dimensionality_reduction(value_list)\n",
    "        for layer in self.layers:\n",
    "            h = torch.relu(layer(h))\n",
    "        return h\n",
    "\n",
    "    def forward(self, input_list,input_label,list_x):\n",
    "        global iteration,echo,target_order\n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        loss3 = 0\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).to(dev).type(torch.float32)\n",
    "        h_list = []\n",
    "\n",
    "        for i in range(Agent_number_n):\n",
    "            h = self.calculate(input_list[i])\n",
    "            h_list.append(h)\n",
    "#             loss3 += torch.square(h_function_2(input_list)-h2[1])\n",
    "            \n",
    "        input_label = torch.from_numpy(\n",
    "            np.array(input_label)).to(dev).type(torch.float32)\n",
    "        sum_h = torch.sum(torch.cat(h_list)).to(dev)\n",
    "\n",
    "\n",
    "        loss1 = torch.where((Agent_number_n-1)*input_label>sum_h,\n",
    "                        torch.square(((Agent_number_n-1)*input_label-sum_h)),\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "        loss2 = torch.where((Agent_number_n-Alpha)*input_label<sum_h,\n",
    "                        torch.square((sum_h-(Agent_number_n-Alpha)*input_label))/100,\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "\n",
    "        return loss1,loss2\n",
    "    \n",
    "    def supervised_loss(self, input_list,label):\n",
    "        global iteration,echo,target_order\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).to(dev).type(torch.float32)\n",
    "        loss = 0 \n",
    "        for i in range(Agent_number_n):\n",
    "            h = self.calculate(input_list[i])\n",
    "            loss += torch.square(h - label[i])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:53.855221Z",
     "start_time": "2021-07-14T02:48:53.323620Z"
    }
   },
   "outputs": [],
   "source": [
    "def redistribution_value_function(input_tensor):\n",
    "    S = torch.max(torch.sum(input_tensor), torch.ones(1).to(dev))\n",
    "    temp_list = []\n",
    "\n",
    "\n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        \n",
    "        for j in range(Agent_number_n):\n",
    "            if(i != j):\n",
    "                temp .append(input_tensor[j])\n",
    "                \n",
    "        temp = torch.stack(temp)\n",
    "        temp_list.append(temp)\n",
    "    return torch.stack(temp_list), S\n",
    "\n",
    "GeneratorNet = nn.Sequential(                      # Generator\n",
    "    # random ideas (could from normal distribution)\n",
    "    nn.Linear(N_IDEAS, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    # making a painting from these random ideas\n",
    "    nn.Linear(64, ART_COMPONENTS),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.793093Z",
     "start_time": "2021-07-14T02:48:53.858212Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-564ae25454f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mDiscriminatorNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mGeneratorNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mDiscriminatorNet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"save/Deep_learning_D_9_supervised\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIs_GAN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mGeneratorNet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"save/Deep_learning_G_9\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m             \u001b[0mload_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[1;34m(data_type, size, key, location)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 846\u001b[1;33m         \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[0;32m    136\u001b[0m                            \u001b[1;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                            \u001b[1;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "DiscriminatorNet  = Net()\n",
    "DiscriminatorNet.apply(weight_init)\n",
    "GeneratorNet.apply(weight_init)\n",
    "DiscriminatorNet = torch.load(\"save/Deep_learning_D_9_supervised\")\n",
    "if(Is_GAN):\n",
    "    GeneratorNet = torch.load(\"save/Deep_learning_G_9\")\n",
    "DiscriminatorNet.to(dev)\n",
    "GeneratorNet.to(dev)\n",
    "\n",
    "opt_D = torch.optim.Adam(DiscriminatorNet.parameters(), lr=LR_D)\n",
    "opt_G = torch.optim.Adam(GeneratorNet.parameters(), lr=LR_G)\n",
    "\n",
    "\n",
    "scheduler_D = torch.optim.lr_scheduler.StepLR(opt_D, step_size=100, gamma=0.98)\n",
    "scheduler_G = torch.optim.lr_scheduler.StepLR(opt_G, step_size=100, gamma=0.98)\n",
    "\n",
    "index_train_list = []\n",
    "index_test_list = []\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.797083Z",
     "start_time": "2021-07-14T02:48:28.375Z"
    }
   },
   "outputs": [],
   "source": [
    "#supervised\n",
    "index_supervisedtrain_list = []\n",
    "supervisedtrain_losses = []\n",
    "for iteration in range(echo):\n",
    "\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "    \n",
    "    loss_sum = 0\n",
    "    denominator = 0\n",
    "    for index in range(0, BATCH_SIZE):\n",
    "        training_data_i, training_S, training_data,label = appen_train(\n",
    "            Generate_distribution(Agent_number_n))\n",
    "        h_loss = DiscriminatorNet.supervised_loss(training_data_i, label)\n",
    "        denominator += 1\n",
    "        loss_sum += h_loss\n",
    "\n",
    "    loss_sum = torch.sum(loss_sum)\n",
    "    loss = (loss_sum) / denominator \n",
    "    total_batch_loss += float(loss_sum)\n",
    "\n",
    "    opt_D.zero_grad()\n",
    "    loss.backward()\n",
    "    opt_D.step()\n",
    "\n",
    "    if (iteration%100 == 0):\n",
    "        print(iteration,loss,total_batch_loss)\n",
    "        index_supervisedtrain_list.append(iteration)\n",
    "        supervisedtrain_losses.append(total_batch_loss)\n",
    "    scheduler_D.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.798080Z",
     "start_time": "2021-07-14T02:48:28.376Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylim(0, 0.1)\n",
    "plt.plot(index_supervisedtrain_list ,supervisedtrain_losses)\n",
    "plt.ylabel('supervised train loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.799078Z",
     "start_time": "2021-07-14T02:48:28.378Z"
    }
   },
   "outputs": [],
   "source": [
    "if(echo!=0):\n",
    "    torch.save(DiscriminatorNet, \"save/Deep_learning_D_9_supervised\")\n",
    "    if(Is_GAN):\n",
    "        torch.save(GeneratorNet, \"save/Deep_learning_G_9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.800075Z",
     "start_time": "2021-07-14T02:48:28.379Z"
    }
   },
   "outputs": [],
   "source": [
    "opt_D = torch.optim.Adam(DiscriminatorNet.parameters(), lr=LR_D/100)\n",
    "opt_G = torch.optim.Adam(GeneratorNet.parameters(), lr=LR_G/100)\n",
    "scheduler_D = torch.optim.lr_scheduler.StepLR(opt_D, step_size=100, gamma=0.98)\n",
    "scheduler_G = torch.optim.lr_scheduler.StepLR(opt_G, step_size=100, gamma=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.801072Z",
     "start_time": "2021-07-14T02:48:28.381Z"
    }
   },
   "outputs": [],
   "source": [
    "for iteration in range(int(echo)):\n",
    "\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "    \n",
    "    loss2_list = []\n",
    "    loss1_sum = 0\n",
    "    loss2_sum = 0\n",
    "    loss = 0\n",
    "    if(Is_GAN==False):\n",
    "        denominator = 0\n",
    "        for index in range(0, BATCH_SIZE):\n",
    "            training_data_i, training_label, training_data, label = appen_train(\n",
    "                Generate_distribution(Agent_number_n))\n",
    "            h_loss1, h_loss2 = DiscriminatorNet(training_data_i, training_label,\n",
    "                                           training_data)\n",
    "            denominator += 1\n",
    "            loss1_sum += h_loss1\n",
    "            loss2_sum += h_loss2\n",
    "\n",
    "        loss_sum = torch.sum(loss1_sum + loss2_sum)\n",
    "        loss = (loss_sum) / denominator \n",
    "        total_batch_loss +=float(loss_sum)\n",
    "\n",
    "        opt_D.zero_grad()\n",
    "        loss.backward()\n",
    "        opt_D.step()\n",
    "\n",
    "        temp_number = iteration\n",
    "        index_train_list.append(iteration)\n",
    "        train_losses.append(total_batch_loss)\n",
    "\n",
    "\n",
    "    ## Gan \n",
    "    else:## Gan Work traning GeneratorNet\n",
    "\n",
    "        # real painting from artist\n",
    "        G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                              requires_grad=True).to(dev)  # random ideas\\n\n",
    "        # fake painting from G (random ideas)\n",
    "\n",
    "        G_values = GeneratorNet(G_ideas)\n",
    "        G_values , indices = torch.sort(G_values, descending=True)\n",
    "    #     print(artist_paintings)\n",
    "    #     print(G_paintings)\n",
    "\n",
    "        result_list = []\n",
    "        for index in range(BATCH_SIZE):\n",
    "            h_list = []\n",
    "            value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                G_values[index])\n",
    "            for i in range(Agent_number_n):\n",
    "                h = DiscriminatorNet.calculate(\n",
    "                    value_list_tensor[i].cuda().type(torch.float32))\n",
    "                h_list.append(h)\n",
    "            h_list = torch.stack(h_list)\n",
    "            result_list.append(torch.sum(h_list)/S_tensor.cuda())\n",
    "        result_list = torch.stack(result_list)\n",
    "\n",
    "        diff_loss = torch.max(result_list)-torch.min(result_list)\n",
    "        G_loss = torch.max(- diff_loss)\n",
    "\n",
    "        opt_G.zero_grad()\n",
    "        G_loss.backward()\n",
    "        opt_G.step()\n",
    "\n",
    "    # real painting from artist\n",
    "        G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                              requires_grad=True).to(dev)  # random ideas\\n\n",
    "        # fake painting from G (random ideas)\n",
    "\n",
    "        G_values = GeneratorNet(G_ideas)\n",
    "        G_values , indices = torch.sort(G_values, descending=True)\n",
    "    #     print(artist_paintings)\n",
    "    #     print(G_paintings)\n",
    "\n",
    "        result_list = []\n",
    "        for index in range(BATCH_SIZE):\n",
    "            h_list = []\n",
    "            value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                G_values[index])\n",
    "            for i in range(Agent_number_n):\n",
    "                h = DiscriminatorNet.calculate(\n",
    "                    value_list_tensor[i].cuda().type(torch.float32))\n",
    "                h_list.append(h)\n",
    "            h_list = torch.stack(h_list)\n",
    "            result_list.append(torch.sum(h_list)/S_tensor.cuda())\n",
    "        result_list = torch.stack(result_list)\n",
    "\n",
    "        diff_loss = torch.max(result_list)-torch.min(result_list)\n",
    "\n",
    "        D_loss = torch.where((Agent_number_n-1)>torch.min(result_list),\n",
    "            torch.square(((Agent_number_n-1)-torch.min(result_list))),\n",
    "            torch.zeros(1).to(dev)\n",
    "          )   + torch.where((Agent_number_n-Alpha)<torch.max(result_list),\n",
    "                        torch.square((torch.max(result_list)-(Agent_number_n-Alpha)))/10000,\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "\n",
    "        opt_D.zero_grad()\n",
    "        D_loss.backward()\n",
    "        opt_D.step()\n",
    "\n",
    "\n",
    "\n",
    "    scheduler_D.step()\n",
    "    scheduler_G.step()\n",
    "    temp_number = iteration\n",
    "    if (iteration%50 == 0):\n",
    "        print(temp_number)\n",
    "        if(Is_GAN):\n",
    "            print(\"Gan:\",G_loss,D_loss)\n",
    "            print()\n",
    "        else:\n",
    "            print(loss,float(loss1_sum),float(loss2_sum))\n",
    "            print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.801072Z",
     "start_time": "2021-07-14T02:48:28.384Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylim(0, 1.0)\n",
    "plt.plot(index_test_list,test_losses)\n",
    "plt.ylabel('test loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.802070Z",
     "start_time": "2021-07-14T02:48:28.386Z"
    }
   },
   "outputs": [],
   "source": [
    "if(echo!=0):\n",
    "    torch.save(DiscriminatorNet, \"save/Deep_learning_D_9_supervised_1\")\n",
    "    if(Is_GAN):\n",
    "        torch.save(GeneratorNet, \"save/Deep_learning_G_9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.803067Z",
     "start_time": "2021-07-14T02:48:28.388Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list.append(sum(h_list)/testing_label[index])\n",
    "    \n",
    "\n",
    "print(max(result_list),min(result_list),max(result_list)-min(result_list))\n",
    "print(sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.804064Z",
     "start_time": "2021-07-14T02:48:28.391Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.805061Z",
     "start_time": "2021-07-14T02:48:28.392Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def appen_test_G(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data_G.append(temp_list)\n",
    "    testing_label_G.append(S)\n",
    "def read_testing_data_G():\n",
    "    for i in range(100000):\n",
    "        #appen_test_G(sorted(np.random.rand(Agent_number_n), reverse=True));\n",
    "        G_ideas = torch.randn(N_IDEAS).to(dev)  # random ideas\\n\n",
    "        G_values = GeneratorNet(G_ideas)\n",
    "        G_values , indices = torch.sort(G_values, descending=True)\n",
    "        appen_test_G(G_values.detach().cpu().numpy()) \n",
    "\n",
    "testing_data_G = []\n",
    "testing_label_G = []\n",
    "read_testing_data_G()\n",
    "testing_data_G=np.array(testing_data_G)\n",
    "testing_label_G=np.array(testing_label_G)\n",
    "print(testing_data_G)\n",
    "print(testing_label_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.806058Z",
     "start_time": "2021-07-14T02:48:28.394Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "result_list_G = []\n",
    "for index in range(len(testing_data_G)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data_G[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list_G.append(sum(h_list)/testing_label_G[index])\n",
    "    \n",
    "\n",
    "print(max(result_list_G),min(result_list_G),max(result_list_G)-min(result_list_G))\n",
    "print(sum(result_list_G)/len(result_list_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.807056Z",
     "start_time": "2021-07-14T02:48:28.395Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list_G,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list_G)/len(result_list_G), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.808088Z",
     "start_time": "2021-07-14T02:48:28.397Z"
    }
   },
   "outputs": [],
   "source": [
    "final_list = result_list + result_list_G\n",
    "print(max(final_list),min(final_list),max(final_list)-min(final_list))\n",
    "\n",
    "plt.hist(final_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(final_list)/len(final_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "final_list.sort()\n",
    "\n",
    "plt.axvline(x=final_list[int(len(final_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=final_list[int(len(final_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.810048Z",
     "start_time": "2021-07-14T02:48:28.399Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_testing_data():\n",
    "    for i in range(100000):\n",
    "        appen_test(Generate_distribution(Agent_number_n));\n",
    "        \n",
    "testing_data=[]\n",
    "testing_label=[]\n",
    "S=1.0\n",
    "read_testing_data();\n",
    "\n",
    "testing_data=np.array(testing_data)\n",
    "testing_label=np.array(testing_label)\n",
    "print(testing_data)\n",
    "print(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.811044Z",
     "start_time": "2021-07-14T02:48:28.401Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list.append(sum(h_list)/testing_label[index])\n",
    "    \n",
    "\n",
    "print(max(result_list),min(result_list),max(result_list)-min(result_list))\n",
    "print(sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.812042Z",
     "start_time": "2021-07-14T02:48:28.403Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.813039Z",
     "start_time": "2021-07-14T02:48:28.405Z"
    }
   },
   "outputs": [],
   "source": [
    "def appen_test_G(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data_G.append(temp_list)\n",
    "    testing_label_G.append(S)\n",
    "def read_testing_data_G():\n",
    "    for i in range(100000):\n",
    "        #appen_test_G(sorted(np.random.rand(Agent_number_n), reverse=True));\n",
    "        G_ideas = torch.randn(N_IDEAS).to(dev)  # random ideas\\n\n",
    "        G_values = GeneratorNet(G_ideas)\n",
    "        G_values , indices = torch.sort(G_values, descending=True)\n",
    "        appen_test_G(G_values.detach().cpu().numpy()) \n",
    "\n",
    "testing_data_G = []\n",
    "testing_label_G = []\n",
    "read_testing_data_G()\n",
    "testing_data_G=np.array(testing_data_G)\n",
    "testing_label_G=np.array(testing_label_G)\n",
    "print(testing_data_G)\n",
    "print(testing_label_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.815034Z",
     "start_time": "2021-07-14T02:48:28.406Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "result_list_G = []\n",
    "for index in range(len(testing_data_G)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data_G[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list_G.append(sum(h_list)/testing_label_G[index])\n",
    "    \n",
    "\n",
    "print(max(result_list_G),min(result_list_G),max(result_list_G)-min(result_list_G))\n",
    "print(sum(result_list_G)/len(result_list_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.816031Z",
     "start_time": "2021-07-14T02:48:28.407Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list_G,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list_G)/len(result_list_G), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "# result_list_G.sort()\n",
    "\n",
    "# plt.axvline(x=result_list[int(len(result_list_G)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "# plt.axvline(x=result_list[int(len(result_list_G)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.817030Z",
     "start_time": "2021-07-14T02:48:28.409Z"
    }
   },
   "outputs": [],
   "source": [
    "final_list = result_list + result_list_G\n",
    "\n",
    "\n",
    "plt.hist(final_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(final_list)/len(final_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "# final_list.sort()\n",
    "\n",
    "# plt.axvline(x=final_list[int(len(final_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "# plt.axvline(x=final_list[int(len(final_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.818026Z",
     "start_time": "2021-07-14T02:48:28.410Z"
    }
   },
   "outputs": [],
   "source": [
    "final_list = result_list[:5000] + result_list_G[:5000]\n",
    "\n",
    "\n",
    "plt.hist(final_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(final_list)/len(final_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(max(final_list),min(final_list),max(final_list)-min(final_list))\n",
    "print(sum(final_list)/len(final_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.819023Z",
     "start_time": "2021-07-14T02:48:28.412Z"
    }
   },
   "outputs": [],
   "source": [
    "final_list = result_list[:10000] + result_list_G[:10000]\n",
    "\n",
    "\n",
    "plt.hist(final_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(final_list)/len(final_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(max(final_list),min(final_list),max(final_list)-min(final_list))\n",
    "print(sum(final_list)/len(final_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T02:48:54.820020Z",
     "start_time": "2021-07-14T02:48:28.414Z"
    }
   },
   "outputs": [],
   "source": [
    "final_list = result_list[:50000] + result_list_G[:50000]\n",
    "\n",
    "\n",
    "plt.hist(final_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(final_list)/len(final_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(max(final_list),min(final_list),max(final_list)-min(final_list))\n",
    "print(sum(final_list)/len(final_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
