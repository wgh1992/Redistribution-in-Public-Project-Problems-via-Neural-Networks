{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T05:09:30.969949Z",
     "start_time": "2021-06-27T05:09:29.242530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pygame\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm \n",
    "import matplotlib.cm as cm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy.interpolate import griddata\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "print(dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T05:09:30.985927Z",
     "start_time": "2021-06-27T05:09:30.970948Z"
    }
   },
   "outputs": [],
   "source": [
    "global temp_list\n",
    "temp_list = []\n",
    "Agent_number_n=11;\n",
    "Alpha = 0.7\n",
    "\n",
    "# Hyper Parameters\n",
    "echo = 1001 \n",
    "BATCH_SIZE = 64\n",
    "LR_G = 0.01           # learning rate for generator\n",
    "LR_D = 0.01           # learning rate for discriminator\n",
    "N_IDEAS = Agent_number_n             # think of this as number of ideas for generating an art work (Generator)\n",
    "ART_COMPONENTS = Agent_number_n     # it could be total point G can draw in the canvas\n",
    "\n",
    "Is_GAN = True # if use Gan\n",
    "\n",
    "def Generate_distribution(Agent_number_n):\n",
    "    return sorted(np.random.rand(Agent_number_n), reverse=True)\n",
    "    #return sorted(np.random.normal(normalloc,normalscale,Agent_number_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T05:09:31.001866Z",
     "start_time": "2021-06-27T05:09:30.987902Z"
    }
   },
   "outputs": [],
   "source": [
    "new_input = 3\n",
    "def Dimensionality_reduction(data_sorted):\n",
    "    out_data = torch.ones(new_input).cuda()\n",
    "    out_data[0] = torch.max(data_sorted) \n",
    "    out_data[1] = torch.sum(data_sorted) \n",
    "    \n",
    "    temp_list = []\n",
    "    for i in range(len(data_sorted)-1):\n",
    "        temp_list.append(data_sorted[i] - data_sorted[i + 1])\n",
    "    \n",
    "    temp_tensor = torch.stack(temp_list)    \n",
    "    out_data[2] = torch.max(temp_tensor) \n",
    "    return out_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T05:09:31.095613Z",
     "start_time": "2021-06-27T05:09:31.002863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[6.31318948e-01 5.19645182e-01 4.93935505e-01 ... 1.57741980e-01\n",
      "   8.04144379e-03 3.58796286e-04]\n",
      "  [9.80366445e-01 5.19645182e-01 4.93935505e-01 ... 1.57741980e-01\n",
      "   8.04144379e-03 3.58796286e-04]\n",
      "  [9.80366445e-01 6.31318948e-01 4.93935505e-01 ... 1.57741980e-01\n",
      "   8.04144379e-03 3.58796286e-04]\n",
      "  ...\n",
      "  [9.80366445e-01 6.31318948e-01 5.19645182e-01 ... 3.15562083e-01\n",
      "   8.04144379e-03 3.58796286e-04]\n",
      "  [9.80366445e-01 6.31318948e-01 5.19645182e-01 ... 3.15562083e-01\n",
      "   1.57741980e-01 3.58796286e-04]\n",
      "  [9.80366445e-01 6.31318948e-01 5.19645182e-01 ... 3.15562083e-01\n",
      "   1.57741980e-01 8.04144379e-03]]\n",
      "\n",
      " [[9.31648740e-01 6.51906683e-01 6.45608567e-01 ... 2.51880361e-01\n",
      "   1.90907009e-01 1.14952873e-01]\n",
      "  [9.92919536e-01 6.51906683e-01 6.45608567e-01 ... 2.51880361e-01\n",
      "   1.90907009e-01 1.14952873e-01]\n",
      "  [9.92919536e-01 9.31648740e-01 6.45608567e-01 ... 2.51880361e-01\n",
      "   1.90907009e-01 1.14952873e-01]\n",
      "  ...\n",
      "  [9.92919536e-01 9.31648740e-01 6.51906683e-01 ... 3.68085109e-01\n",
      "   1.90907009e-01 1.14952873e-01]\n",
      "  [9.92919536e-01 9.31648740e-01 6.51906683e-01 ... 3.68085109e-01\n",
      "   2.51880361e-01 1.14952873e-01]\n",
      "  [9.92919536e-01 9.31648740e-01 6.51906683e-01 ... 3.68085109e-01\n",
      "   2.51880361e-01 1.90907009e-01]]\n",
      "\n",
      " [[8.28710114e-01 7.51931944e-01 6.35608421e-01 ... 3.20300660e-01\n",
      "   2.55200070e-01 8.26088082e-02]\n",
      "  [8.32681398e-01 7.51931944e-01 6.35608421e-01 ... 3.20300660e-01\n",
      "   2.55200070e-01 8.26088082e-02]\n",
      "  [8.32681398e-01 8.28710114e-01 6.35608421e-01 ... 3.20300660e-01\n",
      "   2.55200070e-01 8.26088082e-02]\n",
      "  ...\n",
      "  [8.32681398e-01 8.28710114e-01 7.51931944e-01 ... 3.32026837e-01\n",
      "   2.55200070e-01 8.26088082e-02]\n",
      "  [8.32681398e-01 8.28710114e-01 7.51931944e-01 ... 3.32026837e-01\n",
      "   3.20300660e-01 8.26088082e-02]\n",
      "  [8.32681398e-01 8.28710114e-01 7.51931944e-01 ... 3.32026837e-01\n",
      "   3.20300660e-01 2.55200070e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[6.61612491e-01 6.48658459e-01 5.74249530e-01 ... 2.86360705e-01\n",
      "   1.75966856e-01 9.67576516e-02]\n",
      "  [7.30219950e-01 6.48658459e-01 5.74249530e-01 ... 2.86360705e-01\n",
      "   1.75966856e-01 9.67576516e-02]\n",
      "  [7.30219950e-01 6.61612491e-01 5.74249530e-01 ... 2.86360705e-01\n",
      "   1.75966856e-01 9.67576516e-02]\n",
      "  ...\n",
      "  [7.30219950e-01 6.61612491e-01 6.48658459e-01 ... 3.35190005e-01\n",
      "   1.75966856e-01 9.67576516e-02]\n",
      "  [7.30219950e-01 6.61612491e-01 6.48658459e-01 ... 3.35190005e-01\n",
      "   2.86360705e-01 9.67576516e-02]\n",
      "  [7.30219950e-01 6.61612491e-01 6.48658459e-01 ... 3.35190005e-01\n",
      "   2.86360705e-01 1.75966856e-01]]\n",
      "\n",
      " [[7.91992280e-01 7.71385282e-01 7.18932517e-01 ... 1.02475874e-01\n",
      "   9.12054420e-02 7.20587955e-02]\n",
      "  [8.14822841e-01 7.71385282e-01 7.18932517e-01 ... 1.02475874e-01\n",
      "   9.12054420e-02 7.20587955e-02]\n",
      "  [8.14822841e-01 7.91992280e-01 7.18932517e-01 ... 1.02475874e-01\n",
      "   9.12054420e-02 7.20587955e-02]\n",
      "  ...\n",
      "  [8.14822841e-01 7.91992280e-01 7.71385282e-01 ... 2.03131251e-01\n",
      "   9.12054420e-02 7.20587955e-02]\n",
      "  [8.14822841e-01 7.91992280e-01 7.71385282e-01 ... 2.03131251e-01\n",
      "   1.02475874e-01 7.20587955e-02]\n",
      "  [8.14822841e-01 7.91992280e-01 7.71385282e-01 ... 2.03131251e-01\n",
      "   1.02475874e-01 9.12054420e-02]]\n",
      "\n",
      " [[8.77333602e-01 7.75058088e-01 7.25804295e-01 ... 1.98842938e-01\n",
      "   1.39719090e-01 1.12495721e-02]\n",
      "  [9.18507046e-01 7.75058088e-01 7.25804295e-01 ... 1.98842938e-01\n",
      "   1.39719090e-01 1.12495721e-02]\n",
      "  [9.18507046e-01 8.77333602e-01 7.25804295e-01 ... 1.98842938e-01\n",
      "   1.39719090e-01 1.12495721e-02]\n",
      "  ...\n",
      "  [9.18507046e-01 8.77333602e-01 7.75058088e-01 ... 4.14221506e-01\n",
      "   1.39719090e-01 1.12495721e-02]\n",
      "  [9.18507046e-01 8.77333602e-01 7.75058088e-01 ... 4.14221506e-01\n",
      "   1.98842938e-01 1.12495721e-02]\n",
      "  [9.18507046e-01 8.77333602e-01 7.75058088e-01 ... 4.14221506e-01\n",
      "   1.98842938e-01 1.39719090e-01]]]\n",
      "[4.17658116 5.82776448 5.67537967 5.51341964 4.69620908 5.69897925\n",
      " 5.48544051 6.51265291 7.02178413 5.61032599 4.65668483 4.93431231\n",
      " 6.30046289 7.66730105 7.27111081 5.18654004 5.61616499 4.55482543\n",
      " 5.46028846 5.7296817  4.77891863 4.49064907 5.20871231 7.04942316\n",
      " 5.4666355  5.2159881  6.31092619 4.33523399 5.28845305 5.06598607\n",
      " 4.35697842 7.55995137 5.20125534 6.79535602 5.78332503 5.39750334\n",
      " 5.97017566 5.49894796 5.60187758 7.32160512 4.92927592 5.33230017\n",
      " 4.73583597 4.64311662 4.38865502 5.71694398 6.50898789 5.69219396\n",
      " 6.63454106 5.82117302 7.42502074 5.7055943  5.30812473 6.90485825\n",
      " 6.44531224 5.11381582 5.34151601 6.07036534 5.59909177 6.00342465\n",
      " 5.29114242 6.36295739 5.83319238 6.69219482 4.8122227  3.58720525\n",
      " 3.7682209  6.03584161 4.56373687 5.25817128 3.43673479 5.5347413\n",
      " 6.32176196 4.57404638 2.6950702  4.53347282 5.16276927 6.07511168\n",
      " 4.36248371 7.25868298 3.39368884 6.23063722 4.56707077 7.54369264\n",
      " 5.95938453 6.51833282 5.31263585 6.35538978 4.54818646 5.12353071\n",
      " 5.66836993 6.43704985 5.04962179 6.35238413 5.64030494 4.78732695\n",
      " 6.63288746 5.68165251 5.38856701 4.6777648  7.01571941 6.15013863\n",
      " 5.22871246 6.3262078  5.63059819 6.75248804 6.26384299 5.80643853\n",
      " 4.78744812 8.29596971 4.12290985 4.41744127 6.30249247 4.18653707\n",
      " 3.94119873 6.87770406 5.54098908 5.90033819 5.98107885 5.71871449\n",
      " 4.99404062 5.06053271 5.44369853 5.88074177 5.61837452 5.01117868\n",
      " 4.57313    5.41177239 4.87136945 6.16212361 5.41347851 4.42095944\n",
      " 5.63664659 6.90440902 5.55944789 5.52336221 5.98822513 4.95335424\n",
      " 5.84475894 5.91160746 4.53413145 4.51459476 5.48050212 5.84007744\n",
      " 5.55424909 5.64187779 6.70165224 5.80177175 5.56201367 4.57624317\n",
      " 5.7362554  5.67538128 3.44570363 5.43307687 5.933694   5.0036749\n",
      " 5.02261017 6.24950162 3.29673278 5.61315796 5.05886117 5.73049497\n",
      " 5.35529298 5.78186119 5.14629596 5.62428918 7.57401977 5.85640686\n",
      " 4.64817999 6.51476645 4.54195223 4.93786036 5.02159645 5.43564412\n",
      " 5.68159287 6.4116369  4.73110275 5.89743718 6.45092165 4.37546083\n",
      " 4.89944191 4.56840418 6.38936154 4.49471119 6.12972362 5.27961096\n",
      " 3.146487   4.81726603 6.41007672 5.58173611 3.60580014 5.94438527\n",
      " 5.21507142 5.70113029 3.86894326 4.16149246 5.01991208 5.84105633\n",
      " 4.91047202 5.60563784 5.23903846 6.05903522 6.56208702 6.00392362\n",
      " 4.78424752 6.5692317  4.78578774 6.27627139 8.00897432 6.26093707\n",
      " 4.99332099 5.48222085 5.9070279  6.00605976 7.2454577  7.19724188\n",
      " 6.85884646 4.33787999 6.16627586 7.1887156  3.85431466 7.65883674\n",
      " 4.8531101  6.09160039 4.04943791 4.16310009 5.52604345 5.69113458\n",
      " 6.2586427  4.43879865 4.42892196 7.6168886  5.3194188  7.07308173\n",
      " 5.42634212 6.81207446 4.94366301 6.09065266 3.06766906 6.4369669\n",
      " 6.17067062 4.70231132 4.74045979 5.75389361 6.50515616 5.81840591\n",
      " 6.8546231  5.23895974 5.65189459 4.62900484 7.62041464 6.60738974\n",
      " 4.86367861 6.62545213 4.82659484 5.23958967 6.03185991 3.56696603\n",
      " 5.51689685 5.56310802 4.66504775 4.65808248 6.37778376 5.90554911\n",
      " 5.50242106 4.14387357 4.77611773 4.8846541  5.50922422 4.67879936\n",
      " 6.55510744 5.20363167 6.04405249 7.09999801 5.60704599 6.49597834\n",
      " 6.15840876 3.88936561 4.40922822 5.33235743 6.05365547 6.48994793\n",
      " 4.71213216 5.70515286 5.03790634 5.61720902 6.13389156 5.18292832\n",
      " 5.84783886 5.43965653 5.58205656 7.23837651 5.50213915 5.90685581\n",
      " 6.55197275 6.38157734 6.06669892 5.23485334 5.20607467 5.37192643\n",
      " 7.02130614 5.33353913 5.48492534 6.4353822  5.65040135 5.55970978\n",
      " 6.32554545 5.14391361 6.07597197 6.75984948 6.7706606  5.30539497\n",
      " 5.77749946 5.65958772 5.29822736 5.32724796 6.28430264 5.29355503\n",
      " 3.50188644 4.9989377  3.60326526 6.16652223 5.90195202 4.73752499\n",
      " 5.38673744 4.96951534 7.4172299  5.25422817 6.3765757  4.06163272\n",
      " 6.88424669 7.3988392  5.81229716 4.72266719 4.97233781 5.07714387\n",
      " 5.71917717 4.93962771 7.31228212 8.46642028 4.62723698 6.12908126\n",
      " 5.53203386 4.32867336 3.52506159 7.50056325 5.38725682 6.36164406\n",
      " 3.84902904 6.12180395 5.99985738 7.94660234 6.50108702 5.92899852\n",
      " 5.54980905 7.0833175  6.24263028 5.18351557 5.74362961 6.66236449\n",
      " 5.26068794 5.15322998 4.66196574 5.58713202 4.95231868 6.66705206\n",
      " 5.46676799 5.07897435 4.28670237 5.36614173 4.40097474 6.78616485\n",
      " 3.48507036 4.8834755  6.7395909  5.51960633 4.855369   7.12102252\n",
      " 4.99205602 5.2035873  6.95185822 4.36365688 4.49768673 6.97094795\n",
      " 7.32494945 5.17044795 5.5812132  5.78627084 5.92639223 4.99244353\n",
      " 4.57192563 4.75950232 4.80239699 7.17504362 6.4634318  5.40232074\n",
      " 5.65413095 6.68766661 6.83082923 6.22338919 5.77457369 4.65105759\n",
      " 6.9215649  5.60324548 7.16992698 6.4238809  5.5716419  5.80589868\n",
      " 6.37967579 5.48983359 4.11542189 4.28383991 3.48224538 5.44804621\n",
      " 5.09172633 6.56399821 5.05536942 4.65470024 5.80187106 4.67257932\n",
      " 5.72943941 5.78351379 4.15358002 5.95598419 4.96560851 5.22280966\n",
      " 3.93195895 7.632212   4.69517625 4.80533301 4.37143608 5.7896311\n",
      " 6.24538579 4.65123362 5.35982238 6.36558991 4.76135382 5.32378959\n",
      " 5.99861833 5.66615203 4.64140966 6.53739776 5.05238239 6.28307522\n",
      " 6.20658205 3.60620769 5.77636217 4.80120778 5.11946405 6.23611373\n",
      " 4.33499952 5.96438135 5.09434515 5.39613148 5.145241   5.88665897\n",
      " 6.72199405 5.93675084 5.50212676 3.81274813 4.98681051 5.09684068\n",
      " 4.41752011 4.53171109 6.31156925 5.14565771 4.56747285 5.42205617\n",
      " 5.90042698 5.33692937 5.62711139 6.53217894 6.55963423 5.70828297\n",
      " 5.65770529 6.74737648 5.99512935 6.55886621 4.22447943 4.65185152\n",
      " 5.08953107 5.05244823 4.86945848 4.9299922  6.07293916 7.28828533\n",
      " 6.11121681 6.08471593 4.87365525 3.99848376 5.04407529 5.06256018\n",
      " 5.27278611 5.66987437 6.02631241 5.46596526 5.99652301 4.71008658\n",
      " 5.46068332 3.12938871 5.9795972  4.84441248 6.15553307 5.69478122\n",
      " 5.95988596 6.86155034 6.41088606 3.52901673 6.20227781 5.35037949\n",
      " 4.70314175 5.38740102 6.01884625 4.50697229 6.90904257 5.68078108\n",
      " 5.95634416 6.5821782  5.51819562 5.53715097 5.98907337 6.53507695\n",
      " 3.66219207 6.14810966 5.41148002 4.905223   6.08292978 5.10468505\n",
      " 4.53351201 5.84314381 6.63415318 4.01720565 4.47651176 6.09099346\n",
      " 4.55823664 4.36855116 4.80341616 5.62744644 5.93803461 5.96249862\n",
      " 5.60507122 5.58255925 4.19851538 5.74965391 6.69122801 4.00580177\n",
      " 5.08903128 6.10526021 6.70156681 5.85428995 6.8087304  4.68085472\n",
      " 7.91867848 5.01630078 4.47213943 6.21599555 6.80322043 5.48988736\n",
      " 5.15131198 4.68931273 5.05745447 4.24205064 5.16497437 4.99354586\n",
      " 4.58527143 7.19852073 5.74999633 4.51290302 6.2044429  4.22383669\n",
      " 4.82536089 5.34002945 6.1757433  5.89007472 5.83581079 5.78622678\n",
      " 6.66965343 4.83693495 5.01187856 6.144267   6.82816806 5.23922454\n",
      " 3.11022424 6.43243667 5.24933273 6.0338293  4.28620778 5.74087814\n",
      " 4.50716998 4.06381016 6.06563086 4.42343829 4.95395391 6.10585589\n",
      " 6.35796394 5.54704279 4.30058612 6.69029413 4.02956643 4.89140596\n",
      " 4.61407863 6.09277374 4.20778236 5.43533296 6.03493664 4.97270445\n",
      " 6.37555704 6.03498158 5.56892112 5.27884689 5.86124468 4.98615024\n",
      " 5.17417307 6.73651172 5.58615831 4.4167013  5.57626713 5.43077574\n",
      " 5.59164789 6.40567769 6.35156116 6.38914779 5.13892022 5.16256894\n",
      " 7.70912585 6.50061823 5.18638041 5.18347901 4.12736047 6.78740531\n",
      " 3.97579509 4.03523437 5.18988562 7.20065473 5.42045139 4.13574209\n",
      " 5.70289923 3.96118384 6.2019279  4.81985034 5.00306478 4.60928863\n",
      " 4.78740525 5.46422627 5.45766847 6.23606225 6.67094384 4.85168899\n",
      " 5.33678241 4.55027501 5.12432217 5.32159576 4.12765828 4.86713296\n",
      " 5.68126697 4.12449255 4.8220556  4.5131938  5.00163262 6.86258654\n",
      " 5.70284826 5.12172079 6.24723037 4.59607463 6.78410286 4.3866813\n",
      " 6.37080152 6.31681382 5.78649216 5.64061507 5.50990168 5.51403771\n",
      " 4.08735945 5.22011747 4.97999123 4.70972993 4.45275735 5.75014897\n",
      " 4.90083264 5.73308812 6.73266872 4.46064028 4.56591945 4.88633829\n",
      " 6.78904595 8.04151795 5.38298461 6.63898731 6.79294936 4.11657648\n",
      " 6.04892958 4.80946774 5.37863562 4.04292664 4.52357733 3.54015064\n",
      " 4.85211295 4.6349088  4.52968525 5.62142295 6.67305643 5.06967178\n",
      " 4.57519282 5.033499   5.79665012 3.86854732 5.27170729 6.58670443\n",
      " 6.60838158 6.47380423 3.50368888 6.31333472 5.05800129 4.71860563\n",
      " 6.45308174 5.57179335 5.06876022 5.96229134 6.69924943 5.03293079\n",
      " 5.29143394 6.87748945 5.14446497 5.58550983 5.42784199 5.39928315\n",
      " 5.61322573 4.41885967 6.23242745 5.06364678 5.06078841 6.07163491\n",
      " 5.38879188 6.03271001 5.27748395 4.81201332 6.67278788 7.16936505\n",
      " 5.11277602 6.28984694 5.75980328 3.74988511 4.86547546 6.02624122\n",
      " 5.30151224 7.42049931 5.58502333 6.22934449 6.78012872 6.02626912\n",
      " 5.69807102 6.00694884 4.85380965 5.91247805 4.80922518 6.18600921\n",
      " 5.5930855  4.57044755 4.31215339 5.38224242 3.61216639 7.4328722\n",
      " 4.76149722 5.96705851 4.50717297 5.19215226 3.31275676 5.6731327\n",
      " 6.8724519  5.41656266 5.03207336 5.32923656 4.07782613 5.74417655\n",
      " 6.06983693 5.928641   6.22146273 5.11759364 6.08914702 5.91440118\n",
      " 5.2560087  4.42170744 6.71581338 5.41666247 6.77072831 5.9593255\n",
      " 4.86892237 4.86905817 5.06523538 5.61895181 4.23598404 5.40430345\n",
      " 5.6494946  4.48107662 4.99832864 6.73755124 6.40766722 4.49436929\n",
      " 6.42985227 8.18427133 5.50541568 5.01426424 5.8661038  5.78823734\n",
      " 5.22340818 5.43410066 5.49677839 5.7296927  5.01601057 3.13481927\n",
      " 7.63597832 4.13268927 4.67923955 5.34149718 7.2523251  5.72319318\n",
      " 5.9476638  6.26375557 5.24361534 6.64865782 6.06758445 4.73344893\n",
      " 5.08510311 5.93528836 4.25929748 7.29597694 6.47466742 6.01483765\n",
      " 2.59805724 6.44501037 4.20219161 2.99705828 4.24345613 7.20157937\n",
      " 5.21997813 5.23792179 5.63820455 4.52040013 5.8891977  5.18918487\n",
      " 6.72547631 5.83788121 3.89517787 5.66135475 5.30239334 6.00418939\n",
      " 7.10387144 5.46691809 4.80020823 4.55959029 5.94808622 6.69311032\n",
      " 5.75435623 5.51280265 4.80980995 5.61379923 5.3387736  5.16792097\n",
      " 4.96038646 5.42477257 5.48437394 5.61584528 4.4404521  5.68210226\n",
      " 3.91053215 4.96214835 6.41592314 4.85327084 5.21807879 5.27815216\n",
      " 6.48254656 6.20833878 5.80110125 4.8114836  4.96376174 6.26020414\n",
      " 6.24628283 6.97897378 6.04929173 6.06284769 6.50428339 4.58564228\n",
      " 5.43138704 5.02778591 5.95916726 4.94503692 3.99715564 6.66580511\n",
      " 4.73635456 6.26923814 5.8350836  6.41039803 5.26556237 4.42567452\n",
      " 6.1302912  5.89825532 3.90222377 6.49617948 4.16257156 5.72634724\n",
      " 4.48801038 4.81568163 5.01903543 5.20081554 5.47666061 6.33856853\n",
      " 4.31559615 4.2441697  5.06380593 5.39304827 4.04420361 5.99044389\n",
      " 5.939502   7.41923839 5.04609786 6.00224364 5.14557565 4.17853516\n",
      " 5.3170068  5.4858354  4.727771   7.22693498 4.83621398 5.88710675\n",
      " 4.57603502 5.63111723 6.01269714 6.63893712 5.03567683 4.47678363\n",
      " 6.24105173 6.45417149 5.00483013 5.56639117 5.44776804 4.38425254\n",
      " 4.86740347 4.96126775 6.86176738 6.96552667 4.84372606 5.89510505\n",
      " 4.44399373 5.79696353 7.29007458 5.94232455 6.30835486 5.70790137\n",
      " 4.86370711 5.95494286 5.28545963 5.84382817 4.79290076 6.6488939\n",
      " 4.9970082  5.05311662 6.42580508 5.60059298 5.15999098 5.24098804\n",
      " 5.89026361 5.41688944 5.46152838 4.20982722 6.41053772 5.09719783\n",
      " 6.9688004  6.73757546 6.61271849 7.85651122 7.41205435 5.21121681\n",
      " 5.61542798 4.42503819 5.61560985 7.45490183 5.41579618 5.31394936\n",
      " 7.12785873 5.67337065 6.00270782 6.29425618 5.21180682 3.74697182\n",
      " 6.40659874 4.80441341 5.36844506 3.76705473 5.05821309 5.22417497\n",
      " 4.0925199  5.27661924 5.81442892 4.81603847 5.60117424 6.1973049\n",
      " 4.59838743 4.77481013 5.00448526 5.64646157]\n"
     ]
    }
   ],
   "source": [
    "def h_3_star(a, b, t):\n",
    "    return a - min(a, t) + b - min(b, t) + max(min(a, t)+min(b, t), 2*t/3) + 1/2 * max(min(a, t)+min(b, t), t) - 1/2 * max(max(min(a, t), min(b, t)), 2*t/3) - t/6\n",
    "\n",
    "\n",
    "def f_function(a, b, z):\n",
    "    if(z >= 1):\n",
    "        return (a+b)/2 + z/3\n",
    "    else:\n",
    "        return z/3 + h_3_star(a, b, 1-z)/2\n",
    "\n",
    "def h_function_label(input_list):\n",
    "    #input_list = sorted(input_list)\n",
    "    g_list = []\n",
    "    for j1 in range(len(input_list) ):\n",
    "        for j2 in range(len(input_list)):\n",
    "            if(j1 != j2):\n",
    "                a = input_list[j1]\n",
    "                b = input_list[j2]\n",
    "                z = sum(input_list)- a-b\n",
    "\n",
    "                g_list.append( f_function(a, b, z) * (Agent_number_n-1))\n",
    "    h = sum(g_list) * 3 /  (Agent_number_n) /  (Agent_number_n-1) /  (Agent_number_n - 2)\n",
    "    return h\n",
    "\n",
    "def appen(_x_list,y):\n",
    "    global temp_list\n",
    "    temp_list.append(_x_list)\n",
    "    \n",
    "def appen_train(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "        \n",
    "        h = h_function_label(temp)\n",
    "        h_list.append(float(h))\n",
    "    temp_list = np.array(temp_list)\n",
    "    x_list = np.array(x_list)\n",
    "    return temp_list,S,x_list,h_list\n",
    "    \n",
    "\n",
    "def appen_test(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data.append(temp_list)\n",
    "    testing_label.append(S)\n",
    "    temp_list = np.array(temp_list)\n",
    "    return temp_list,S\n",
    "    \n",
    "\n",
    "def read_testing_data():\n",
    "    for i in range(1000):\n",
    "        appen_test(Generate_distribution(Agent_number_n));\n",
    "                        \n",
    "            \n",
    "\n",
    "testing_data=[]\n",
    "testing_label=[]\n",
    "S=1.0\n",
    "read_testing_data();\n",
    "\n",
    "testing_data=np.array(testing_data)\n",
    "testing_label=np.array(testing_label)\n",
    "print(testing_data)\n",
    "print(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T05:09:31.111572Z",
     "start_time": "2021-06-27T05:09:31.096611Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.normal_(m.bias, mean=0.0, std=0.01)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.input_dim = new_input# (Agent_number_n-1)\n",
    "        self.hidden_dim = 128\n",
    "        self.output_dim = 1\n",
    "        self.hidden_layer_count = 6 \n",
    "        \n",
    "        current_dim = self.input_dim\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(self.hidden_layer_count):\n",
    "            self.layers.append(torch.nn.Linear(current_dim, self.hidden_dim))\n",
    "            current_dim = self.hidden_dim\n",
    "        self.layers.append(torch.nn.Linear(current_dim, self.output_dim))\n",
    "\n",
    "    def calculate(self, value_list):\n",
    "        h = Dimensionality_reduction(value_list)\n",
    "        for layer in self.layers:\n",
    "            h = torch.relu(layer(h))\n",
    "        return h\n",
    "\n",
    "    def forward(self, input_list,input_label,list_x):\n",
    "        global iteration,echo,target_order\n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        loss3 = 0\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).to(dev).type(torch.float32)\n",
    "        h_list = []\n",
    "\n",
    "        for i in range(Agent_number_n):\n",
    "            h = self.calculate(input_list[i])\n",
    "            h_list.append(h)\n",
    "#             loss3 += torch.square(h_function_2(input_list)-h2[1])\n",
    "            \n",
    "        input_label = torch.from_numpy(\n",
    "            np.array(input_label)).to(dev).type(torch.float32)\n",
    "        sum_h = torch.sum(torch.cat(h_list)).to(dev)\n",
    "\n",
    "\n",
    "        loss1 = torch.where((Agent_number_n-1)*input_label>sum_h,\n",
    "                        torch.square(((Agent_number_n-1)*input_label-sum_h)),\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "        loss2 = torch.where((Agent_number_n-Alpha)*input_label<sum_h,\n",
    "                        torch.square((sum_h-(Agent_number_n-Alpha)*input_label))/100,\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "\n",
    "        return loss1,loss2\n",
    "    \n",
    "    def supervised_loss(self, input_list,label):\n",
    "        global iteration,echo,target_order\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).to(dev).type(torch.float32)\n",
    "        loss = 0 \n",
    "        for i in range(Agent_number_n):\n",
    "            h = self.calculate(input_list[i])\n",
    "            loss += torch.square(h - label[i])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T05:09:31.127529Z",
     "start_time": "2021-06-27T05:09:31.112570Z"
    }
   },
   "outputs": [],
   "source": [
    "def redistribution_value_function(input_tensor):\n",
    "    S = torch.max(torch.sum(input_tensor), torch.ones(1).to(dev))\n",
    "    temp_list = []\n",
    "\n",
    "\n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        \n",
    "        for j in range(Agent_number_n):\n",
    "            if(i != j):\n",
    "                temp .append(input_tensor[j])\n",
    "                \n",
    "        temp = torch.stack(temp)\n",
    "        temp_list.append(temp)\n",
    "    return torch.stack(temp_list), S\n",
    "\n",
    "GeneratorNet = nn.Sequential(                      # Generator\n",
    "    # random ideas (could from normal distribution)\n",
    "    nn.Linear(N_IDEAS, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    # making a painting from these random ideas\n",
    "    nn.Linear(64, ART_COMPONENTS),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T05:09:32.293425Z",
     "start_time": "2021-06-27T05:09:31.130521Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "DiscriminatorNet  = Net()\n",
    "DiscriminatorNet.apply(weight_init)\n",
    "GeneratorNet.apply(weight_init)\n",
    "# DiscriminatorNet = torch.load(\"save/Deep_learning_D_11_supervised_1\")\n",
    "# if(Is_GAN):\n",
    "#     GeneratorNet = torch.load(\"save/Deep_learning_G_11\")\n",
    "DiscriminatorNet.to(dev)\n",
    "GeneratorNet.to(dev)\n",
    "\n",
    "opt_D = torch.optim.Adam(DiscriminatorNet.parameters(), lr=LR_D)\n",
    "opt_G = torch.optim.Adam(GeneratorNet.parameters(), lr=LR_G)\n",
    "\n",
    "\n",
    "scheduler_D = torch.optim.lr_scheduler.StepLR(opt_D, step_size=100, gamma=0.98)\n",
    "scheduler_G = torch.optim.lr_scheduler.StepLR(opt_G, step_size=100, gamma=0.98)\n",
    "\n",
    "index_train_list = []\n",
    "index_test_list = []\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T05:30:17.403430Z",
     "start_time": "2021-06-27T05:09:32.295419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(283.9498, device='cuda:0', grad_fn=<DivBackward0>) 18172.787109375\n",
      "100 tensor(287.5962, device='cuda:0', grad_fn=<DivBackward0>) 18406.158203125\n",
      "200 tensor(283.5165, device='cuda:0', grad_fn=<DivBackward0>) 18145.05859375\n",
      "300 tensor(280.5276, device='cuda:0', grad_fn=<DivBackward0>) 17953.765625\n",
      "400 tensor(283.7141, device='cuda:0', grad_fn=<DivBackward0>) 18157.69921875\n",
      "500 tensor(272.8195, device='cuda:0', grad_fn=<DivBackward0>) 17460.4453125\n",
      "600 tensor(302.1386, device='cuda:0', grad_fn=<DivBackward0>) 19336.87109375\n",
      "700 tensor(291.9385, device='cuda:0', grad_fn=<DivBackward0>) 18684.064453125\n",
      "800 tensor(258.5535, device='cuda:0', grad_fn=<DivBackward0>) 16547.423828125\n",
      "900 tensor(277.6626, device='cuda:0', grad_fn=<DivBackward0>) 17770.408203125\n",
      "1000 tensor(299.0664, device='cuda:0', grad_fn=<DivBackward0>) 19140.25\n"
     ]
    }
   ],
   "source": [
    "#supervised\n",
    "index_supervisedtrain_list = []\n",
    "supervisedtrain_losses = []\n",
    "for iteration in range(echo):\n",
    "\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "    \n",
    "    loss_sum = 0\n",
    "    denominator = 0\n",
    "    for index in range(0, BATCH_SIZE):\n",
    "        training_data_i, training_S, training_data,label = appen_train(\n",
    "            Generate_distribution(Agent_number_n))\n",
    "        h_loss = DiscriminatorNet.supervised_loss(training_data_i, label)\n",
    "        denominator += 1\n",
    "        loss_sum += h_loss\n",
    "\n",
    "    loss_sum = torch.sum(loss_sum)\n",
    "    loss = (loss_sum) / denominator \n",
    "    total_batch_loss += float(loss_sum)\n",
    "\n",
    "    opt_D.zero_grad()\n",
    "    loss.backward()\n",
    "    opt_D.step()\n",
    "\n",
    "    if (iteration%100 == 0):\n",
    "        print(iteration,loss,total_batch_loss)\n",
    "        index_supervisedtrain_list.append(iteration)\n",
    "        supervisedtrain_losses.append(total_batch_loss)\n",
    "    scheduler_D.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T05:30:17.530708Z",
     "start_time": "2021-06-27T05:30:17.405363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylim(0, 0.1)\n",
    "plt.plot(index_supervisedtrain_list ,supervisedtrain_losses)\n",
    "plt.ylabel('supervised train loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T05:30:17.546665Z",
     "start_time": "2021-06-27T05:30:17.531668Z"
    }
   },
   "outputs": [],
   "source": [
    "if(echo!=0):\n",
    "    torch.save(DiscriminatorNet, \"save/Deep_learning_D_11_supervised\")\n",
    "    if(Is_GAN):\n",
    "        torch.save(GeneratorNet, \"save/Deep_learning_G_11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T05:30:17.562655Z",
     "start_time": "2021-06-27T05:30:17.547626Z"
    }
   },
   "outputs": [],
   "source": [
    "opt_D = torch.optim.Adam(DiscriminatorNet.parameters(), lr=LR_D/10)\n",
    "opt_G = torch.optim.Adam(GeneratorNet.parameters(), lr=LR_G/100)\n",
    "scheduler_D = torch.optim.lr_scheduler.StepLR(opt_D, step_size=100, gamma=0.98)\n",
    "scheduler_G = torch.optim.lr_scheduler.StepLR(opt_G, step_size=100, gamma=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-27T05:09:29.229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Gan: tensor(-0., device='cuda:0', grad_fn=<MaxBackward1>) tensor([100.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "50\n",
      "Gan: tensor(-0., device='cuda:0', grad_fn=<MaxBackward1>) tensor([100.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "100\n",
      "Gan: tensor(-0., device='cuda:0', grad_fn=<MaxBackward1>) tensor([100.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "150\n",
      "Gan: tensor(-0., device='cuda:0', grad_fn=<MaxBackward1>) tensor([100.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "200\n",
      "Gan: tensor(-0., device='cuda:0', grad_fn=<MaxBackward1>) tensor([100.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "250\n",
      "Gan: tensor(-0., device='cuda:0', grad_fn=<MaxBackward1>) tensor([100.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "300\n",
      "Gan: tensor(-0., device='cuda:0', grad_fn=<MaxBackward1>) tensor([100.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "350\n",
      "Gan: tensor(-0., device='cuda:0', grad_fn=<MaxBackward1>) tensor([100.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(int(echo)):\n",
    "\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "    \n",
    "    loss2_list = []\n",
    "    loss1_sum = 0\n",
    "    loss2_sum = 0\n",
    "    loss = 0\n",
    "    if(Is_GAN==False):\n",
    "        denominator = 0\n",
    "        for index in range(0, BATCH_SIZE):\n",
    "            training_data_i, training_label, training_data, label = appen_train(\n",
    "                Generate_distribution(Agent_number_n))\n",
    "            h_loss1, h_loss2 = DiscriminatorNet(training_data_i, training_label,\n",
    "                                           training_data)\n",
    "            denominator += 1\n",
    "            loss1_sum += h_loss1\n",
    "            loss2_sum += h_loss2\n",
    "\n",
    "        loss_sum = torch.sum(loss1_sum + loss2_sum)\n",
    "        loss = (loss_sum) / denominator \n",
    "        total_batch_loss +=float(loss_sum)\n",
    "\n",
    "        opt_D.zero_grad()\n",
    "        loss.backward()\n",
    "        opt_D.step()\n",
    "\n",
    "        temp_number = iteration\n",
    "        index_train_list.append(iteration)\n",
    "        train_losses.append(total_batch_loss)\n",
    "\n",
    "\n",
    "    ## Gan \n",
    "    else:## Gan Work traning GeneratorNet\n",
    "\n",
    "        # real painting from artist\n",
    "        G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                              requires_grad=True).to(dev)  # random ideas\\n\n",
    "        # fake painting from G (random ideas)\n",
    "\n",
    "        G_values = GeneratorNet(G_ideas)\n",
    "        G_values , indices = torch.sort(G_values, descending=True)\n",
    "    #     print(artist_paintings)\n",
    "    #     print(G_paintings)\n",
    "\n",
    "        result_list = []\n",
    "        for index in range(BATCH_SIZE):\n",
    "            h_list = []\n",
    "            value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                G_values[index])\n",
    "            for i in range(Agent_number_n):\n",
    "                h = DiscriminatorNet.calculate(\n",
    "                    value_list_tensor[i].cuda().type(torch.float32))\n",
    "                h_list.append(h)\n",
    "            h_list = torch.stack(h_list)\n",
    "            result_list.append(torch.sum(h_list)/S_tensor.cuda())\n",
    "        result_list = torch.stack(result_list)\n",
    "\n",
    "        diff_loss = torch.max(result_list)-torch.min(result_list)\n",
    "        G_loss = torch.max(- diff_loss)\n",
    "\n",
    "        opt_G.zero_grad()\n",
    "        G_loss.backward()\n",
    "        opt_G.step()\n",
    "\n",
    "    # real painting from artist\n",
    "        G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                              requires_grad=True).to(dev)  # random ideas\\n\n",
    "        # fake painting from G (random ideas)\n",
    "\n",
    "        G_values = GeneratorNet(G_ideas)\n",
    "        G_values , indices = torch.sort(G_values, descending=True)\n",
    "    #     print(artist_paintings)\n",
    "    #     print(G_paintings)\n",
    "\n",
    "        result_list = []\n",
    "        for index in range(BATCH_SIZE):\n",
    "            h_list = []\n",
    "            value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                G_values[index])\n",
    "            for i in range(Agent_number_n):\n",
    "                h = DiscriminatorNet.calculate(\n",
    "                    value_list_tensor[i].cuda().type(torch.float32))\n",
    "                h_list.append(h)\n",
    "            h_list = torch.stack(h_list)\n",
    "            result_list.append(torch.sum(h_list)/S_tensor.cuda())\n",
    "        result_list = torch.stack(result_list)\n",
    "\n",
    "        diff_loss = torch.max(result_list)-torch.min(result_list)\n",
    "\n",
    "        D_loss = torch.where((Agent_number_n-1)>torch.min(result_list),\n",
    "            torch.square(((Agent_number_n-1)-torch.min(result_list))),\n",
    "            torch.zeros(1).to(dev)\n",
    "          )   + torch.where((Agent_number_n-Alpha)<torch.max(result_list),\n",
    "                        torch.square((torch.max(result_list)-(Agent_number_n-Alpha)))/10000,\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "\n",
    "        opt_D.zero_grad()\n",
    "        D_loss.backward()\n",
    "        opt_D.step()\n",
    "\n",
    "\n",
    "\n",
    "    scheduler_D.step()\n",
    "    scheduler_G.step()\n",
    "    temp_number = iteration\n",
    "    if (iteration%50 == 0):\n",
    "        print(temp_number)\n",
    "        if(Is_GAN):\n",
    "            print(\"Gan:\",G_loss,D_loss)\n",
    "            print()\n",
    "        else:\n",
    "            print(loss,float(loss1_sum),float(loss2_sum))\n",
    "            print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-27T05:09:29.231Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylim(0, 1.0)\n",
    "plt.plot(index_test_list,test_losses)\n",
    "plt.ylabel('test loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-27T05:09:29.234Z"
    }
   },
   "outputs": [],
   "source": [
    "if(echo!=0):\n",
    "    torch.save(DiscriminatorNet, \"save/Deep_learning_D_11_supervised_1\")\n",
    "    if(Is_GAN):\n",
    "        torch.save(GeneratorNet, \"save/Deep_learning_G_11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-27T05:09:29.235Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list.append(sum(h_list)/testing_label[index])\n",
    "    \n",
    "\n",
    "print(max(result_list),min(result_list),max(result_list)-min(result_list))\n",
    "print(sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-27T05:09:29.237Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-27T05:09:29.238Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def appen_test_G(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data_G.append(temp_list)\n",
    "    testing_label_G.append(S)\n",
    "def read_testing_data_G():\n",
    "    for i in range(10000):\n",
    "        #appen_test_G(sorted(np.random.rand(Agent_number_n), reverse=True));\n",
    "        G_ideas = torch.randn(N_IDEAS).to(dev)  # random ideas\\n\n",
    "        G_values = GeneratorNet(G_ideas)\n",
    "        G_values , indices = torch.sort(G_values, descending=True)\n",
    "        appen_test_G(G_values.detach().cpu().numpy()) \n",
    "\n",
    "testing_data_G = []\n",
    "testing_label_G = []\n",
    "read_testing_data_G()\n",
    "testing_data_G=np.array(testing_data_G)\n",
    "testing_label_G=np.array(testing_label_G)\n",
    "print(testing_data_G)\n",
    "print(testing_label_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-27T05:09:29.240Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "result_list_G = []\n",
    "for index in range(len(testing_data_G)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data_G[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list_G.append(sum(h_list)/testing_label_G[index])\n",
    "    \n",
    "\n",
    "print(max(result_list_G),min(result_list_G),max(result_list_G)-min(result_list_G))\n",
    "print(sum(result_list_G)/len(result_list_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-27T05:09:29.242Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list_G,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list_G)/len(result_list_G), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "result_list_G.sort()\n",
    "\n",
    "plt.axvline(x=result_list[int(len(result_list_G)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=result_list[int(len(result_list_G)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-27T05:09:29.243Z"
    }
   },
   "outputs": [],
   "source": [
    "final_list = result_list + result_list_G\n",
    "\n",
    "\n",
    "plt.hist(final_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(final_list)/len(final_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "final_list.sort()\n",
    "\n",
    "plt.axvline(x=final_list[int(len(final_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "plt.axvline(x=final_list[int(len(final_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
