{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T14:43:56.244661Z",
     "start_time": "2021-07-11T14:43:54.133202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pygame\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm \n",
    "import matplotlib.cm as cm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy.interpolate import griddata\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "print(dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T14:43:56.260214Z",
     "start_time": "2021-07-11T14:43:56.246624Z"
    }
   },
   "outputs": [],
   "source": [
    "global temp_list\n",
    "temp_list = []\n",
    "Agent_number_n=4;\n",
    "Alpha = 0.64\n",
    "\n",
    "# Hyper Parameters\n",
    "echo = 2001\n",
    "BATCH_SIZE = 64\n",
    "LR_G = 0.0005           # learning rate for generator\n",
    "LR_D = 0.0005           # learning rate for discriminator\n",
    "N_IDEAS = Agent_number_n             # think of this as number of ideas for generating an art work (Generator)\n",
    "ART_COMPONENTS = Agent_number_n     # it could be total point G can draw in the canvas\n",
    "\n",
    "Is_GAN = True # if use Gan\n",
    "\n",
    "def Generate_distribution(Agent_number_n):\n",
    "    return sorted(np.random.rand(Agent_number_n), reverse=True)\n",
    "    #return sorted(np.random.normal(normalloc,normalscale,Agent_number_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T14:43:56.511739Z",
     "start_time": "2021-07-11T14:43:56.262145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.6296199  0.16428312 0.02135004]\n",
      "  [0.72693163 0.16428312 0.02135004]\n",
      "  [0.72693163 0.6296199  0.02135004]\n",
      "  [0.72693163 0.6296199  0.16428312]]\n",
      "\n",
      " [[0.72624192 0.43927588 0.24831071]\n",
      "  [0.95824557 0.43927588 0.24831071]\n",
      "  [0.95824557 0.72624192 0.24831071]\n",
      "  [0.95824557 0.72624192 0.43927588]]\n",
      "\n",
      " [[0.54655145 0.33835037 0.23127281]\n",
      "  [0.66952469 0.33835037 0.23127281]\n",
      "  [0.66952469 0.54655145 0.23127281]\n",
      "  [0.66952469 0.54655145 0.33835037]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.3617713  0.16659563 0.06292157]\n",
      "  [0.95262855 0.16659563 0.06292157]\n",
      "  [0.95262855 0.3617713  0.06292157]\n",
      "  [0.95262855 0.3617713  0.16659563]]\n",
      "\n",
      " [[0.31382345 0.10691546 0.00950515]\n",
      "  [0.71071537 0.10691546 0.00950515]\n",
      "  [0.71071537 0.31382345 0.00950515]\n",
      "  [0.71071537 0.31382345 0.10691546]]\n",
      "\n",
      " [[0.67274149 0.36020593 0.27449534]\n",
      "  [0.92429048 0.36020593 0.27449534]\n",
      "  [0.92429048 0.67274149 0.27449534]\n",
      "  [0.92429048 0.67274149 0.36020593]]]\n",
      "[1.54218469 2.37207409 1.78569934 ... 1.54391705 1.14095943 2.23173324]\n"
     ]
    }
   ],
   "source": [
    "def h_3_star(a, b, t):\n",
    "    return a - min(a, t) + b - min(b, t) + max(min(a, t)+min(b, t), 2*t/3) + 1/2 * max(min(a, t)+min(b, t), t) - 1/2 * max(max(min(a, t), min(b, t)), 2*t/3) - t/6\n",
    "\n",
    "\n",
    "def f_function(a, b, z):\n",
    "    if(z >= 1):\n",
    "        return (a+b)/2 + z/3\n",
    "    else:\n",
    "        return z/3 + h_3_star(a, b, 1-z)/2\n",
    "\n",
    "def h_function_label(input_list):\n",
    "    #input_list = sorted(input_list)\n",
    "    g_list = []\n",
    "    for j1 in range(len(input_list) ):\n",
    "        for j2 in range(len(input_list)):\n",
    "            if(j1 != j2):\n",
    "                a = input_list[j1]\n",
    "                b = input_list[j2]\n",
    "                z = sum(input_list)- a-b\n",
    "\n",
    "                g_list.append( f_function(a, b, z) * (Agent_number_n-1))\n",
    "    h = sum(g_list) * 3 /  (Agent_number_n) /  (Agent_number_n-1) /  (Agent_number_n - 2)\n",
    "    return h\n",
    "\n",
    "def appen(_x_list,y):\n",
    "    global temp_list\n",
    "    temp_list.append(_x_list)\n",
    "    \n",
    "def appen_train(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "        \n",
    "        h = h_function_label(temp)\n",
    "        h_list.append(float(h))\n",
    "    temp_list = np.array(temp_list)\n",
    "    x_list = np.array(x_list)\n",
    "    return temp_list,S,x_list,h_list\n",
    "    \n",
    "\n",
    "def appen_test(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data.append(temp_list)\n",
    "    testing_label.append(S)\n",
    "    temp_list = np.array(temp_list)\n",
    "    return temp_list,S\n",
    "    \n",
    "\n",
    "def read_testing_data():\n",
    "    for i in range(10000):\n",
    "        appen_test(Generate_distribution(Agent_number_n));\n",
    "                            \n",
    "\n",
    "testing_data=[]\n",
    "testing_label=[]\n",
    "S=1.0\n",
    "read_testing_data();\n",
    "\n",
    "testing_data=np.array(testing_data)\n",
    "testing_label=np.array(testing_label)\n",
    "print(testing_data)\n",
    "print(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T14:43:56.527777Z",
     "start_time": "2021-07-11T14:43:56.512699Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.input_dim = (Agent_number_n-1)\n",
    "        self.hidden_dim = 128\n",
    "        self.output_dim = 1\n",
    "        self.hidden_layer_count = 6 \n",
    "        \n",
    "        current_dim = self.input_dim\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(self.hidden_layer_count):\n",
    "            self.layers.append(torch.nn.Linear(current_dim, self.hidden_dim))\n",
    "            current_dim = self.hidden_dim\n",
    "        self.layers.append(torch.nn.Linear(current_dim, self.output_dim))\n",
    "\n",
    "    def calculate(self, value_list):\n",
    "        h = value_list\n",
    "        LeakyReLU = torch.nn.LeakyReLU()\n",
    "        for layer in self.layers:\n",
    "            h = torch.relu(layer(h))\n",
    "        return h\n",
    "\n",
    "    def forward(self, input_list,input_label,list_x):\n",
    "        global iteration,echo,target_order\n",
    "        loss1 = 0\n",
    "        loss2 = 0\n",
    "        loss3 = 0\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).to(dev).type(torch.float32)\n",
    "        h_list = []\n",
    "\n",
    "        for i in range(Agent_number_n):\n",
    "            h = self.calculate(input_list[i])\n",
    "            h_list.append(h)\n",
    "#             loss3 += torch.square(h_function_2(input_list)-h2[1])\n",
    "            \n",
    "        input_label = torch.from_numpy(\n",
    "            np.array(input_label)).to(dev).type(torch.float32)\n",
    "        sum_h = torch.sum(torch.cat(h_list)).to(dev)\n",
    "\n",
    "\n",
    "        loss1 = torch.where((Agent_number_n-1)*input_label>sum_h,\n",
    "                        torch.square(((Agent_number_n-1)*input_label-sum_h)),\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "        loss2 = torch.where((Agent_number_n-Alpha)*input_label<sum_h,\n",
    "                        torch.square((sum_h-(Agent_number_n-Alpha)*input_label))/100,\n",
    "                        torch.zeros(1).to(dev)\n",
    "                      )\n",
    "\n",
    "\n",
    "        return loss1,loss2\n",
    "    \n",
    "    def supervised_loss(self, input_list,label):\n",
    "        global iteration,echo,target_order\n",
    "        input_list = torch.from_numpy(\n",
    "            np.array(input_list)).to(dev).type(torch.float32)\n",
    "        loss = 0 \n",
    "        for i in range(Agent_number_n):\n",
    "            h = self.calculate(input_list[i])\n",
    "            loss += torch.square(h - label[i])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T14:43:56.543317Z",
     "start_time": "2021-07-11T14:43:56.528696Z"
    }
   },
   "outputs": [],
   "source": [
    "def redistribution_value_function(input_tensor):\n",
    "    S = torch.max(torch.sum(input_tensor), torch.ones(1).to(dev))\n",
    "    temp_list = []\n",
    "\n",
    "\n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        \n",
    "        for j in range(Agent_number_n):\n",
    "            if(i != j):\n",
    "                temp .append(input_tensor[j])\n",
    "                \n",
    "        temp = torch.stack(temp)\n",
    "        temp_list.append(temp)\n",
    "    return torch.stack(temp_list), S\n",
    "\n",
    "GeneratorNet = nn.Sequential(                      # Generator\n",
    "    # random ideas (could from normal distribution)\n",
    "    nn.Linear(N_IDEAS, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    # making a painting from these random ideas\n",
    "    nn.Linear(64, ART_COMPONENTS),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T14:43:58.282557Z",
     "start_time": "2021-07-11T14:43:56.545264Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "DiscriminatorNet  = Net()\n",
    "DiscriminatorNet.apply(weight_init)\n",
    "GeneratorNet.apply(weight_init)\n",
    "DiscriminatorNet = torch.load(\"save/Deep_learning_D_4_gan_1\")\n",
    "if(Is_GAN):\n",
    "    GeneratorNet = torch.load(\"save/Deep_learning_G_4_1\")\n",
    "DiscriminatorNet.to(dev)\n",
    "GeneratorNet.to(dev)\n",
    "\n",
    "opt_D = torch.optim.Adam(DiscriminatorNet.parameters(), lr=LR_D)\n",
    "opt_G = torch.optim.Adam(GeneratorNet.parameters(), lr=LR_G)\n",
    "\n",
    "\n",
    "scheduler_D = torch.optim.lr_scheduler.StepLR(opt_D, step_size=100, gamma=0.98)\n",
    "scheduler_G = torch.optim.lr_scheduler.StepLR(opt_G, step_size=100, gamma=0.98)\n",
    "\n",
    "index_train_list = []\n",
    "index_test_list = []\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T15:07:38.099900Z",
     "start_time": "2021-07-11T14:43:58.284554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.0017, device='cuda:0', grad_fn=<DivBackward0>) 0.10564491897821426\n",
      "100 tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) 0.008830081671476364\n",
      "200 tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) 0.007123796734958887\n",
      "300 tensor(7.9291e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.005074651446193457\n",
      "400 tensor(4.7456e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.003037160262465477\n",
      "500 tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) 0.00662061246111989\n",
      "600 tensor(5.1057e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.003267669351771474\n",
      "700 tensor(5.2649e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.003369544865563512\n",
      "800 tensor(5.7262e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0036647918168455362\n",
      "900 tensor(4.6944e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0030043977312743664\n",
      "1000 tensor(3.7944e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0024283863604068756\n",
      "1100 tensor(3.9200e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.002508787205442786\n",
      "1200 tensor(5.3762e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0034407833591103554\n",
      "1300 tensor(3.1087e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0019895907025784254\n",
      "1400 tensor(3.3335e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0021334157790988684\n",
      "1500 tensor(2.1608e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0013829190284013748\n",
      "1600 tensor(2.2815e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.001460139057599008\n",
      "1700 tensor(2.7592e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0017658957513049245\n",
      "1800 tensor(2.2533e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0014421310042962432\n",
      "1900 tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) 0.007794181350618601\n",
      "2000 tensor(1.6578e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.001060984912328422\n",
      "2100 tensor(9.5077e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.006084902212023735\n",
      "2200 tensor(3.7694e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.002412414411082864\n",
      "2300 tensor(5.3570e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.003428511554375291\n",
      "2400 tensor(2.3491e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0015033953823149204\n",
      "2500 tensor(2.6870e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.001719708670862019\n",
      "2600 tensor(2.9071e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0018605481600388885\n",
      "2700 tensor(1.9018e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0012171261478215456\n",
      "2800 tensor(2.4769e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0015852386131882668\n",
      "2900 tensor(3.0938e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0019800588488578796\n",
      "3000 tensor(2.1232e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0013588399160653353\n",
      "3100 tensor(1.4543e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0009307365398854017\n",
      "3200 tensor(3.8382e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.002456430811434984\n",
      "3300 tensor(5.0782e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0032500610686838627\n",
      "3400 tensor(1.5099e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0009663520031608641\n",
      "3500 tensor(1.5191e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0009721937240101397\n",
      "3600 tensor(5.7214e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0036616907455027103\n",
      "3700 tensor(1.6697e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0010686024324968457\n",
      "3800 tensor(1.3792e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0008826814009808004\n",
      "3900 tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>) 0.013920551165938377\n",
      "4000 tensor(6.5355e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.004182692617177963\n",
      "4100 tensor(9.5440e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0006108154193498194\n",
      "4200 tensor(2.5098e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.001606281497515738\n",
      "4300 tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>) 0.00913891289383173\n",
      "4400 tensor(6.3008e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0004032481519971043\n",
      "4500 tensor(6.3301e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0004051259020343423\n",
      "4600 tensor(1.1503e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0007361707976087928\n",
      "4700 tensor(1.1160e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0007142702233977616\n",
      "4800 tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>) 0.019199911504983902\n",
      "4900 tensor(1.2796e-05, device='cuda:0', grad_fn=<DivBackward0>) 0.0008189635700546205\n"
     ]
    }
   ],
   "source": [
    "#supervised\n",
    "index_supervisedtrain_list = []\n",
    "supervisedtrain_losses = []\n",
    "for iteration in range(int(1000)):\n",
    "\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "    \n",
    "    loss_sum = 0\n",
    "    denominator = 0\n",
    "    for index in range(0, BATCH_SIZE):\n",
    "        training_data_i, training_S, training_data,label = appen_train(\n",
    "            Generate_distribution(Agent_number_n))\n",
    "        h_loss = DiscriminatorNet.supervised_loss(training_data_i, label)\n",
    "        denominator += 1\n",
    "        loss_sum += h_loss\n",
    "\n",
    "    loss_sum = torch.sum(loss_sum)\n",
    "    loss = (loss_sum) / denominator \n",
    "    total_batch_loss += float(loss_sum)\n",
    "\n",
    "    opt_D.zero_grad()\n",
    "    loss.backward()\n",
    "    opt_D.step()\n",
    "\n",
    "    if (iteration%100 == 0):\n",
    "        print(iteration,loss,total_batch_loss)\n",
    "        index_supervisedtrain_list.append(iteration)\n",
    "        supervisedtrain_losses.append(total_batch_loss)\n",
    "    scheduler_D.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T15:07:38.209951Z",
     "start_time": "2021-07-11T15:07:38.101573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylim(0, 0.1)\n",
    "plt.plot(index_supervisedtrain_list ,supervisedtrain_losses)\n",
    "plt.ylabel('supervised train loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "Gan: tensor(-0.8569, device='cuda:0', grad_fn=<MaxBackward1>) tensor([7.1646e-05], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "4.2273805141448975 3.233732329425131 0.9936481847197665 0.252444672870352\n",
      "\n",
      "\n",
      "100 tensor(8.0380e-06, device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0005144319729879498\n",
      "Gan: tensor(-0.9129, device='cuda:0', grad_fn=<MaxBackward1>) tensor([1.3246e-05], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "3.658748984336853 3.0387343955714394 0.6200145887654136 0.15173319983173528\n",
      "\n",
      "\n",
      "200 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "Gan: tensor(-0.8801, device='cuda:0', grad_fn=<MaxBackward1>) tensor([2.7164e-05], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "3.549465596675873 2.9897904992103577 0.5596750974655151 0.1637487632411858\n",
      "\n",
      "\n",
      "300 tensor(0., device='cuda:0', grad_fn=<DivBackward0>) 0.0 0.0\n",
      "Gan: tensor(-0.7720, device='cuda:0', grad_fn=<MaxBackward1>) tensor([2.2082e-05], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "3.508164882659912 3.0135873379375444 0.4945775447223677 0.14261337361195814\n",
      "\n",
      "\n",
      "400 tensor(1.6423e-09, device='cuda:0', grad_fn=<DivBackward0>) 0.0 1.0510666470509022e-07\n",
      "Gan: tensor(-0.7142, device='cuda:0', grad_fn=<MaxBackward1>) tensor([0.0002], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "3.5518962083185053 3.0552259330832756 0.49667027523522966 0.14808385790306833\n",
      "\n",
      "\n",
      "500 tensor(3.1726e-07, device='cuda:0', grad_fn=<DivBackward0>) 0.0 2.0304418285377324e-05\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(int(echo)):\n",
    "\n",
    "    temp_number = 0\n",
    "    total_batch_loss = 0 \n",
    "        \n",
    "    loss2_list = []\n",
    "    loss1_sum = 0\n",
    "    loss2_sum = 0\n",
    "    denominator = 0\n",
    "    for index in range(0, BATCH_SIZE):\n",
    "        training_data_i, training_label, training_data, label = appen_train(\n",
    "            Generate_distribution(Agent_number_n))\n",
    "        h_loss1, h_loss2 = DiscriminatorNet(training_data_i, training_label,\n",
    "                                       training_data)\n",
    "        denominator += 1\n",
    "        loss1_sum += h_loss1\n",
    "        loss2_sum += h_loss2\n",
    "\n",
    "    loss_sum = torch.sum(loss1_sum + loss2_sum)\n",
    "    loss = (loss_sum) / denominator \n",
    "    total_batch_loss +=float(loss_sum)\n",
    "\n",
    "    opt_D.zero_grad()\n",
    "    loss.backward()\n",
    "    opt_D.step()\n",
    "\n",
    "    temp_number = iteration\n",
    "    index_train_list.append(iteration)\n",
    "    train_losses.append(total_batch_loss)\n",
    "\n",
    "    if (iteration%100 == 0):\n",
    "        print(temp_number,loss,float(loss1_sum),float(loss2_sum))\n",
    "    ## Gan \n",
    "        if(Is_GAN):## Gan Work traning GeneratorNet\n",
    "\n",
    "            DiscriminatorNet.requires_grad = True\n",
    "            GeneratorNet.requires_grad = True\n",
    "\n",
    "\n",
    "            for step in range(10):\n",
    "                # real painting from artist\n",
    "                G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                                      requires_grad=True).to(dev)  # random ideas\\n\n",
    "                # fake painting from G (random ideas)\n",
    "\n",
    "                G_values = GeneratorNet(G_ideas)\n",
    "                G_values , indices = torch.sort(G_values, descending=True)\n",
    "            #     print(artist_paintings)\n",
    "            #     print(G_paintings)\n",
    "\n",
    "                result_list = []\n",
    "                for index in range(BATCH_SIZE):\n",
    "                    h_list = []\n",
    "                    value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                        G_values[index])\n",
    "                    for i in range(Agent_number_n):\n",
    "                        h = DiscriminatorNet.calculate(\n",
    "                            value_list_tensor[i].cuda().type(torch.float32))\n",
    "                        h_list.append(h)\n",
    "                    h_list = torch.stack(h_list)\n",
    "                    result_list.append(torch.sum(h_list)/S_tensor.cuda())\n",
    "                result_list = torch.stack(result_list)\n",
    "\n",
    "                diff_loss = torch.max(result_list)-torch.min(result_list)\n",
    "                G_loss = torch.max(- diff_loss)\n",
    "\n",
    "                opt_G.zero_grad()\n",
    "                G_loss.backward()\n",
    "                opt_G.step()\n",
    "\n",
    "            # real painting from artist\n",
    "                G_ideas = torch.randn(BATCH_SIZE, N_IDEAS,\n",
    "                                      requires_grad=True).to(dev)  # random ideas\\n\n",
    "                # fake painting from G (random ideas)\n",
    "\n",
    "                G_values = GeneratorNet(G_ideas)\n",
    "                G_values , indices = torch.sort(G_values, descending=True)\n",
    "            #     print(artist_paintings)\n",
    "            #     print(G_paintings)\n",
    "\n",
    "                result_list = []\n",
    "                for index in range(BATCH_SIZE):\n",
    "                    h_list = []\n",
    "                    value_list_tensor, S_tensor = redistribution_value_function(\n",
    "                        G_values[index])\n",
    "                    for i in range(Agent_number_n):\n",
    "                        h = DiscriminatorNet.calculate(\n",
    "                            value_list_tensor[i].cuda().type(torch.float32))\n",
    "                        h_list.append(h)\n",
    "                    h_list = torch.stack(h_list)\n",
    "                    result_list.append(torch.sum(h_list)/S_tensor.cuda())\n",
    "                result_list = torch.stack(result_list)\n",
    "\n",
    "                diff_loss = torch.max(result_list)-torch.min(result_list)\n",
    "\n",
    "                D_loss = torch.where((Agent_number_n-1)>torch.min(result_list),\n",
    "                    torch.square(((Agent_number_n-1)-torch.min(result_list))),\n",
    "                    torch.zeros(1).to(dev)\n",
    "                  )   + torch.where((Agent_number_n-Alpha)<torch.max(result_list),\n",
    "                                torch.square((torch.max(result_list)-(Agent_number_n-Alpha)))/10000,\n",
    "                                torch.zeros(1).to(dev)\n",
    "                              )\n",
    "\n",
    "\n",
    "                opt_D.zero_grad()\n",
    "                D_loss.backward()\n",
    "                opt_D.step()\n",
    "                \n",
    "            print(\"Gan:\",G_loss,D_loss)\n",
    "            print()\n",
    "\n",
    "            \n",
    "        result_list = []\n",
    "        for index in range(len(testing_data)):\n",
    "            h_list = []\n",
    "            for i in range(Agent_number_n):\n",
    "                h = DiscriminatorNet.calculate(\n",
    "                    torch.tensor(testing_data[index][i]).to(dev).type(\n",
    "                        torch.float32))\n",
    "                h_list.append(float(h))\n",
    "            result_list.append(sum(h_list) / testing_label[index])\n",
    "        print(max(result_list), min(result_list),\n",
    "              max(result_list) - min(result_list),\n",
    "              (sum(result_list) / len(result_list) - min(result_list))+ Agent_number_n-1 - min(min(result_list),Agent_number_n-1) )\n",
    "\n",
    "        index_test_list.append(iteration)\n",
    "        test_losses.append(\n",
    "            (sum(result_list) / len(result_list) - min(result_list))+ Agent_number_n-1 - min(min(result_list),Agent_number_n-1) )\n",
    "        print()\n",
    "        index_test_list.append(iteration)\n",
    "        test_losses.append(\n",
    "            max(result_list)-min(result_list) )\n",
    "        \n",
    "  \n",
    "        print()\n",
    "\n",
    "\n",
    "    scheduler_D.step()\n",
    "    scheduler_G.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.098Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylim(0, 1.0)\n",
    "plt.plot(index_test_list,test_losses)\n",
    "plt.ylabel('test loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.100Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(DiscriminatorNet, \"save/Deep_learning_D_4_gan_1\")\n",
    "if(Is_GAN):\n",
    "    torch.save(GeneratorNet, \"save/Deep_learning_G_4_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.103Z"
    }
   },
   "outputs": [],
   "source": [
    "def h_3_star(a, b, t):\n",
    "    return a - min(a, t) + b - min(b, t) + max(min(a, t)+min(b, t), 2*t/3) + 1/2 * max(min(a, t)+min(b, t), t) - 1/2 * max(max(min(a, t), min(b, t)), 2*t/3) - t/6\n",
    "\n",
    "\n",
    "def f_function(a, b, z):\n",
    "    if(z >= 1):\n",
    "        return (a+b)/2 + z/3\n",
    "    else:\n",
    "        return z/3 + h_3_star(a, b, 1-z)/2\n",
    "\n",
    "def h_function(input_list):\n",
    "    #input_list = sorted(input_list)\n",
    "    g_list = []\n",
    "    for j1 in range(len(input_list) ):\n",
    "        for j2 in range(len(input_list)):\n",
    "            if(j1 != j2):\n",
    "                a = input_list[j1]\n",
    "                b = input_list[j2]\n",
    "                z = sum(input_list)- a-b\n",
    "\n",
    "                g_list.append( f_function(a, b, z) * (Agent_number_n-1))\n",
    "    h = sum(g_list) * 3 /  (Agent_number_n) /  (Agent_number_n-1) /  (Agent_number_n - 2)\n",
    "    return h\n",
    "                \n",
    "                \n",
    "x_list = []\n",
    "y_list = []\n",
    "z_list = []\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        x_list.append(testing_data[index][i][0])\n",
    "        y_list.append(testing_data[index][i][1])\n",
    "        h = h_function(testing_data[index][i])\n",
    "        z_list.append(float(h))\n",
    "        h_list.append(float(h))\n",
    "    result_list.append(sum(h_list)/testing_label[index]) \n",
    "    \n",
    "    \n",
    "print(max(result_list), min(result_list), max(result_list)-min(result_list),sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.104Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "# result_list.sort()\n",
    "\n",
    "# plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "# plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.106Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_testing_data():\n",
    "    for i in range(100000):\n",
    "        appen_test(Generate_distribution(Agent_number_n));\n",
    "        \n",
    "testing_data=[]\n",
    "testing_label=[]\n",
    "S=1.0\n",
    "read_testing_data();\n",
    "\n",
    "testing_data=np.array(testing_data)\n",
    "testing_label=np.array(testing_label)\n",
    "print(testing_data)\n",
    "print(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.107Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "result_list = []\n",
    "for index in range(len(testing_data)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list.append(sum(h_list)/testing_label[index])\n",
    "    \n",
    "\n",
    "print(max(result_list),min(result_list),max(result_list)-min(result_list))\n",
    "print(sum(result_list)/len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.108Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list)/len(result_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "# result_list.sort()\n",
    "\n",
    "# plt.axvline(x=result_list[int(len(result_list)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "# plt.axvline(x=result_list[int(len(result_list)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.110Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate 10000 testing data on GeneratorNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.111Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def appen_test_G(x_list):\n",
    "    global temp_list\n",
    "                \n",
    "    S= max(sum(x_list),1.0);\n",
    "    temp_list = []\n",
    "    \n",
    "    for i in range(Agent_number_n):\n",
    "        temp = []\n",
    "        for j in range(Agent_number_n):\n",
    "            if(i!=j):\n",
    "                temp.append(x_list[j])\n",
    "        appen(temp,S)\n",
    "    testing_data_G.append(temp_list)\n",
    "    testing_label_G.append(S)\n",
    "# fake painting from G (random ideas)\n",
    "\n",
    "def read_testing_data_G():\n",
    "    for i in range(100000):\n",
    "        #appen_test_G(sorted(np.random.rand(Agent_number_n), reverse=True));\n",
    "        G_ideas = torch.randn(N_IDEAS).to(dev)  # random ideas\\n\n",
    "        G_values = GeneratorNet(G_ideas)\n",
    "        G_values , indices = torch.sort(G_values, descending=True)\n",
    "        appen_test_G(G_values.detach().cpu().numpy()) \n",
    "        \n",
    "testing_data_G = []\n",
    "testing_label_G = []\n",
    "read_testing_data_G()\n",
    "testing_data_G=np.array(testing_data_G)\n",
    "testing_label_G=np.array(testing_label_G)\n",
    "print(testing_data_G)\n",
    "print(testing_label_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.112Z"
    }
   },
   "outputs": [],
   "source": [
    "result_list_G = []\n",
    "for index in range(len(testing_data_G)):\n",
    "    h_list = []\n",
    "    for i in range(Agent_number_n):\n",
    "        h = DiscriminatorNet.calculate(torch.tensor(testing_data_G[index][i]).to(dev).type(torch.float32))\n",
    "        h_list.append(float(h))\n",
    "    \n",
    "    #print(sum(h_list),h_list,sum(h_list)/testing_label[index])\n",
    "    result_list_G.append(sum(h_list)/testing_label_G[index])\n",
    "    \n",
    "\n",
    "print(max(result_list_G),min(result_list_G),max(result_list_G)-min(result_list_G))\n",
    "print(sum(result_list_G)/len(result_list_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.113Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(result_list_G,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(result_list_G)/len(result_list_G), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "# result_list_G.sort()\n",
    "\n",
    "# plt.axvline(x=result_list[int(len(result_list_G)*0.01)], linestyle='--', linewidth=0.5, label=\"1%\", c='b')\n",
    "# plt.axvline(x=result_list[int(len(result_list_G)*0.99)], linestyle='--', linewidth=0.5, label=\"99%\", c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.115Z"
    }
   },
   "outputs": [],
   "source": [
    "final_list = result_list + result_list_G\n",
    "\n",
    "\n",
    "plt.hist(final_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(final_list)/len(final_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(max(final_list),min(final_list),max(final_list)-min(final_list))\n",
    "print(sum(final_list)/len(final_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.116Z"
    }
   },
   "outputs": [],
   "source": [
    "final_list = result_list[:10000] + result_list_G[:10000]\n",
    "\n",
    "\n",
    "plt.hist(final_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(final_list)/len(final_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(max(final_list),min(final_list),max(final_list)-min(final_list))\n",
    "print(sum(final_list)/len(final_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.118Z"
    }
   },
   "outputs": [],
   "source": [
    "final_list = result_list[:20000] + result_list_G[:20000]\n",
    "\n",
    "\n",
    "plt.hist(final_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(final_list)/len(final_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(max(final_list),min(final_list),max(final_list)-min(final_list))\n",
    "print(sum(final_list)/len(final_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-11T14:43:54.119Z"
    }
   },
   "outputs": [],
   "source": [
    "final_list = result_list[:50000] + result_list_G[:50000]\n",
    "\n",
    "\n",
    "plt.hist(final_list,bins=500)\n",
    "\n",
    "plt.title(\"Means\", y=1.015, fontsize=20)\n",
    "plt.axvline(x=sum(final_list)/len(final_list), linestyle='--', linewidth=2.5, label=\"sample mean\", c='orange')\n",
    "plt.xlabel(\"samples\", labelpad=14)\n",
    "plt.ylabel(\"frequency of occurence\", labelpad=14)\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(max(final_list),min(final_list),max(final_list)-min(final_list))\n",
    "print(sum(final_list)/len(final_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
